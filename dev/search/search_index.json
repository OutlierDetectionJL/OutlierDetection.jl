{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"API/datasets/","text":"Datasets OutlierDetectionData provides access to collections of outlier detection datasets. The following collections are currently supported: ODDS , Outlier Detection DataSets, Shebuti Rayana, 2016 ELKI , On the Evaluation of Unsupervised Outlier Detection, Campos et al., 2016 The following methods are defined for all collections. list # OutlierDetectionData.list \u2014 Function . list ([ prefix ]) List the available datasets in a dataset collection optionally given a prefix. Parameters prefix::Union{Regex, AbstractString} Regex or string used to filter the datasets. load # OutlierDetectionData.load \u2014 Function . load ( dataset ) Load a given dataset from a dataset collection. Parameters name::AbstractString Name of the dataset to load.","title":"Datasets"},{"location":"API/datasets/#datasets","text":"OutlierDetectionData provides access to collections of outlier detection datasets. The following collections are currently supported: ODDS , Outlier Detection DataSets, Shebuti Rayana, 2016 ELKI , On the Evaluation of Unsupervised Outlier Detection, Campos et al., 2016 The following methods are defined for all collections.","title":"Datasets"},{"location":"API/datasets/#list","text":"# OutlierDetectionData.list \u2014 Function . list ([ prefix ]) List the available datasets in a dataset collection optionally given a prefix. Parameters prefix::Union{Regex, AbstractString} Regex or string used to filter the datasets.","title":"list"},{"location":"API/datasets/#load","text":"# OutlierDetectionData.load \u2014 Function . load ( dataset ) Load a given dataset from a dataset collection. Parameters name::AbstractString Name of the dataset to load.","title":"load"},{"location":"API/detectors/","text":"Detectors A Detector is just a collection of hyperparameters. Each detector implements a fit and transform method, where fit refers to learning a model from training data and transform refers to using a learned model to calculate outlier scores of new data. Detectors typically do not classify samples into inliers and outliers; that's a DeterministicDetector wrapper is used to convert the raw scores into binary labels. Neighbor-based ABODDetector # OutlierDetectionNeighbors.ABODDetector \u2014 Type . ABODDetector ( k = 5 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false , enhanced = false ) Determine outliers based on the angles to its nearest neighbors. This implements the FastABOD variant described in the paper, that is, it uses the variance of angles to its nearest neighbors, not to the whole dataset, see [1]. Notice: The scores are inverted, to conform to our notion that higher scores describe higher outlierness. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. enhanced::Bool When enhanced=true , it uses the enhanced ABOD (EABOD) adaptation proposed by [2]. Examples using OutlierDetection : ABODDetector , fit , score detector = ABODDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Kriegel, Hans-Peter; S hubert, Matthias; Zimek, Arthur (2008): Angle-based outlier detection in high-dimensional data. [2] Li, Xiaojie; Lv, Jian Cheng; Cheng, Dongdong (2015): Angle-Based Outlier Detection Algorithm with More Stable Relationships. COFDetector # OutlierDetectionNeighbors.COFDetector \u2014 Type . COFDetector ( k = 5 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false ) Local outlier density based on chaining distance between graphs of neighbors, as described in [1]. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. Examples using OutlierDetection : COFDetector , fit , score detector = COFDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Tang, Jian; Chen, Zhixiang; Fu, Ada Wai-Chee; Cheung, David Wai-Lok (2002): Enhancing Effectiveness of Outlier Detections for Low Density Patterns. DNNDetector # OutlierDetectionNeighbors.DNNDetector \u2014 Type . DNNDetector ( d = 0 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false ) Anomaly score based on the number of neighbors in a hypersphere of radius d . Knorr et al. [1] directly converted the resulting outlier scores to labels, thus this implementation does not fully reflect the approach from the paper. Parameters d::Real The hypersphere radius used to calculate the global density of an instance. metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. Examples using OutlierDetection : DNNDetector , fit , score detector = DNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Knorr, Edwin M.; Ng, Raymond T. (1998): Algorithms for Mining Distance-Based Outliers in Large Datasets. KNNDetector # OutlierDetectionNeighbors.KNNDetector \u2014 Type . KNNDetector ( k = 5 , metric = Euclidean , algorithm = :kdtree , leafsize = 10 , reorder = true , reduction = :maximum ) Calculate the anomaly score of an instance based on the distance to its k-nearest neighbors. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. reduction::Symbol One of (:maximum, :median, :mean) . ( reduction=:maximum ) was proposed by [1]. Angiulli et al. [2] proposed sum to reduce the distances, but mean has been implemented for numerical stability. Examples using OutlierDetection : KNNDetector , fit , score detector = KNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Ramaswamy, Sridhar; Rastogi, Rajeev; Shim, Kyuseok (2000): Efficient Algorithms for Mining Outliers from Large Data Sets. [2] Angiulli, Fabrizio; Pizzuti, Clara (2002): Fast Outlier Detection in High Dimensional Spaces. LOFDetector # OutlierDetectionNeighbors.LOFDetector \u2014 Type . LOFDetector ( k = 5 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false ) Calculate an anomaly score based on the density of an instance in comparison to its neighbors. This algorithm introduced the notion of local outliers and was developed by Breunig et al., see [1]. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. Examples using OutlierDetection : LOFDetector , fit , score detector = LOFDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Breunig, Markus M.; Kriegel, Hans-Peter; Ng, Raymond T.; Sander, J\u00f6rg (2000): LOF: Identifying Density-Based Local Outliers. Network-based Warning The neural-network detectors are experimental and subject to change. AEDetector # OutlierDetectionNetworks.AEDetector \u2014 Type . AEDetector ( encoder = Chain (), decoder = Chain (), batchsize = 32 , epochs = 1 , shuffle = false , partial = true , opt = ADAM (), loss = mse ) Calculate the anomaly score of an instance based on the reconstruction loss of an autoencoder, see [1] for an explanation of auto encoders. Parameters encoder::Chain Transforms the input data into a latent state with a fixed shape. decoder::Chain Transforms the latent state back into the shape of the input data. batchsize::Integer The number of samples to work through before updating the internal model parameters. epochs::Integer The number of passes of the entire training dataset the machine learning algorithm has completed. shuffle::Bool If shuffle=true , shuffles the observations each time iterations are re-started, else no shuffling is performed. partial::Bool If partial=false , drops the last mini-batch if it is smaller than the batchsize. opt::Any Any Flux-compatibale optimizer, typically a struct that holds all the optimiser parameters along with a definition of apply! that defines how to apply the update rule associated with the optimizer. loss::Function The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples. Examples using OutlierDetection : AEDetector , fit , score detector = AEDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Aggarwal, Charu C. (2017): Outlier Analysis. DSADDetector # OutlierDetectionNetworks.DSADDetector \u2014 Type . DSADDetector ( encoder = Chain (), decoder = Chain (), batchsize = 32 , epochs = 1 , shuffle = true , partial = false , opt = ADAM (), loss = mse , eta = 1 , eps = 1e-6 , callback = _ -> () -> ()) Deep Semi-Supervised Anomaly detection technique based on the distance to a hypersphere center as described in [1]. Parameters encoder::Chain Transforms the input data into a latent state with a fixed shape. decoder::Chain Transforms the latent state back into the shape of the input data. batchsize::Integer The number of samples to work through before updating the internal model parameters. epochs::Integer The number of passes of the entire training dataset the machine learning algorithm has completed. shuffle::Bool If shuffle=true , shuffles the observations each time iterations are re-started, else no shuffling is performed. partial::Bool If partial=false , drops the last mini-batch if it is smaller than the batchsize. opt::Any Any Flux-compatibale optimizer, typically a struct that holds all the optimiser parameters along with a definition of apply! that defines how to apply the update rule associated with the optimizer. loss::Function The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples. eta::Real Weighting parameter for the labeled data; i.e. higher values of eta assign higher weight to labeled data in the svdd loss function. For a sensitivity analysis of this parameter, see [1]. eps::Real Because the inverse distance used in the svdd loss can lead to division by zero, the parameters eps is added for numerical stability. callback::Function Experimental parameter that might change . A function to be called after the model parameters have been updated that can call Flux's callback helpers, see https://fluxml.ai/Flux.jl/stable/utilities/#Callback-Helpers-1 . Notice: The parameters batchsize , epochs , shuffle , partial , opt and callback can also be tuples of size 2, specifying the corresponding values for (1) pretraining and (2) training; otherwise the same values are used for pretraining and training. Examples using OutlierDetection : DSADDetector , fit , score detector = DSADDetector () X = rand ( 10 , 100 ) y = rand ([ - 1 , 1 ], 100 ) model = fit ( detector , X , y ) train_scores , test_scores = score ( detector , model , X ) References [1] Ruff, Lukas; Vandermeulen, Robert A.; G\u00f6rnitz, Nico; Binder, Alexander; M\u00fcller, Emmanuel; M\u00fcller, Klaus-Robert; Kloft, Marius (2019): Deep Semi-Supervised Anomaly Detection. ESADDetector # OutlierDetectionNetworks.ESADDetector \u2014 Type . ESADDetector ( encoder = Chain (), decoder = Chain (), batchsize = 32 , epochs = 1 , shuffle = false , partial = true , opt = ADAM (), \u03bb1 = 1 , \u03bb2 = 1 , noise = identity ) End-to-End semi-supervised anomaly detection algorithm similar to DeepSAD, but without the pretraining phase. The algorithm was published by Huang et al., see [1]. Parameters loss::Function The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples. \u03bb1::Real Weighting parameter of the norm loss, which minimizes the empirical variance and thus minimizes entropy. \u03bb2::Real Weighting parameter of the assistent loss function to define the consistency between the two encoders. noise::Function (AbstractArray{T} -> AbstractArray{T}) A function to be applied to a batch of input data to add noise, see [1] for an explanation. Examples using OutlierDetection : ESADDetector , fit , score detector = ESADDetector () X = rand ( 10 , 100 ) y = rand ([ - 1 , 1 ], 100 ) model = fit ( detector , X , y ) train_scores , test_scores = score ( detector , model , X ) References [1] Huang, Chaoqin; Ye, Fei; Zhang, Ya; Wang, Yan-Feng; Tian, Qi (2020): ESAD: End-to-end Deep Semi-supervised Anomaly Detection. Python-based Using PyCall , we can easily integrate existing python outlier detection algorithms. Currently, almost every PyOD algorithm is integrated and can thus be easily used directly from Julia. ABODDetector # OutlierDetectionPython.ABODDetector \u2014 Type . ABODDetector ( n_neighbors = 5 , method = \"fast\" ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.abod CBLOFDetector # OutlierDetectionPython.CBLOFDetector \u2014 Type . CBLOFDetector ( n_clusters = 8 , alpha = 0.9 , beta = 5 , use_weights = false , random_state = nothing , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cblof COFDetector # OutlierDetectionPython.COFDetector \u2014 Type . COFDetector ( n_neighbors = 5 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cof COPODDetector # OutlierDetectionPython.COPODDetector \u2014 Type . COPODDetector () https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.copod HBOSDetector # OutlierDetectionPython.HBOSDetector \u2014 Type . HBOSDetector ( n_bins = 10 , alpha = 0.1 , tol = 0.5 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos IForestDetector # OutlierDetectionPython.IForestDetector \u2014 Type . IForestDetector ( n_estimators = 100 , max_samples = \"auto\" , max_features = 1.0 bootstrap = false , behaviour = \"new\" , random_state = nothing , verbose = 0 , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest KNNDetector # OutlierDetectionPython.KNNDetector \u2014 Type . KNNDetector ( n_neighbors = 5 , method = \"largest\" , radius = 1.0 , algorithm = \"auto\" , leaf_size = 30 , metric = \"minkowski\" , p = 2 , metric_params = nothing , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn LMDDDetector # OutlierDetectionPython.LMDDDetector \u2014 Type . LMDDDetector ( n_iter = 50 , dis_measure = \"aad\" , random_state = nothing ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.lmdd LODADetector # OutlierDetectionPython.LODADetector \u2014 Type . LODADetector ( n_bins = 10 , n_random_cuts = 100 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.loda LOFDetector # OutlierDetectionPython.LOFDetector \u2014 Type . LOFDetector ( n_neighbors = 5 , method = \"largest\" , algorithm = \"auto\" , leaf_size = 30 , metric = \"minkowski\" , p = 2 , metric_params = nothing , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.lof LOCIDetector # OutlierDetectionPython.LOCIDetector \u2014 Type . LOCIDetector ( alpha = 0.5 , k = 3 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.loci MCDDetector # OutlierDetectionPython.MCDDetector \u2014 Type . MCDDetector ( store_precision = true , assume_centered = false , support_fraction = nothing , random_state = nothing ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.mcd OCSVMDetector # OutlierDetectionPython.OCSVMDetector \u2014 Type . OCSVMDetector ( kernel = \"rbf\" , degree = 3 , gamma = \"auto\" , coef0 = 0.0 , tol = 0.001 , nu = 0.5 , shrinking = true , cache_size = 200 , verbose = false , max_iter = - 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.ocsvm PCADetector # OutlierDetectionPython.PCADetector \u2014 Type . PCADetector ( n_components = nothing , n_selected_components = nothing , copy = true , whiten = false , svd_solver = \"auto\" , tol = 0.0 iterated_power = \"auto\" , standardization = true , weighted = true , random_state = nothing ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca RODDetector # OutlierDetectionPython.RODDetector \u2014 Type . RODDetector ( parallel_execution = false ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.rod SODDetector # OutlierDetectionPython.SODDetector \u2014 Type . SODDetector ( n_neighbors = 5 , ref_set = 10 , alpha = 0.8 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.sod SOSDetector # OutlierDetectionPython.SOSDetector \u2014 Type . SOSDetector ( perplexity = 4.5 , metric = \"minkowski\" , eps = 1e-5 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.sos","title":"Detectors"},{"location":"API/detectors/#detectors","text":"A Detector is just a collection of hyperparameters. Each detector implements a fit and transform method, where fit refers to learning a model from training data and transform refers to using a learned model to calculate outlier scores of new data. Detectors typically do not classify samples into inliers and outliers; that's a DeterministicDetector wrapper is used to convert the raw scores into binary labels.","title":"Detectors"},{"location":"API/detectors/#neighbor-based","text":"","title":"Neighbor-based"},{"location":"API/detectors/#aboddetector","text":"# OutlierDetectionNeighbors.ABODDetector \u2014 Type . ABODDetector ( k = 5 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false , enhanced = false ) Determine outliers based on the angles to its nearest neighbors. This implements the FastABOD variant described in the paper, that is, it uses the variance of angles to its nearest neighbors, not to the whole dataset, see [1]. Notice: The scores are inverted, to conform to our notion that higher scores describe higher outlierness. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. enhanced::Bool When enhanced=true , it uses the enhanced ABOD (EABOD) adaptation proposed by [2]. Examples using OutlierDetection : ABODDetector , fit , score detector = ABODDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Kriegel, Hans-Peter; S hubert, Matthias; Zimek, Arthur (2008): Angle-based outlier detection in high-dimensional data. [2] Li, Xiaojie; Lv, Jian Cheng; Cheng, Dongdong (2015): Angle-Based Outlier Detection Algorithm with More Stable Relationships.","title":"ABODDetector"},{"location":"API/detectors/#cofdetector","text":"# OutlierDetectionNeighbors.COFDetector \u2014 Type . COFDetector ( k = 5 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false ) Local outlier density based on chaining distance between graphs of neighbors, as described in [1]. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. Examples using OutlierDetection : COFDetector , fit , score detector = COFDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Tang, Jian; Chen, Zhixiang; Fu, Ada Wai-Chee; Cheung, David Wai-Lok (2002): Enhancing Effectiveness of Outlier Detections for Low Density Patterns.","title":"COFDetector"},{"location":"API/detectors/#dnndetector","text":"# OutlierDetectionNeighbors.DNNDetector \u2014 Type . DNNDetector ( d = 0 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false ) Anomaly score based on the number of neighbors in a hypersphere of radius d . Knorr et al. [1] directly converted the resulting outlier scores to labels, thus this implementation does not fully reflect the approach from the paper. Parameters d::Real The hypersphere radius used to calculate the global density of an instance. metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. Examples using OutlierDetection : DNNDetector , fit , score detector = DNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Knorr, Edwin M.; Ng, Raymond T. (1998): Algorithms for Mining Distance-Based Outliers in Large Datasets.","title":"DNNDetector"},{"location":"API/detectors/#knndetector","text":"# OutlierDetectionNeighbors.KNNDetector \u2014 Type . KNNDetector ( k = 5 , metric = Euclidean , algorithm = :kdtree , leafsize = 10 , reorder = true , reduction = :maximum ) Calculate the anomaly score of an instance based on the distance to its k-nearest neighbors. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. reduction::Symbol One of (:maximum, :median, :mean) . ( reduction=:maximum ) was proposed by [1]. Angiulli et al. [2] proposed sum to reduce the distances, but mean has been implemented for numerical stability. Examples using OutlierDetection : KNNDetector , fit , score detector = KNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Ramaswamy, Sridhar; Rastogi, Rajeev; Shim, Kyuseok (2000): Efficient Algorithms for Mining Outliers from Large Data Sets. [2] Angiulli, Fabrizio; Pizzuti, Clara (2002): Fast Outlier Detection in High Dimensional Spaces.","title":"KNNDetector"},{"location":"API/detectors/#lofdetector","text":"# OutlierDetectionNeighbors.LOFDetector \u2014 Type . LOFDetector ( k = 5 , metric = Euclidean (), algorithm = :kdtree , leafsize = 10 , reorder = true , parallel = false ) Calculate an anomaly score based on the density of an instance in comparison to its neighbors. This algorithm introduced the notion of local outliers and was developed by Breunig et al., see [1]. Parameters k::Integer Number of neighbors (must be greater than 0). metric::Metric This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric. algorithm::Symbol One of (:kdtree, :balltree) . In a kdtree , points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric. leafsize::Int Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points. reorder::Bool While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true. parallel::Bool Parallelize score and predict using all threads available. The number of threads can be set with the JULIA_NUM_THREADS environment variable. Note: fit is not parallel. Examples using OutlierDetection : LOFDetector , fit , score detector = LOFDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Breunig, Markus M.; Kriegel, Hans-Peter; Ng, Raymond T.; Sander, J\u00f6rg (2000): LOF: Identifying Density-Based Local Outliers.","title":"LOFDetector"},{"location":"API/detectors/#network-based","text":"Warning The neural-network detectors are experimental and subject to change.","title":"Network-based"},{"location":"API/detectors/#aedetector","text":"# OutlierDetectionNetworks.AEDetector \u2014 Type . AEDetector ( encoder = Chain (), decoder = Chain (), batchsize = 32 , epochs = 1 , shuffle = false , partial = true , opt = ADAM (), loss = mse ) Calculate the anomaly score of an instance based on the reconstruction loss of an autoencoder, see [1] for an explanation of auto encoders. Parameters encoder::Chain Transforms the input data into a latent state with a fixed shape. decoder::Chain Transforms the latent state back into the shape of the input data. batchsize::Integer The number of samples to work through before updating the internal model parameters. epochs::Integer The number of passes of the entire training dataset the machine learning algorithm has completed. shuffle::Bool If shuffle=true , shuffles the observations each time iterations are re-started, else no shuffling is performed. partial::Bool If partial=false , drops the last mini-batch if it is smaller than the batchsize. opt::Any Any Flux-compatibale optimizer, typically a struct that holds all the optimiser parameters along with a definition of apply! that defines how to apply the update rule associated with the optimizer. loss::Function The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples. Examples using OutlierDetection : AEDetector , fit , score detector = AEDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) References [1] Aggarwal, Charu C. (2017): Outlier Analysis.","title":"AEDetector"},{"location":"API/detectors/#dsaddetector","text":"# OutlierDetectionNetworks.DSADDetector \u2014 Type . DSADDetector ( encoder = Chain (), decoder = Chain (), batchsize = 32 , epochs = 1 , shuffle = true , partial = false , opt = ADAM (), loss = mse , eta = 1 , eps = 1e-6 , callback = _ -> () -> ()) Deep Semi-Supervised Anomaly detection technique based on the distance to a hypersphere center as described in [1]. Parameters encoder::Chain Transforms the input data into a latent state with a fixed shape. decoder::Chain Transforms the latent state back into the shape of the input data. batchsize::Integer The number of samples to work through before updating the internal model parameters. epochs::Integer The number of passes of the entire training dataset the machine learning algorithm has completed. shuffle::Bool If shuffle=true , shuffles the observations each time iterations are re-started, else no shuffling is performed. partial::Bool If partial=false , drops the last mini-batch if it is smaller than the batchsize. opt::Any Any Flux-compatibale optimizer, typically a struct that holds all the optimiser parameters along with a definition of apply! that defines how to apply the update rule associated with the optimizer. loss::Function The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples. eta::Real Weighting parameter for the labeled data; i.e. higher values of eta assign higher weight to labeled data in the svdd loss function. For a sensitivity analysis of this parameter, see [1]. eps::Real Because the inverse distance used in the svdd loss can lead to division by zero, the parameters eps is added for numerical stability. callback::Function Experimental parameter that might change . A function to be called after the model parameters have been updated that can call Flux's callback helpers, see https://fluxml.ai/Flux.jl/stable/utilities/#Callback-Helpers-1 . Notice: The parameters batchsize , epochs , shuffle , partial , opt and callback can also be tuples of size 2, specifying the corresponding values for (1) pretraining and (2) training; otherwise the same values are used for pretraining and training. Examples using OutlierDetection : DSADDetector , fit , score detector = DSADDetector () X = rand ( 10 , 100 ) y = rand ([ - 1 , 1 ], 100 ) model = fit ( detector , X , y ) train_scores , test_scores = score ( detector , model , X ) References [1] Ruff, Lukas; Vandermeulen, Robert A.; G\u00f6rnitz, Nico; Binder, Alexander; M\u00fcller, Emmanuel; M\u00fcller, Klaus-Robert; Kloft, Marius (2019): Deep Semi-Supervised Anomaly Detection.","title":"DSADDetector"},{"location":"API/detectors/#esaddetector","text":"# OutlierDetectionNetworks.ESADDetector \u2014 Type . ESADDetector ( encoder = Chain (), decoder = Chain (), batchsize = 32 , epochs = 1 , shuffle = false , partial = true , opt = ADAM (), \u03bb1 = 1 , \u03bb2 = 1 , noise = identity ) End-to-End semi-supervised anomaly detection algorithm similar to DeepSAD, but without the pretraining phase. The algorithm was published by Huang et al., see [1]. Parameters loss::Function The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples. \u03bb1::Real Weighting parameter of the norm loss, which minimizes the empirical variance and thus minimizes entropy. \u03bb2::Real Weighting parameter of the assistent loss function to define the consistency between the two encoders. noise::Function (AbstractArray{T} -> AbstractArray{T}) A function to be applied to a batch of input data to add noise, see [1] for an explanation. Examples using OutlierDetection : ESADDetector , fit , score detector = ESADDetector () X = rand ( 10 , 100 ) y = rand ([ - 1 , 1 ], 100 ) model = fit ( detector , X , y ) train_scores , test_scores = score ( detector , model , X ) References [1] Huang, Chaoqin; Ye, Fei; Zhang, Ya; Wang, Yan-Feng; Tian, Qi (2020): ESAD: End-to-end Deep Semi-supervised Anomaly Detection.","title":"ESADDetector"},{"location":"API/detectors/#python-based","text":"Using PyCall , we can easily integrate existing python outlier detection algorithms. Currently, almost every PyOD algorithm is integrated and can thus be easily used directly from Julia.","title":"Python-based"},{"location":"API/detectors/#aboddetector_1","text":"# OutlierDetectionPython.ABODDetector \u2014 Type . ABODDetector ( n_neighbors = 5 , method = \"fast\" ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.abod","title":"ABODDetector"},{"location":"API/detectors/#cblofdetector","text":"# OutlierDetectionPython.CBLOFDetector \u2014 Type . CBLOFDetector ( n_clusters = 8 , alpha = 0.9 , beta = 5 , use_weights = false , random_state = nothing , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cblof","title":"CBLOFDetector"},{"location":"API/detectors/#cofdetector_1","text":"# OutlierDetectionPython.COFDetector \u2014 Type . COFDetector ( n_neighbors = 5 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cof","title":"COFDetector"},{"location":"API/detectors/#copoddetector","text":"# OutlierDetectionPython.COPODDetector \u2014 Type . COPODDetector () https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.copod","title":"COPODDetector"},{"location":"API/detectors/#hbosdetector","text":"# OutlierDetectionPython.HBOSDetector \u2014 Type . HBOSDetector ( n_bins = 10 , alpha = 0.1 , tol = 0.5 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos","title":"HBOSDetector"},{"location":"API/detectors/#iforestdetector","text":"# OutlierDetectionPython.IForestDetector \u2014 Type . IForestDetector ( n_estimators = 100 , max_samples = \"auto\" , max_features = 1.0 bootstrap = false , behaviour = \"new\" , random_state = nothing , verbose = 0 , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest","title":"IForestDetector"},{"location":"API/detectors/#knndetector_1","text":"# OutlierDetectionPython.KNNDetector \u2014 Type . KNNDetector ( n_neighbors = 5 , method = \"largest\" , radius = 1.0 , algorithm = \"auto\" , leaf_size = 30 , metric = \"minkowski\" , p = 2 , metric_params = nothing , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn","title":"KNNDetector"},{"location":"API/detectors/#lmdddetector","text":"# OutlierDetectionPython.LMDDDetector \u2014 Type . LMDDDetector ( n_iter = 50 , dis_measure = \"aad\" , random_state = nothing ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.lmdd","title":"LMDDDetector"},{"location":"API/detectors/#lodadetector","text":"# OutlierDetectionPython.LODADetector \u2014 Type . LODADetector ( n_bins = 10 , n_random_cuts = 100 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.loda","title":"LODADetector"},{"location":"API/detectors/#lofdetector_1","text":"# OutlierDetectionPython.LOFDetector \u2014 Type . LOFDetector ( n_neighbors = 5 , method = \"largest\" , algorithm = \"auto\" , leaf_size = 30 , metric = \"minkowski\" , p = 2 , metric_params = nothing , n_jobs = 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.lof","title":"LOFDetector"},{"location":"API/detectors/#locidetector","text":"# OutlierDetectionPython.LOCIDetector \u2014 Type . LOCIDetector ( alpha = 0.5 , k = 3 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.loci","title":"LOCIDetector"},{"location":"API/detectors/#mcddetector","text":"# OutlierDetectionPython.MCDDetector \u2014 Type . MCDDetector ( store_precision = true , assume_centered = false , support_fraction = nothing , random_state = nothing ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.mcd","title":"MCDDetector"},{"location":"API/detectors/#ocsvmdetector","text":"# OutlierDetectionPython.OCSVMDetector \u2014 Type . OCSVMDetector ( kernel = \"rbf\" , degree = 3 , gamma = \"auto\" , coef0 = 0.0 , tol = 0.001 , nu = 0.5 , shrinking = true , cache_size = 200 , verbose = false , max_iter = - 1 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.ocsvm","title":"OCSVMDetector"},{"location":"API/detectors/#pcadetector","text":"# OutlierDetectionPython.PCADetector \u2014 Type . PCADetector ( n_components = nothing , n_selected_components = nothing , copy = true , whiten = false , svd_solver = \"auto\" , tol = 0.0 iterated_power = \"auto\" , standardization = true , weighted = true , random_state = nothing ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca","title":"PCADetector"},{"location":"API/detectors/#roddetector","text":"# OutlierDetectionPython.RODDetector \u2014 Type . RODDetector ( parallel_execution = false ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.rod","title":"RODDetector"},{"location":"API/detectors/#soddetector","text":"# OutlierDetectionPython.SODDetector \u2014 Type . SODDetector ( n_neighbors = 5 , ref_set = 10 , alpha = 0.8 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.sod","title":"SODDetector"},{"location":"API/detectors/#sosdetector","text":"# OutlierDetectionPython.SOSDetector \u2014 Type . SOSDetector ( perplexity = 4.5 , metric = \"minkowski\" , eps = 1e-5 ) https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.sos","title":"SOSDetector"},{"location":"API/interface/","text":"Interface Here we define the abstract supertypes that all outlier detectors share as well as useful datatypes use throughout OutlierDetectionJL and the fit and transform methods, that have to be implemented for each detector. Detectors Detector # OutlierDetectionInterface.Detector \u2014 Type . Detector The union type of all detectors, including supervised, semi-supervised and unsupervised detectors. Note: A semi-supervised detector can be seen as a supervised detector with missing labels denoting unlabeled data. SupervisedDetector # OutlierDetectionInterface.SupervisedDetector \u2014 Type . SupervisedDetector This abstract type forms the basis for all implemented supervised outlier detection algorithms. UnsupervisedDetector # OutlierDetectionInterface.UnsupervisedDetector \u2014 Type . UnsupervisedDetector This abstract type forms the basis for all implemented unsupervised outlier detection algorithms. Data types DetectorModel # OutlierDetectionInterface.DetectorModel \u2014 Type . DetectorModel A DetectorModel represents the learned behaviour for specific Detector . This might include parameters in parametric models or other repesentations of the learned data in nonparametric models. In essence, it includes everything required to transform an instance to an outlier score. Scores # OutlierDetectionInterface.Scores \u2014 Type . Scores :: AbstractVector { <: Real } Scores are continuous values, where the range depends on the specific detector yielding the scores. Note: All detectors return increasing scores and higher scores are associated with higher outlierness. Data # OutlierDetectionInterface.Data \u2014 Type . Data :: AbstractArray { <: Real } The raw input data for every detector is defined as AbstractArray{<:Real} and should be a one observation per last dimension in an n-dimensional array. Label # OutlierDetectionInterface.Labels \u2014 Type . Labels :: AbstractVector { <: Union { Missing , String , CategoricalValue { String , <: Integer }}} Labels are used for supervision and evaluation and are defined as an (categorical) vectors of strings. The convention for labels is that \"outlier\" indicates outliers, \"normal\" indicates inliers and missing indicates unlabeled data. Fit # OutlierDetectionInterface.Fit \u2014 Type . Fit :: Tuple { DetectorModel , Scores } A fit results in a learned model of type DetectorModel and the observed training scores of type Scores . Functions fit # OutlierDetectionInterface.fit \u2014 Function . fit ( detector , X , y ; verbosity ) Fit an unsupervised, supervised or semi-supervised outlier detector. That is, learn a DetectorModel from input data X and, in the supervised and semi-supervised setting, labels y . In a supervised setting, the label \"outlier\" represents outliers and \"normal\" inliers. In a semi-supervised setting, missing additionally represents unlabeled data. Note: Unsupervised detectors can be fitted without specifying y . Parameters detector::Detector Any UnsupervisedDetector or SupervisedDetector implementation. X::AbstractArray{<:Real} An array of real values with one observation per last axis. Returns fit::Fit The learned model of the given detector, which contains all the necessary information for later prediction and the achieved outlier scores of the given input data X . Examples using OutlierDetection : KNNDetector , fit , score detector = KNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) transform # OutlierDetectionInterface.transform \u2014 Function . transform ( detector , model , X ) Transform input data X to outlier scores using an UnsupervisedDetector or SupervisedDetector and a corresponding DetectorModel . Parameters detector::Detector Any UnsupervisedDetector or SupervisedDetector implementation. model::DetectorModel The model learned from using fit with a Detector X::AbstractArray{<:Real} An array of real values with one observation per last axis. Returns result::Scores Tuple of the achieved outlier scores of the given train and test data. Examples using OutlierDetection : KNNDetector , fit , score detector = KNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X ) Macros @detector # OutlierDetectionInterface.@detector \u2014 Macro . @detector ( expr ) An alternative to declaring the detector struct, clean! method and keyword constructor, direcly referring to MLJModelInterface.@mlj_model. Parameters expr::Expr An expression of a mutable struct defining a detector's hyperparameters. @default_frontend # OutlierDetectionInterface.@default_frontend \u2014 Macro . @default_frontend ( detector ) Define a data front end for a given detector, which transforms the input data to OutlierDetectionInterface.Data . Parameters detector::T where T<:Detector The detector datatype for which the data frontend should be defined. @default_metadata # OutlierDetectionInterface.@default_metadata \u2014 Macro . @default_metadata ( detector , uuid ) Define the default metadata for a given detector, which is useful when a detector is exported into MLJModels, such that it can be directly loaded with MLJ. By default, we assume that a detector is exported on a package's top-level and we set the load_path accordingly. Additionally, we assume the following metadata defaults: package_name is equal to the @__MODULE__ , where @default_metadata is used The detector is implemented in julia, is_pure_julia=true The detector is no wrapper, is_wrapper=false The package lives in the OutlierDetectionJL github organization Parameters detector::T where T<:Detector The detector datatype for which the data frontend should be defined. uuid::String The UUID of the detector's package.","title":"Interface"},{"location":"API/interface/#interface","text":"Here we define the abstract supertypes that all outlier detectors share as well as useful datatypes use throughout OutlierDetectionJL and the fit and transform methods, that have to be implemented for each detector.","title":"Interface"},{"location":"API/interface/#detectors","text":"","title":"Detectors"},{"location":"API/interface/#detector","text":"# OutlierDetectionInterface.Detector \u2014 Type . Detector The union type of all detectors, including supervised, semi-supervised and unsupervised detectors. Note: A semi-supervised detector can be seen as a supervised detector with missing labels denoting unlabeled data.","title":"Detector"},{"location":"API/interface/#superviseddetector","text":"# OutlierDetectionInterface.SupervisedDetector \u2014 Type . SupervisedDetector This abstract type forms the basis for all implemented supervised outlier detection algorithms.","title":"SupervisedDetector"},{"location":"API/interface/#unsuperviseddetector","text":"# OutlierDetectionInterface.UnsupervisedDetector \u2014 Type . UnsupervisedDetector This abstract type forms the basis for all implemented unsupervised outlier detection algorithms.","title":"UnsupervisedDetector"},{"location":"API/interface/#data-types","text":"","title":"Data types"},{"location":"API/interface/#detectormodel","text":"# OutlierDetectionInterface.DetectorModel \u2014 Type . DetectorModel A DetectorModel represents the learned behaviour for specific Detector . This might include parameters in parametric models or other repesentations of the learned data in nonparametric models. In essence, it includes everything required to transform an instance to an outlier score.","title":"DetectorModel"},{"location":"API/interface/#scores","text":"# OutlierDetectionInterface.Scores \u2014 Type . Scores :: AbstractVector { <: Real } Scores are continuous values, where the range depends on the specific detector yielding the scores. Note: All detectors return increasing scores and higher scores are associated with higher outlierness.","title":"Scores"},{"location":"API/interface/#data","text":"# OutlierDetectionInterface.Data \u2014 Type . Data :: AbstractArray { <: Real } The raw input data for every detector is defined as AbstractArray{<:Real} and should be a one observation per last dimension in an n-dimensional array.","title":"Data"},{"location":"API/interface/#label","text":"# OutlierDetectionInterface.Labels \u2014 Type . Labels :: AbstractVector { <: Union { Missing , String , CategoricalValue { String , <: Integer }}} Labels are used for supervision and evaluation and are defined as an (categorical) vectors of strings. The convention for labels is that \"outlier\" indicates outliers, \"normal\" indicates inliers and missing indicates unlabeled data.","title":"Label"},{"location":"API/interface/#fit","text":"# OutlierDetectionInterface.Fit \u2014 Type . Fit :: Tuple { DetectorModel , Scores } A fit results in a learned model of type DetectorModel and the observed training scores of type Scores .","title":"Fit"},{"location":"API/interface/#functions","text":"","title":"Functions"},{"location":"API/interface/#fit_1","text":"# OutlierDetectionInterface.fit \u2014 Function . fit ( detector , X , y ; verbosity ) Fit an unsupervised, supervised or semi-supervised outlier detector. That is, learn a DetectorModel from input data X and, in the supervised and semi-supervised setting, labels y . In a supervised setting, the label \"outlier\" represents outliers and \"normal\" inliers. In a semi-supervised setting, missing additionally represents unlabeled data. Note: Unsupervised detectors can be fitted without specifying y . Parameters detector::Detector Any UnsupervisedDetector or SupervisedDetector implementation. X::AbstractArray{<:Real} An array of real values with one observation per last axis. Returns fit::Fit The learned model of the given detector, which contains all the necessary information for later prediction and the achieved outlier scores of the given input data X . Examples using OutlierDetection : KNNDetector , fit , score detector = KNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X )","title":"fit"},{"location":"API/interface/#transform","text":"# OutlierDetectionInterface.transform \u2014 Function . transform ( detector , model , X ) Transform input data X to outlier scores using an UnsupervisedDetector or SupervisedDetector and a corresponding DetectorModel . Parameters detector::Detector Any UnsupervisedDetector or SupervisedDetector implementation. model::DetectorModel The model learned from using fit with a Detector X::AbstractArray{<:Real} An array of real values with one observation per last axis. Returns result::Scores Tuple of the achieved outlier scores of the given train and test data. Examples using OutlierDetection : KNNDetector , fit , score detector = KNNDetector () X = rand ( 10 , 100 ) result = fit ( detector , X ) test_scores = transform ( detector , result . model , X )","title":"transform"},{"location":"API/interface/#macros","text":"","title":"Macros"},{"location":"API/interface/#detector_1","text":"# OutlierDetectionInterface.@detector \u2014 Macro . @detector ( expr ) An alternative to declaring the detector struct, clean! method and keyword constructor, direcly referring to MLJModelInterface.@mlj_model. Parameters expr::Expr An expression of a mutable struct defining a detector's hyperparameters.","title":"@detector"},{"location":"API/interface/#default_frontend","text":"# OutlierDetectionInterface.@default_frontend \u2014 Macro . @default_frontend ( detector ) Define a data front end for a given detector, which transforms the input data to OutlierDetectionInterface.Data . Parameters detector::T where T<:Detector The detector datatype for which the data frontend should be defined.","title":"@default_frontend"},{"location":"API/interface/#default_metadata","text":"# OutlierDetectionInterface.@default_metadata \u2014 Macro . @default_metadata ( detector , uuid ) Define the default metadata for a given detector, which is useful when a detector is exported into MLJModels, such that it can be directly loaded with MLJ. By default, we assume that a detector is exported on a package's top-level and we set the load_path accordingly. Additionally, we assume the following metadata defaults: package_name is equal to the @__MODULE__ , where @default_metadata is used The detector is implemented in julia, is_pure_julia=true The detector is no wrapper, is_wrapper=false The package lives in the OutlierDetectionJL github organization Parameters detector::T where T<:Detector The detector datatype for which the data frontend should be defined. uuid::String The UUID of the detector's package.","title":"@default_metadata"},{"location":"API/neural-networks/","text":"Neural Networks OutlierDetectionNetworks contains helpers to generate simple neural-network architectures. Note that the neural-network API is highly experimental and subject to change . Multilayer Perceptron Helpers to construct MLP networks. MLPEncoder # OutlierDetectionNetworks.Templates.MLPEncoder \u2014 Function . MLPEncoder ( in , latent , hidden ; bias ) A MLP encoder with variable number of hidden layers. MLPDecoder # OutlierDetectionNetworks.Templates.MLPDecoder \u2014 Function . MLPDecoder ( in , latent , hidden ; bias ) A MLP decoder with variable number of hidden layers. MLPAutoEncoder # OutlierDetectionNetworks.Templates.MLPAutoEncoder \u2014 Function . MLPAutoEncoder ( in , latent , hidden ; bias ) A MLP auto-encoder with variable number of hidden layers.","title":"Neural Networks"},{"location":"API/neural-networks/#neural-networks","text":"OutlierDetectionNetworks contains helpers to generate simple neural-network architectures. Note that the neural-network API is highly experimental and subject to change .","title":"Neural Networks"},{"location":"API/neural-networks/#multilayer-perceptron","text":"Helpers to construct MLP networks.","title":"Multilayer Perceptron"},{"location":"API/neural-networks/#mlpencoder","text":"# OutlierDetectionNetworks.Templates.MLPEncoder \u2014 Function . MLPEncoder ( in , latent , hidden ; bias ) A MLP encoder with variable number of hidden layers.","title":"MLPEncoder"},{"location":"API/neural-networks/#mlpdecoder","text":"# OutlierDetectionNetworks.Templates.MLPDecoder \u2014 Function . MLPDecoder ( in , latent , hidden ; bias ) A MLP decoder with variable number of hidden layers.","title":"MLPDecoder"},{"location":"API/neural-networks/#mlpautoencoder","text":"# OutlierDetectionNetworks.Templates.MLPAutoEncoder \u2014 Function . MLPAutoEncoder ( in , latent , hidden ; bias ) A MLP auto-encoder with variable number of hidden layers.","title":"MLPAutoEncoder"},{"location":"API/score-helpers/","text":"Score Helpers OutlierDetection.jl provides many useful helper functions to work with outlier scores. The goal of these helpers is to normalize, combine and classify raw outlier scores. The main design philosophy behind all of these functions is that they transform a tuple of train/test scores into some different train/test tuple representation, e.g. train/test classes. Transformers In order to normalize scores or classify them, both the training and testing scores are necessary. We thus provide a helper function called augmented_transform that returns a tuple of training and test scores. Transformers can make use of one or more such train/test tuples to convert them into normalized scores, probabilities or classes. augmented_transform # OutlierDetection.augmented_transform \u2014 Function . augmented_transform ( mach ; rows =: ) Extends transform by additionally returning the training scores from detectors as a train/test score tuple. Parameters mach::MLJ.Machine{<:OD.Detector} A fitted machine with a detector model. rows Test data specified as rows machine-bound data (as in transform ), but could also provide new test data X . Returns augmented_scores::Tuple{AbstractVector{<:Real}, AbstractVector{<:Real}} A tuple of raw training and test scores. source ScoreTransformer # OutlierDetection.ScoreTransformer \u2014 Type . ScoreTransformer ( combine = combine , normalize = normalize ) Transform the results of a single or multiple outlier detection models to combined and normalized scores. Parameters normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See scale_minmax for a specific implementation. combine::Function A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See combine_mean for a specific implementation. source ProbabilisticTransformer # OutlierDetection.ProbabilisticTransformer \u2014 Type . ProbabilisticTransformer ( combine = combine , normalize = normalize ) Transform the results of a single or multiple outlier detection models to combined univariate finite distributions. Parameters normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See scale_minmax for a specific implementation. combine::Function A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See combine_mean for a specific implementation. source DeterministicTransformer # OutlierDetection.DeterministicTransformer \u2014 Type . DeterministicTransformer ( combine = combine , normalize = normalize , classify = classify_quantile ( DEFAULT_THRESHOLD )) Transform the results of a single or multiple outlier detection models to combined categorical values. Parameters normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See scale_minmax for a specific implementation. combine::Function A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See combine_mean for a specific implementation. source Wrappers Wrappers take one or more detectors and transform the (combined) raw scores to probabilities ( ProbabilisticDetector ) or classes ( DeterministicDetector ). Using wrappers, you can easily evaluate outlier detection models with MLJ. CompositeDetector # OutlierDetection.CompositeDetector \u2014 Function . CompositeDetector ( unnamed_detectors ... ; normalize , combine , named_detectors ... ) Transform one or more raw detectors into a single composite detector (that returns raw outlier scores). source ProbabilisticDetector # OutlierDetection.ProbabilisticDetector \u2014 Function . ProbabilisticDetector ( unnamed_detectors ... ; normalize , combine , named_detectors ... ) Transform one or more raw detectors into a single probabilistic detector (that returns outlier probabilities). source DeterministicDetector # OutlierDetection.DeterministicDetector \u2014 Function . DeterministicDetector ( unnamed_detectors ... ; normalize , combine , named_detectors ... ) Transform one or more raw detectors into a single deterministic detector (that returns inlier and outlier classes). source Normalization These functions may be used as an input for the normalize keyword argument present in wrappers and transformers, they transform a tuple of train/test scores into a tuple of normalized train/test scores. scale_minmax # OutlierDetection.scale_minmax \u2014 Function . scale_minmax ( scores ) Transform an array of scores into a range between [0,1] using min-max scaling. Parameters scores::Tuple{Scores, Scores} A tuple consisting of two vectors representing training and test scores. Returns normalized_scores::Tuple{Scores, Scores} The normalized train and test scores. Examples scores_train, scores_test = ([1, 2, 3], [4, 3, 2, 1, 0]) scale_minmax(scores_train, scores_test) # ([0.0, 0.5, 1.0], [1.0, 1.0, 0.5, 0.0, 0.0]) source scale_unify # OutlierDetection.scale_unify \u2014 Function . scale_unify ( scores ) Transform an array of scores into a range between [0,1] using unifying scores as described in [1]. Parameters scores::Tuple{Scores, Scores} A tuple consisting of two vectors representing training and test scores. Returns unified_scores::Tuple{Scores, Scores} The unified train and test scores. Examples scores_train, scores_test = ([1, 2, 3], [4, 3, 2, 1, 0]) unify(scores_train, scores_test) # ([0.0, 0.0, 0.68..], [0.95.., 0.68.., 0.0, 0.0, 0.0]) References Kriegel, Hans-Peter; Kroger, Peer; Schubert, Erich; Zimek, Arthur (2011): Interpreting and Unifying Outlier Scores. source Combination These functions may be used as an input for the combine keyword argument present in wrappers and transformers. The input for the combine functions are one or more train/test score tuples or alternatively a matrix where the first columns represents train scores and the second column test scores. combine_mean # OutlierDetection.combine_mean \u2014 Function . combine_mean ( scores_mat ) Combination method to merge outlier scores from multiple detectors using the mean value of scores. Parameters scores_mat::AbstractMatrix{T} A matrix, with each row representing the scores for a specific instance and each column representing a detector. Returns combined_scores::AbstractVector{T} The combined scores, i.e. column-wise mean. Examples scores = [1 2; 3 4; 5 6] combine_mean(scores) # [1.5, 3.5, 5.5] source combine_median # OutlierDetection.combine_median \u2014 Function . combine_median ( scores_mat ) Combination method to merge outlier scores from multiple detectors using the median value of scores. Parameters scores_mat::AbstractMatrix{T} A matrix, with each row representing the scores for a specific instance and each column representing a detector. Returns combined_scores::AbstractVector{T} The combined scores, i.e. column-wise median. Examples scores = [1 2; 3 4; 5 6] combine_median(scores) # [1.5, 3.5, 5.5] source combine_max # OutlierDetection.combine_max \u2014 Function . combine_max ( scores_mat ) Combination method to merge outlier scores from multiple detectors using the maximum value of scores. Parameters scores_mat::AbstractMatrix{T} A matrix, with each row representing the scores for a specific instance and each column representing a detector. Returns combined_scores::AbstractVector{T} The combined scores, i.e. column-wise maximum. Examples scores = [1 2; 3 4; 5 6] combine_max(scores) # [2, 4, 6] source Classification These functions may be used as an input for the classify keyword argument present in wrappers and transformers, they transform a tuple of train/test scores into a tuple of train/test classes. classify_quantile # OutlierDetection.classify_quantile \u2014 Function . classify_quantile ( threshold ) Create a percentile-based classifiction function that converts scores_train::Scores and scores_test::Scores to an array of classes with \"normal\" indicating normal data and \"outlier\" indicating outliers. The conversion is based on percentiles of the training data, i.e. all datapoints above the threshold percentile are considered outliers. Parameters threshold::Real The score threshold (number between 0 and 1) used to classify the samples into inliers and outliers. scores::Tuple{Scores, Scores} A tuple consisting of two vectors representing training and test scores. Returns classes::AbstractVector{String} The vector of classes consisting of \"outlier\" and \"normal\" elements. Examples classify = classify_quantile(0.9) scores_train, scores_test = ([1, 2, 3], [4, 3, 2]) classify(scores_train, scores_train) # [\"inlier\", \"inlier\", \"outlier\"] classify(scores_train, scores_test) # [\"outlier\", \"outlier\", \"inlier\"] source Output helpers to_univariate_finite # OutlierDetection.to_univariate_finite \u2014 Function . to_univariate_finite ( scores :: Scores ) Convert normalized scores to a vector of univariate finite distributions. Parameters scores::[`Scores`](@ref) Returns fit::UnivariateFiniteVector{OrderedFactor{2}} The learned model of the given detector, which contains all the necessary information for later prediction and the achieved outlier scores of the given input data X . source to_categorical # OutlierDetection.to_categorical \u2014 Function . to_categorical ( classes :: Labels ) Convert a vector of classes (with possible missing values) to a categorical vector. Parameters classes::[`Labels`](@ref) A vector of classes. Returns fit::CategoricalVector{Union{Missing, String},UInt32} The learned model of the given detector, which contains all the necessary information for later prediction and the achieved outlier scores of the given input data X . source from_univariate_finite # OutlierDetection.from_univariate_finite \u2014 Function . raw_scores ( scores ) Extract the raw scores from a vector of univariate finite distributions. Parameters scores::MLJ.UnivariateFiniteVector A vector of univariate finite distributions. Returns scores::[`Scores`](@ref) A vector of raw scores. source from_categorical # OutlierDetection.from_categorical \u2014 Function . raw_scores ( scores ) Extract the raw classes from categorical arrays. Parameters scores::MLJ.CategoricalVector A vector of categorical values. Returns scores::[`Labels`](@ref) A vector of raw classes. source Label helpers outlier_fraction # OutlierDetection.outlier_fraction \u2014 Function . outlier_fraction ( y ) Determine the fraction of outliers in a given vector. Parameters y::Labels An array containing \"normal\" and \"outlier\" classes. Returns outlier_fraction::Float64 The fraction of outliers. source n_normal # OutlierDetection.n_normal \u2014 Function . n_normal ( y ) Determine the amount of normal data points in a given vector. Parameters y::Labels An array containing \"normal\" and \"outlier\" classes. Returns n_normal::Int64 The amount of normal data points. source n_outlier # OutlierDetection.n_outlier \u2014 Function . n_outlier ( y ) Determine the amount of outlier data points in a given vector. Parameters y::Labels An array containing \"normal\" and \"outlier\" classes. Returns outliers::Int64 The amount of outlier data points. source","title":"Score Helpers"},{"location":"API/score-helpers/#score-helpers","text":"OutlierDetection.jl provides many useful helper functions to work with outlier scores. The goal of these helpers is to normalize, combine and classify raw outlier scores. The main design philosophy behind all of these functions is that they transform a tuple of train/test scores into some different train/test tuple representation, e.g. train/test classes.","title":"Score Helpers"},{"location":"API/score-helpers/#transformers","text":"In order to normalize scores or classify them, both the training and testing scores are necessary. We thus provide a helper function called augmented_transform that returns a tuple of training and test scores. Transformers can make use of one or more such train/test tuples to convert them into normalized scores, probabilities or classes.","title":"Transformers"},{"location":"API/score-helpers/#augmented_transform","text":"# OutlierDetection.augmented_transform \u2014 Function . augmented_transform ( mach ; rows =: ) Extends transform by additionally returning the training scores from detectors as a train/test score tuple. Parameters mach::MLJ.Machine{<:OD.Detector} A fitted machine with a detector model. rows Test data specified as rows machine-bound data (as in transform ), but could also provide new test data X . Returns augmented_scores::Tuple{AbstractVector{<:Real}, AbstractVector{<:Real}} A tuple of raw training and test scores. source","title":"augmented_transform"},{"location":"API/score-helpers/#scoretransformer","text":"# OutlierDetection.ScoreTransformer \u2014 Type . ScoreTransformer ( combine = combine , normalize = normalize ) Transform the results of a single or multiple outlier detection models to combined and normalized scores. Parameters normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See scale_minmax for a specific implementation. combine::Function A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See combine_mean for a specific implementation. source","title":"ScoreTransformer"},{"location":"API/score-helpers/#probabilistictransformer","text":"# OutlierDetection.ProbabilisticTransformer \u2014 Type . ProbabilisticTransformer ( combine = combine , normalize = normalize ) Transform the results of a single or multiple outlier detection models to combined univariate finite distributions. Parameters normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See scale_minmax for a specific implementation. combine::Function A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See combine_mean for a specific implementation. source","title":"ProbabilisticTransformer"},{"location":"API/score-helpers/#deterministictransformer","text":"# OutlierDetection.DeterministicTransformer \u2014 Type . DeterministicTransformer ( combine = combine , normalize = normalize , classify = classify_quantile ( DEFAULT_THRESHOLD )) Transform the results of a single or multiple outlier detection models to combined categorical values. Parameters normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See scale_minmax for a specific implementation. combine::Function A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See combine_mean for a specific implementation. source","title":"DeterministicTransformer"},{"location":"API/score-helpers/#wrappers","text":"Wrappers take one or more detectors and transform the (combined) raw scores to probabilities ( ProbabilisticDetector ) or classes ( DeterministicDetector ). Using wrappers, you can easily evaluate outlier detection models with MLJ.","title":"Wrappers"},{"location":"API/score-helpers/#compositedetector","text":"# OutlierDetection.CompositeDetector \u2014 Function . CompositeDetector ( unnamed_detectors ... ; normalize , combine , named_detectors ... ) Transform one or more raw detectors into a single composite detector (that returns raw outlier scores). source","title":"CompositeDetector"},{"location":"API/score-helpers/#probabilisticdetector","text":"# OutlierDetection.ProbabilisticDetector \u2014 Function . ProbabilisticDetector ( unnamed_detectors ... ; normalize , combine , named_detectors ... ) Transform one or more raw detectors into a single probabilistic detector (that returns outlier probabilities). source","title":"ProbabilisticDetector"},{"location":"API/score-helpers/#deterministicdetector","text":"# OutlierDetection.DeterministicDetector \u2014 Function . DeterministicDetector ( unnamed_detectors ... ; normalize , combine , named_detectors ... ) Transform one or more raw detectors into a single deterministic detector (that returns inlier and outlier classes). source","title":"DeterministicDetector"},{"location":"API/score-helpers/#normalization","text":"These functions may be used as an input for the normalize keyword argument present in wrappers and transformers, they transform a tuple of train/test scores into a tuple of normalized train/test scores.","title":"Normalization"},{"location":"API/score-helpers/#scale_minmax","text":"# OutlierDetection.scale_minmax \u2014 Function . scale_minmax ( scores ) Transform an array of scores into a range between [0,1] using min-max scaling. Parameters scores::Tuple{Scores, Scores} A tuple consisting of two vectors representing training and test scores. Returns normalized_scores::Tuple{Scores, Scores} The normalized train and test scores. Examples scores_train, scores_test = ([1, 2, 3], [4, 3, 2, 1, 0]) scale_minmax(scores_train, scores_test) # ([0.0, 0.5, 1.0], [1.0, 1.0, 0.5, 0.0, 0.0]) source","title":"scale_minmax"},{"location":"API/score-helpers/#scale_unify","text":"# OutlierDetection.scale_unify \u2014 Function . scale_unify ( scores ) Transform an array of scores into a range between [0,1] using unifying scores as described in [1]. Parameters scores::Tuple{Scores, Scores} A tuple consisting of two vectors representing training and test scores. Returns unified_scores::Tuple{Scores, Scores} The unified train and test scores. Examples scores_train, scores_test = ([1, 2, 3], [4, 3, 2, 1, 0]) unify(scores_train, scores_test) # ([0.0, 0.0, 0.68..], [0.95.., 0.68.., 0.0, 0.0, 0.0]) References Kriegel, Hans-Peter; Kroger, Peer; Schubert, Erich; Zimek, Arthur (2011): Interpreting and Unifying Outlier Scores. source","title":"scale_unify"},{"location":"API/score-helpers/#combination","text":"These functions may be used as an input for the combine keyword argument present in wrappers and transformers. The input for the combine functions are one or more train/test score tuples or alternatively a matrix where the first columns represents train scores and the second column test scores.","title":"Combination"},{"location":"API/score-helpers/#combine_mean","text":"# OutlierDetection.combine_mean \u2014 Function . combine_mean ( scores_mat ) Combination method to merge outlier scores from multiple detectors using the mean value of scores. Parameters scores_mat::AbstractMatrix{T} A matrix, with each row representing the scores for a specific instance and each column representing a detector. Returns combined_scores::AbstractVector{T} The combined scores, i.e. column-wise mean. Examples scores = [1 2; 3 4; 5 6] combine_mean(scores) # [1.5, 3.5, 5.5] source","title":"combine_mean"},{"location":"API/score-helpers/#combine_median","text":"# OutlierDetection.combine_median \u2014 Function . combine_median ( scores_mat ) Combination method to merge outlier scores from multiple detectors using the median value of scores. Parameters scores_mat::AbstractMatrix{T} A matrix, with each row representing the scores for a specific instance and each column representing a detector. Returns combined_scores::AbstractVector{T} The combined scores, i.e. column-wise median. Examples scores = [1 2; 3 4; 5 6] combine_median(scores) # [1.5, 3.5, 5.5] source","title":"combine_median"},{"location":"API/score-helpers/#combine_max","text":"# OutlierDetection.combine_max \u2014 Function . combine_max ( scores_mat ) Combination method to merge outlier scores from multiple detectors using the maximum value of scores. Parameters scores_mat::AbstractMatrix{T} A matrix, with each row representing the scores for a specific instance and each column representing a detector. Returns combined_scores::AbstractVector{T} The combined scores, i.e. column-wise maximum. Examples scores = [1 2; 3 4; 5 6] combine_max(scores) # [2, 4, 6] source","title":"combine_max"},{"location":"API/score-helpers/#classification","text":"These functions may be used as an input for the classify keyword argument present in wrappers and transformers, they transform a tuple of train/test scores into a tuple of train/test classes.","title":"Classification"},{"location":"API/score-helpers/#classify_quantile","text":"# OutlierDetection.classify_quantile \u2014 Function . classify_quantile ( threshold ) Create a percentile-based classifiction function that converts scores_train::Scores and scores_test::Scores to an array of classes with \"normal\" indicating normal data and \"outlier\" indicating outliers. The conversion is based on percentiles of the training data, i.e. all datapoints above the threshold percentile are considered outliers. Parameters threshold::Real The score threshold (number between 0 and 1) used to classify the samples into inliers and outliers. scores::Tuple{Scores, Scores} A tuple consisting of two vectors representing training and test scores. Returns classes::AbstractVector{String} The vector of classes consisting of \"outlier\" and \"normal\" elements. Examples classify = classify_quantile(0.9) scores_train, scores_test = ([1, 2, 3], [4, 3, 2]) classify(scores_train, scores_train) # [\"inlier\", \"inlier\", \"outlier\"] classify(scores_train, scores_test) # [\"outlier\", \"outlier\", \"inlier\"] source","title":"classify_quantile"},{"location":"API/score-helpers/#output-helpers","text":"","title":"Output helpers"},{"location":"API/score-helpers/#to_univariate_finite","text":"# OutlierDetection.to_univariate_finite \u2014 Function . to_univariate_finite ( scores :: Scores ) Convert normalized scores to a vector of univariate finite distributions. Parameters scores::[`Scores`](@ref) Returns fit::UnivariateFiniteVector{OrderedFactor{2}} The learned model of the given detector, which contains all the necessary information for later prediction and the achieved outlier scores of the given input data X . source","title":"to_univariate_finite"},{"location":"API/score-helpers/#to_categorical","text":"# OutlierDetection.to_categorical \u2014 Function . to_categorical ( classes :: Labels ) Convert a vector of classes (with possible missing values) to a categorical vector. Parameters classes::[`Labels`](@ref) A vector of classes. Returns fit::CategoricalVector{Union{Missing, String},UInt32} The learned model of the given detector, which contains all the necessary information for later prediction and the achieved outlier scores of the given input data X . source","title":"to_categorical"},{"location":"API/score-helpers/#from_univariate_finite","text":"# OutlierDetection.from_univariate_finite \u2014 Function . raw_scores ( scores ) Extract the raw scores from a vector of univariate finite distributions. Parameters scores::MLJ.UnivariateFiniteVector A vector of univariate finite distributions. Returns scores::[`Scores`](@ref) A vector of raw scores. source","title":"from_univariate_finite"},{"location":"API/score-helpers/#from_categorical","text":"# OutlierDetection.from_categorical \u2014 Function . raw_scores ( scores ) Extract the raw classes from categorical arrays. Parameters scores::MLJ.CategoricalVector A vector of categorical values. Returns scores::[`Labels`](@ref) A vector of raw classes. source","title":"from_categorical"},{"location":"API/score-helpers/#label-helpers","text":"","title":"Label helpers"},{"location":"API/score-helpers/#outlier_fraction","text":"# OutlierDetection.outlier_fraction \u2014 Function . outlier_fraction ( y ) Determine the fraction of outliers in a given vector. Parameters y::Labels An array containing \"normal\" and \"outlier\" classes. Returns outlier_fraction::Float64 The fraction of outliers. source","title":"outlier_fraction"},{"location":"API/score-helpers/#n_normal","text":"# OutlierDetection.n_normal \u2014 Function . n_normal ( y ) Determine the amount of normal data points in a given vector. Parameters y::Labels An array containing \"normal\" and \"outlier\" classes. Returns n_normal::Int64 The amount of normal data points. source","title":"n_normal"},{"location":"API/score-helpers/#n_outlier","text":"# OutlierDetection.n_outlier \u2014 Function . n_outlier ( y ) Determine the amount of outlier data points in a given vector. Parameters y::Labels An array containing \"normal\" and \"outlier\" classes. Returns outliers::Int64 The amount of outlier data points. source","title":"n_outlier"},{"location":"documentation/advanced-usage/","text":"Advanced Usage The simple usage guide covered how you can use and optimize an existing outlier detection model, however, sometimes it is necessary to combine the results of multiple models or create entirely new models. Working with scores An outlier detection model, whether supervised or unsupervised, typically assigns an outlier score to each datapoint. We further differentiate between outier scores achieved during training or testing . Because both train and test scores are essential for further score processing, e.g. converting the scores to classes, we provide an augmented_transform that returns a tuple of train and test scores. using MLJ , OutlierDetection using OutlierDetectionData : ODDS X , y = ODDS . load ( \"annthyroid\" ) train , test = partition ( eachindex ( y ), 0.5 , shuffle = true , stratify = y , rng = 0 ) KNN = @iload KNNDetector pkg = OutlierDetectionNeighbors verbosity = 0 knn = KNN () KNNDetector( k = 5, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum) Let's bind the detector to data and perform an augmented_transform . mach = machine ( knn , X , y ) fit! ( mach , rows = train ) scores = augmented_transform ( mach , rows = test ) scores_train , scores_test = scores ([0.015809329524050033, 0.01227884359375915, 0.0459156835950419, 0.020099952736262826, 0.013580868897091973, 0.021063000735887565, 0.014748030376968972, 0.012825447360618655, 0.03674629232997528, 0.005899999999999996 \u2026 0.01025134137564445, 0.01916101249934356, 0.01497412434835507, 0.015076140089558737, 0.01764709607839205, 0.06715745751590065, 0.014039804129687852, 0.010630785483678995, 0.02923597783553682, 0.02754246902512554], [0.007383319036855991, 0.012256920494153502, 0.017696609844826204, 0.024054440338532098, 0.015375304875026054, 0.023503616742961086, 0.01673977598416418, 0.010000000000000009, 0.028750652166516153, 0.008564864272129474 \u2026 0.012658597868642494, 0.010416544532617329, 0.017795867497820923, 0.04766550115125195, 0.012879689437249653, 0.021236292049225534, 0.013329906226226798, 0.03016661068134767, 0.006801698317332226, 0.10986355173577815]) We split the into 50% train and 50% test data, thus scores_train and scores_test should return an equal amount of scores. scores_train 3600-element Vector{Float64}: 0.015809329524050033 0.01227884359375915 0.0459156835950419 0.020099952736262826 0.013580868897091973 0.021063000735887565 0.014748030376968972 0.012825447360618655 0.03674629232997528 0.005899999999999996 \u22ee 0.01916101249934356 0.01497412434835507 0.015076140089558737 0.01764709607839205 0.06715745751590065 0.014039804129687852 0.010630785483678995 0.02923597783553682 0.02754246902512554 scores_test 3600-element Vector{Float64}: 0.007383319036855991 0.012256920494153502 0.017696609844826204 0.024054440338532098 0.015375304875026054 0.023503616742961086 0.01673977598416418 0.010000000000000009 0.028750652166516153 0.008564864272129474 \u22ee 0.010416544532617329 0.017795867497820923 0.04766550115125195 0.012879689437249653 0.021236292049225534 0.013329906226226798 0.03016661068134767 0.006801698317332226 0.10986355173577815 OutlierDetection.jl provides many helper functions to work with scores, see score helpers . The fundamental datatype to work with scores is a tuple of train/test scores and all helper functions work with this datatype. An example for such a helper function is scale_minmax , which scales the scores to lie between 0 and 1 using min-max scaling. last ( scores |> scale_minmax ) 3600-element Vector{Float64}: 0.009915879968108363 0.02187720506179054 0.03522788490341164 0.05083196703693757 0.029530684664811027 0.04948007559615709 0.032879518717070275 0.01633802423674759 0.062357923124135045 0.0128157573577204 \u22ee 0.01736035333244564 0.0354714938783983 0.10878081177982465 0.023405672633850193 0.0439153596479345 0.02451064385949808 0.0658331231919836 0.008488402861413877 0.2614340621027081 Another exemplary helper function is classify_quantile , which is used to transform scores to classes. We only display the test scores using the last element of the tuple. last ( scores |> classify_quantile ( 0.9 )) 3600-element Vector{String}: \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \u22ee \"normal\" \"normal\" \"outlier\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"outlier\" Sometimes it's also necessary to combine scores from multiple detectors, which can, for example, be achieved with combine_mean . combine_mean ( scores , scores ) == scores true We can see that combine_mean can work with multiple train/test tuples and combines them into one final tuple. In this case the resulting tuple consists of the means of the individual train and test score vectors. Combining models We typically want to deal with probabilistic or deterministic predictions instead of raw scores. Using a ProbabilisticDetector or DeterministicDetector , we can simply wrap a detector to enable such predictions. Both wrappers, however, are designed such that they can work with multiple models and combine them into one probabilistic or deterministic result. When using multiple models, we have to provide them as keyword arguments as follows. knn = ProbabilisticDetector ( knn1 = KNN ( k = 5 ), knn2 = KNN ( k = 10 ), normalize = scale_minmax , combine = combine_mean ) ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, knn1 = KNNDetector( k = 5, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum), knn2 = KNNDetector( k = 10, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum)) As you can see, we additionally provided explicit arguments to normalize and combine , which take function arguments and are used for score normalization and combination. Those are the default, thus we could have also just left them unspecified and achieved the same result. The scores are always normalized before they are combined. Notice that any function that maps a train/test score tuple to a score tuple with values in the range [0,1] works for normalization . For example, if the scores are already in the range [0,1] we could just pass the identity function. Let's see the predictions of the defined detector. mach = machine ( knn , X , y ) fit! ( mach , rows = train ) predict ( mach , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.991, outlier=>0.00914) UnivariateFinite{OrderedFactor{2}}(normal=>0.978, outlier=>0.0224) UnivariateFinite{OrderedFactor{2}}(normal=>0.963, outlier=>0.0365) UnivariateFinite{OrderedFactor{2}}(normal=>0.953, outlier=>0.0465) UnivariateFinite{OrderedFactor{2}}(normal=>0.975, outlier=>0.0247) UnivariateFinite{OrderedFactor{2}}(normal=>0.951, outlier=>0.0485) UnivariateFinite{OrderedFactor{2}}(normal=>0.966, outlier=>0.0344) UnivariateFinite{OrderedFactor{2}}(normal=>0.989, outlier=>0.0114) UnivariateFinite{OrderedFactor{2}}(normal=>0.942, outlier=>0.0578) UnivariateFinite{OrderedFactor{2}}(normal=>0.989, outlier=>0.0115) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.985, outlier=>0.0151) UnivariateFinite{OrderedFactor{2}}(normal=>0.97, outlier=>0.03) UnivariateFinite{OrderedFactor{2}}(normal=>0.894, outlier=>0.106) UnivariateFinite{OrderedFactor{2}}(normal=>0.98, outlier=>0.0201) UnivariateFinite{OrderedFactor{2}}(normal=>0.956, outlier=>0.0444) UnivariateFinite{OrderedFactor{2}}(normal=>0.974, outlier=>0.0262) UnivariateFinite{OrderedFactor{2}}(normal=>0.939, outlier=>0.0606) UnivariateFinite{OrderedFactor{2}}(normal=>0.991, outlier=>0.00866) UnivariateFinite{OrderedFactor{2}}(normal=>0.748, outlier=>0.252) Pretty simple, huh? Learning networks Sometimes we need more flexibility to define outlier models. Unfortunately MLJ's linear pipelines are not yet usable for outlier detection models, thus we need to define our learning networks manually. Let's, for example, create a machine that standardizes the input features before applying the detector. Xs , ys = source ( X ), source ( y ) Xstd = transform ( machine ( Standardizer (), Xs ), Xs ) y\u0302 = predict ( machine ( knn , Xstd ), Xstd ) knn_std = machine ( ProbabilisticUnsupervisedDetector (), Xs , ys ; predict = y\u0302 ) Machine{ProbabilisticUnsupervisedDetectorSurrogate,\u2026} trained 0 times; does not cache data args: 1: Source @370 \u23ce `Table{AbstractVector{Continuous}}` 2: Source @643 \u23ce `AbstractVector{OrderedFactor{2}}` We can fit! and predict with the resulting model as usual. fit! ( knn_std , rows = train ) predict ( knn_std , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.988, outlier=>0.0116) UnivariateFinite{OrderedFactor{2}}(normal=>0.977, outlier=>0.0229) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0359) UnivariateFinite{OrderedFactor{2}}(normal=>0.958, outlier=>0.0417) UnivariateFinite{OrderedFactor{2}}(normal=>0.971, outlier=>0.029) UnivariateFinite{OrderedFactor{2}}(normal=>0.945, outlier=>0.0551) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0362) UnivariateFinite{OrderedFactor{2}}(normal=>0.997, outlier=>0.00341) UnivariateFinite{OrderedFactor{2}}(normal=>0.937, outlier=>0.0629) UnivariateFinite{OrderedFactor{2}}(normal=>0.975, outlier=>0.0247) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.986, outlier=>0.0142) UnivariateFinite{OrderedFactor{2}}(normal=>0.955, outlier=>0.0451) UnivariateFinite{OrderedFactor{2}}(normal=>0.888, outlier=>0.112) UnivariateFinite{OrderedFactor{2}}(normal=>0.961, outlier=>0.0386) UnivariateFinite{OrderedFactor{2}}(normal=>0.962, outlier=>0.0376) UnivariateFinite{OrderedFactor{2}}(normal=>0.97, outlier=>0.0301) UnivariateFinite{OrderedFactor{2}}(normal=>0.953, outlier=>0.0471) UnivariateFinite{OrderedFactor{2}}(normal=>0.987, outlier=>0.0129) UnivariateFinite{OrderedFactor{2}}(normal=>0.786, outlier=>0.214) Note that we supplied labels ys to an unsupervised algorithm; this is not necessary if you just want to predict, but it is necessary if you want to evaluate the resulting learning network . We can easily export such a learning network as a model with @from_network . @from_network knn_std mutable struct StandardizedKNN end Furthermore, if the goal is to create a standalone model from a network, we could use empty sources ( source() ) for Xs and ys . The standalone model can be bound to data again like any other model. knn_std = machine ( StandardizedKNN (), X , y ) fit! ( knn_std , rows = train ) predict ( knn_std , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.988, outlier=>0.0116) UnivariateFinite{OrderedFactor{2}}(normal=>0.977, outlier=>0.0229) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0359) UnivariateFinite{OrderedFactor{2}}(normal=>0.958, outlier=>0.0417) UnivariateFinite{OrderedFactor{2}}(normal=>0.971, outlier=>0.029) UnivariateFinite{OrderedFactor{2}}(normal=>0.945, outlier=>0.0551) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0362) UnivariateFinite{OrderedFactor{2}}(normal=>0.997, outlier=>0.00341) UnivariateFinite{OrderedFactor{2}}(normal=>0.937, outlier=>0.0629) UnivariateFinite{OrderedFactor{2}}(normal=>0.975, outlier=>0.0247) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.986, outlier=>0.0142) UnivariateFinite{OrderedFactor{2}}(normal=>0.955, outlier=>0.0451) UnivariateFinite{OrderedFactor{2}}(normal=>0.888, outlier=>0.112) UnivariateFinite{OrderedFactor{2}}(normal=>0.961, outlier=>0.0386) UnivariateFinite{OrderedFactor{2}}(normal=>0.962, outlier=>0.0376) UnivariateFinite{OrderedFactor{2}}(normal=>0.97, outlier=>0.0301) UnivariateFinite{OrderedFactor{2}}(normal=>0.953, outlier=>0.0471) UnivariateFinite{OrderedFactor{2}}(normal=>0.987, outlier=>0.0129) UnivariateFinite{OrderedFactor{2}}(normal=>0.786, outlier=>0.214) There might be occasions, where our ProbabilisticDetector or DeterministicDetector wrappers are not flexible enough. In such cases we can directly use augmented_transform in our learning networks and use a ProbabilisticTransformer or DeterministicTransformer , which takes one or more train/test tuples as inputs returning probabilistic or deterministic predictions. Implementing models Learning networks let us flexibly create complex combinations of existing models , however, sometimes it's necessary to develop new outlier detection models for specific tasks. OutlierDetection.jl builds on top of MLJ and provides a simple interface defining how an outlier detection algorithm can be implemented. Let's first import the interface and the packages relevant to our new algorithm. import OutlierDetectionInterface const OD = OutlierDetectionInterface using Statistics : mean using LinearAlgebra : norm Our proposed algorithm calculates a central point from the training data and defines an outlier as a point that's far away from that center. The only hyperparameter is p specifying which p-norm to use to calculate the distance. Using @detector , which replicates @mlj_model , we can define our detector struct with macro-generated keyword arguments and default values. OD . @detector mutable struct SimpleDetector <: OD . UnsupervisedDetector p :: Float64 = 2 end Our DetectorModel , then, defines the learned parameters of our model. In this case the only learned parameter is the center. struct SimpleModel <: OD . DetectorModel center :: AbstractArray { <: Real } end Let's further define a helper function to calculate the distance from the center. function distances_from ( center , vectors :: AbstractMatrix , p ) deviations = vectors .- center return [ norm ( deviations [ : , i ], p ) for i in 1 : size ( deviations , 2 )] end distances_from (generic function with 1 method) Finally, we can implement the two methods necessary to implement a detector, namely fit and transform . Please refer to the Key Concepts to learn more about the involved methods and types. function OD . fit ( detector :: SimpleDetector , X :: OD . Data ; verbosity ) :: OD . Fit center = mean ( X , dims = 2 ) training_scores = distances_from ( center , X , detector . p ) return SimpleModel ( center ), training_scores end function OD . transform ( detector :: SimpleDetector , model :: SimpleModel , X :: OD . Data ) :: OD . Scores distances_from ( model . center , X , detector . p ) end Using a data-frontend, we can make sure that MLJ internally transforms input data to Data , which refers to column-major Julia arrays with the last dimension representing an example. Registering that frontend can be achieved with @default_frontend . OD . @default_frontend SimpleDetector Again, we can simply wrap our detector in a ProbabilisticDetector to enable probabilistic predictions. sd = machine ( ProbabilisticDetector ( SimpleDetector ()), X , y ) fit! ( sd , rows = train ) predict ( sd , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.903, outlier=>0.0972) UnivariateFinite{OrderedFactor{2}}(normal=>0.874, outlier=>0.126) UnivariateFinite{OrderedFactor{2}}(normal=>0.917, outlier=>0.0826) UnivariateFinite{OrderedFactor{2}}(normal=>0.564, outlier=>0.436) UnivariateFinite{OrderedFactor{2}}(normal=>0.67, outlier=>0.33) UnivariateFinite{OrderedFactor{2}}(normal=>0.531, outlier=>0.469) UnivariateFinite{OrderedFactor{2}}(normal=>0.832, outlier=>0.168) UnivariateFinite{OrderedFactor{2}}(normal=>0.729, outlier=>0.271) UnivariateFinite{OrderedFactor{2}}(normal=>0.677, outlier=>0.323) UnivariateFinite{OrderedFactor{2}}(normal=>0.688, outlier=>0.312) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.874, outlier=>0.126) UnivariateFinite{OrderedFactor{2}}(normal=>0.742, outlier=>0.258) UnivariateFinite{OrderedFactor{2}}(normal=>0.816, outlier=>0.184) UnivariateFinite{OrderedFactor{2}}(normal=>0.713, outlier=>0.287) UnivariateFinite{OrderedFactor{2}}(normal=>0.564, outlier=>0.436) UnivariateFinite{OrderedFactor{2}}(normal=>0.932, outlier=>0.0679) UnivariateFinite{OrderedFactor{2}}(normal=>0.631, outlier=>0.369) UnivariateFinite{OrderedFactor{2}}(normal=>0.526, outlier=>0.474) UnivariateFinite{OrderedFactor{2}}(normal=>0.408, outlier=>0.592) Remember: Your feedback and contributions are extremely welcome, join us on Github or #outlierdetection on Slack and get involved.","title":"Advanced Usage"},{"location":"documentation/advanced-usage/#advanced-usage","text":"The simple usage guide covered how you can use and optimize an existing outlier detection model, however, sometimes it is necessary to combine the results of multiple models or create entirely new models.","title":"Advanced Usage"},{"location":"documentation/advanced-usage/#working-with-scores","text":"An outlier detection model, whether supervised or unsupervised, typically assigns an outlier score to each datapoint. We further differentiate between outier scores achieved during training or testing . Because both train and test scores are essential for further score processing, e.g. converting the scores to classes, we provide an augmented_transform that returns a tuple of train and test scores. using MLJ , OutlierDetection using OutlierDetectionData : ODDS X , y = ODDS . load ( \"annthyroid\" ) train , test = partition ( eachindex ( y ), 0.5 , shuffle = true , stratify = y , rng = 0 ) KNN = @iload KNNDetector pkg = OutlierDetectionNeighbors verbosity = 0 knn = KNN () KNNDetector( k = 5, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum) Let's bind the detector to data and perform an augmented_transform . mach = machine ( knn , X , y ) fit! ( mach , rows = train ) scores = augmented_transform ( mach , rows = test ) scores_train , scores_test = scores ([0.015809329524050033, 0.01227884359375915, 0.0459156835950419, 0.020099952736262826, 0.013580868897091973, 0.021063000735887565, 0.014748030376968972, 0.012825447360618655, 0.03674629232997528, 0.005899999999999996 \u2026 0.01025134137564445, 0.01916101249934356, 0.01497412434835507, 0.015076140089558737, 0.01764709607839205, 0.06715745751590065, 0.014039804129687852, 0.010630785483678995, 0.02923597783553682, 0.02754246902512554], [0.007383319036855991, 0.012256920494153502, 0.017696609844826204, 0.024054440338532098, 0.015375304875026054, 0.023503616742961086, 0.01673977598416418, 0.010000000000000009, 0.028750652166516153, 0.008564864272129474 \u2026 0.012658597868642494, 0.010416544532617329, 0.017795867497820923, 0.04766550115125195, 0.012879689437249653, 0.021236292049225534, 0.013329906226226798, 0.03016661068134767, 0.006801698317332226, 0.10986355173577815]) We split the into 50% train and 50% test data, thus scores_train and scores_test should return an equal amount of scores. scores_train 3600-element Vector{Float64}: 0.015809329524050033 0.01227884359375915 0.0459156835950419 0.020099952736262826 0.013580868897091973 0.021063000735887565 0.014748030376968972 0.012825447360618655 0.03674629232997528 0.005899999999999996 \u22ee 0.01916101249934356 0.01497412434835507 0.015076140089558737 0.01764709607839205 0.06715745751590065 0.014039804129687852 0.010630785483678995 0.02923597783553682 0.02754246902512554 scores_test 3600-element Vector{Float64}: 0.007383319036855991 0.012256920494153502 0.017696609844826204 0.024054440338532098 0.015375304875026054 0.023503616742961086 0.01673977598416418 0.010000000000000009 0.028750652166516153 0.008564864272129474 \u22ee 0.010416544532617329 0.017795867497820923 0.04766550115125195 0.012879689437249653 0.021236292049225534 0.013329906226226798 0.03016661068134767 0.006801698317332226 0.10986355173577815 OutlierDetection.jl provides many helper functions to work with scores, see score helpers . The fundamental datatype to work with scores is a tuple of train/test scores and all helper functions work with this datatype. An example for such a helper function is scale_minmax , which scales the scores to lie between 0 and 1 using min-max scaling. last ( scores |> scale_minmax ) 3600-element Vector{Float64}: 0.009915879968108363 0.02187720506179054 0.03522788490341164 0.05083196703693757 0.029530684664811027 0.04948007559615709 0.032879518717070275 0.01633802423674759 0.062357923124135045 0.0128157573577204 \u22ee 0.01736035333244564 0.0354714938783983 0.10878081177982465 0.023405672633850193 0.0439153596479345 0.02451064385949808 0.0658331231919836 0.008488402861413877 0.2614340621027081 Another exemplary helper function is classify_quantile , which is used to transform scores to classes. We only display the test scores using the last element of the tuple. last ( scores |> classify_quantile ( 0.9 )) 3600-element Vector{String}: \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \u22ee \"normal\" \"normal\" \"outlier\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"outlier\" Sometimes it's also necessary to combine scores from multiple detectors, which can, for example, be achieved with combine_mean . combine_mean ( scores , scores ) == scores true We can see that combine_mean can work with multiple train/test tuples and combines them into one final tuple. In this case the resulting tuple consists of the means of the individual train and test score vectors.","title":"Working with scores"},{"location":"documentation/advanced-usage/#combining-models","text":"We typically want to deal with probabilistic or deterministic predictions instead of raw scores. Using a ProbabilisticDetector or DeterministicDetector , we can simply wrap a detector to enable such predictions. Both wrappers, however, are designed such that they can work with multiple models and combine them into one probabilistic or deterministic result. When using multiple models, we have to provide them as keyword arguments as follows. knn = ProbabilisticDetector ( knn1 = KNN ( k = 5 ), knn2 = KNN ( k = 10 ), normalize = scale_minmax , combine = combine_mean ) ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, knn1 = KNNDetector( k = 5, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum), knn2 = KNNDetector( k = 10, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum)) As you can see, we additionally provided explicit arguments to normalize and combine , which take function arguments and are used for score normalization and combination. Those are the default, thus we could have also just left them unspecified and achieved the same result. The scores are always normalized before they are combined. Notice that any function that maps a train/test score tuple to a score tuple with values in the range [0,1] works for normalization . For example, if the scores are already in the range [0,1] we could just pass the identity function. Let's see the predictions of the defined detector. mach = machine ( knn , X , y ) fit! ( mach , rows = train ) predict ( mach , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.991, outlier=>0.00914) UnivariateFinite{OrderedFactor{2}}(normal=>0.978, outlier=>0.0224) UnivariateFinite{OrderedFactor{2}}(normal=>0.963, outlier=>0.0365) UnivariateFinite{OrderedFactor{2}}(normal=>0.953, outlier=>0.0465) UnivariateFinite{OrderedFactor{2}}(normal=>0.975, outlier=>0.0247) UnivariateFinite{OrderedFactor{2}}(normal=>0.951, outlier=>0.0485) UnivariateFinite{OrderedFactor{2}}(normal=>0.966, outlier=>0.0344) UnivariateFinite{OrderedFactor{2}}(normal=>0.989, outlier=>0.0114) UnivariateFinite{OrderedFactor{2}}(normal=>0.942, outlier=>0.0578) UnivariateFinite{OrderedFactor{2}}(normal=>0.989, outlier=>0.0115) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.985, outlier=>0.0151) UnivariateFinite{OrderedFactor{2}}(normal=>0.97, outlier=>0.03) UnivariateFinite{OrderedFactor{2}}(normal=>0.894, outlier=>0.106) UnivariateFinite{OrderedFactor{2}}(normal=>0.98, outlier=>0.0201) UnivariateFinite{OrderedFactor{2}}(normal=>0.956, outlier=>0.0444) UnivariateFinite{OrderedFactor{2}}(normal=>0.974, outlier=>0.0262) UnivariateFinite{OrderedFactor{2}}(normal=>0.939, outlier=>0.0606) UnivariateFinite{OrderedFactor{2}}(normal=>0.991, outlier=>0.00866) UnivariateFinite{OrderedFactor{2}}(normal=>0.748, outlier=>0.252) Pretty simple, huh?","title":"Combining models"},{"location":"documentation/advanced-usage/#learning-networks","text":"Sometimes we need more flexibility to define outlier models. Unfortunately MLJ's linear pipelines are not yet usable for outlier detection models, thus we need to define our learning networks manually. Let's, for example, create a machine that standardizes the input features before applying the detector. Xs , ys = source ( X ), source ( y ) Xstd = transform ( machine ( Standardizer (), Xs ), Xs ) y\u0302 = predict ( machine ( knn , Xstd ), Xstd ) knn_std = machine ( ProbabilisticUnsupervisedDetector (), Xs , ys ; predict = y\u0302 ) Machine{ProbabilisticUnsupervisedDetectorSurrogate,\u2026} trained 0 times; does not cache data args: 1: Source @370 \u23ce `Table{AbstractVector{Continuous}}` 2: Source @643 \u23ce `AbstractVector{OrderedFactor{2}}` We can fit! and predict with the resulting model as usual. fit! ( knn_std , rows = train ) predict ( knn_std , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.988, outlier=>0.0116) UnivariateFinite{OrderedFactor{2}}(normal=>0.977, outlier=>0.0229) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0359) UnivariateFinite{OrderedFactor{2}}(normal=>0.958, outlier=>0.0417) UnivariateFinite{OrderedFactor{2}}(normal=>0.971, outlier=>0.029) UnivariateFinite{OrderedFactor{2}}(normal=>0.945, outlier=>0.0551) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0362) UnivariateFinite{OrderedFactor{2}}(normal=>0.997, outlier=>0.00341) UnivariateFinite{OrderedFactor{2}}(normal=>0.937, outlier=>0.0629) UnivariateFinite{OrderedFactor{2}}(normal=>0.975, outlier=>0.0247) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.986, outlier=>0.0142) UnivariateFinite{OrderedFactor{2}}(normal=>0.955, outlier=>0.0451) UnivariateFinite{OrderedFactor{2}}(normal=>0.888, outlier=>0.112) UnivariateFinite{OrderedFactor{2}}(normal=>0.961, outlier=>0.0386) UnivariateFinite{OrderedFactor{2}}(normal=>0.962, outlier=>0.0376) UnivariateFinite{OrderedFactor{2}}(normal=>0.97, outlier=>0.0301) UnivariateFinite{OrderedFactor{2}}(normal=>0.953, outlier=>0.0471) UnivariateFinite{OrderedFactor{2}}(normal=>0.987, outlier=>0.0129) UnivariateFinite{OrderedFactor{2}}(normal=>0.786, outlier=>0.214) Note that we supplied labels ys to an unsupervised algorithm; this is not necessary if you just want to predict, but it is necessary if you want to evaluate the resulting learning network . We can easily export such a learning network as a model with @from_network . @from_network knn_std mutable struct StandardizedKNN end Furthermore, if the goal is to create a standalone model from a network, we could use empty sources ( source() ) for Xs and ys . The standalone model can be bound to data again like any other model. knn_std = machine ( StandardizedKNN (), X , y ) fit! ( knn_std , rows = train ) predict ( knn_std , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.988, outlier=>0.0116) UnivariateFinite{OrderedFactor{2}}(normal=>0.977, outlier=>0.0229) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0359) UnivariateFinite{OrderedFactor{2}}(normal=>0.958, outlier=>0.0417) UnivariateFinite{OrderedFactor{2}}(normal=>0.971, outlier=>0.029) UnivariateFinite{OrderedFactor{2}}(normal=>0.945, outlier=>0.0551) UnivariateFinite{OrderedFactor{2}}(normal=>0.964, outlier=>0.0362) UnivariateFinite{OrderedFactor{2}}(normal=>0.997, outlier=>0.00341) UnivariateFinite{OrderedFactor{2}}(normal=>0.937, outlier=>0.0629) UnivariateFinite{OrderedFactor{2}}(normal=>0.975, outlier=>0.0247) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.986, outlier=>0.0142) UnivariateFinite{OrderedFactor{2}}(normal=>0.955, outlier=>0.0451) UnivariateFinite{OrderedFactor{2}}(normal=>0.888, outlier=>0.112) UnivariateFinite{OrderedFactor{2}}(normal=>0.961, outlier=>0.0386) UnivariateFinite{OrderedFactor{2}}(normal=>0.962, outlier=>0.0376) UnivariateFinite{OrderedFactor{2}}(normal=>0.97, outlier=>0.0301) UnivariateFinite{OrderedFactor{2}}(normal=>0.953, outlier=>0.0471) UnivariateFinite{OrderedFactor{2}}(normal=>0.987, outlier=>0.0129) UnivariateFinite{OrderedFactor{2}}(normal=>0.786, outlier=>0.214) There might be occasions, where our ProbabilisticDetector or DeterministicDetector wrappers are not flexible enough. In such cases we can directly use augmented_transform in our learning networks and use a ProbabilisticTransformer or DeterministicTransformer , which takes one or more train/test tuples as inputs returning probabilistic or deterministic predictions.","title":"Learning networks"},{"location":"documentation/advanced-usage/#implementing-models","text":"Learning networks let us flexibly create complex combinations of existing models , however, sometimes it's necessary to develop new outlier detection models for specific tasks. OutlierDetection.jl builds on top of MLJ and provides a simple interface defining how an outlier detection algorithm can be implemented. Let's first import the interface and the packages relevant to our new algorithm. import OutlierDetectionInterface const OD = OutlierDetectionInterface using Statistics : mean using LinearAlgebra : norm Our proposed algorithm calculates a central point from the training data and defines an outlier as a point that's far away from that center. The only hyperparameter is p specifying which p-norm to use to calculate the distance. Using @detector , which replicates @mlj_model , we can define our detector struct with macro-generated keyword arguments and default values. OD . @detector mutable struct SimpleDetector <: OD . UnsupervisedDetector p :: Float64 = 2 end Our DetectorModel , then, defines the learned parameters of our model. In this case the only learned parameter is the center. struct SimpleModel <: OD . DetectorModel center :: AbstractArray { <: Real } end Let's further define a helper function to calculate the distance from the center. function distances_from ( center , vectors :: AbstractMatrix , p ) deviations = vectors .- center return [ norm ( deviations [ : , i ], p ) for i in 1 : size ( deviations , 2 )] end distances_from (generic function with 1 method) Finally, we can implement the two methods necessary to implement a detector, namely fit and transform . Please refer to the Key Concepts to learn more about the involved methods and types. function OD . fit ( detector :: SimpleDetector , X :: OD . Data ; verbosity ) :: OD . Fit center = mean ( X , dims = 2 ) training_scores = distances_from ( center , X , detector . p ) return SimpleModel ( center ), training_scores end function OD . transform ( detector :: SimpleDetector , model :: SimpleModel , X :: OD . Data ) :: OD . Scores distances_from ( model . center , X , detector . p ) end Using a data-frontend, we can make sure that MLJ internally transforms input data to Data , which refers to column-major Julia arrays with the last dimension representing an example. Registering that frontend can be achieved with @default_frontend . OD . @default_frontend SimpleDetector Again, we can simply wrap our detector in a ProbabilisticDetector to enable probabilistic predictions. sd = machine ( ProbabilisticDetector ( SimpleDetector ()), X , y ) fit! ( sd , rows = train ) predict ( sd , rows = test ) 3600-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.903, outlier=>0.0972) UnivariateFinite{OrderedFactor{2}}(normal=>0.874, outlier=>0.126) UnivariateFinite{OrderedFactor{2}}(normal=>0.917, outlier=>0.0826) UnivariateFinite{OrderedFactor{2}}(normal=>0.564, outlier=>0.436) UnivariateFinite{OrderedFactor{2}}(normal=>0.67, outlier=>0.33) UnivariateFinite{OrderedFactor{2}}(normal=>0.531, outlier=>0.469) UnivariateFinite{OrderedFactor{2}}(normal=>0.832, outlier=>0.168) UnivariateFinite{OrderedFactor{2}}(normal=>0.729, outlier=>0.271) UnivariateFinite{OrderedFactor{2}}(normal=>0.677, outlier=>0.323) UnivariateFinite{OrderedFactor{2}}(normal=>0.688, outlier=>0.312) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.874, outlier=>0.126) UnivariateFinite{OrderedFactor{2}}(normal=>0.742, outlier=>0.258) UnivariateFinite{OrderedFactor{2}}(normal=>0.816, outlier=>0.184) UnivariateFinite{OrderedFactor{2}}(normal=>0.713, outlier=>0.287) UnivariateFinite{OrderedFactor{2}}(normal=>0.564, outlier=>0.436) UnivariateFinite{OrderedFactor{2}}(normal=>0.932, outlier=>0.0679) UnivariateFinite{OrderedFactor{2}}(normal=>0.631, outlier=>0.369) UnivariateFinite{OrderedFactor{2}}(normal=>0.526, outlier=>0.474) UnivariateFinite{OrderedFactor{2}}(normal=>0.408, outlier=>0.592) Remember: Your feedback and contributions are extremely welcome, join us on Github or #outlierdetection on Slack and get involved.","title":"Implementing models"},{"location":"documentation/architecture/","text":"Architecture TODO","title":"Architecture"},{"location":"documentation/architecture/#architecture","text":"TODO","title":"Architecture"},{"location":"documentation/benchmark-datasets/","text":"Benchmark Datasets TODO","title":"Benchmark Datasets"},{"location":"documentation/benchmark-datasets/#benchmark-datasets","text":"TODO","title":"Benchmark Datasets"},{"location":"documentation/contributing/","text":"How to Contribute OutlierDetection.jl is a community-driven project and your help is extremely welcome. If you get stuck, please don't hesitate to chat with us or raise an issue . Take a look at Github's How to Contribute Guide to find out more about what it means to contribute. Note: To avoid duplicating work, it is highly advised that you search through the issue tracker and the PR list . If in doubt about duplicated work, or if you want to work on a non-trivial feature, it\u2019s recommended to first open an issue in the issue tracker to get some feedbacks from core developers. Areas of contribution We value all kinds of contributions - not just code. The following table gives an overview of key contribution areas. Area Description Documentation Improve or add docstrings, glossary terms, the user guide, and the example notebooks Testing Report bugs, improve or add unit tests, conduct field testing on real-world data sets Code Improve or add functionality, fix bugs Mentoring Onboarding and mentoring of new contributors Outreach Organize talks, tutorials or workshops, write blog posts Maintenance Manage and review issues/pull requests API design Design interfaces for detectors and other functionality Reporting bugs We use GitHub issues to track all bugs and feature requests; feel free to open an issue if you have found a bug or wish to see a feature implemented. It is recommended to check that your issue complies with the following rules before submitting: Verify that your issue is not being currently addressed by other issues or pull requests . Please ensure all code snippets and error messages are formatted in appropriate code blocks. See Creating and highlighting code blocks . Please be specific about what detectors and/or functions are involved and the shape of the data, as appropriate; please include a reproducible code snippet or link to a gist . If an exception is raised, please provide the traceback. The contribution workflow The preferred workflow for contributing to OutlierDetection's repository is to fork the main repository on GitHub, clone, and develop on a new branch. Fork the project repository by clicking on the \\'Fork\\' button near the top right of the page. This creates a copy of the code under your GitHub user account. For more details on how to fork a repository see this guide . Clone your fork of the OutlierDetection.jl repo from your GitHub account to your local disk: git clone git@github.com:USERNAME/OutlierDetection.jl.git cd OutlierDetection.jl Configure and link the remote for your fork to the upstream repository: git remote -v git remote add upstream https://github.com/OutlierDetectionJL/OutlierDetection.git Verify the new upstream repository you\\'ve specified for your fork: git remote -v > origin https://github.com/USERNAME/YOUR_FORK.git ( fetch ) > origin https://github.com/YOUR_USERNAME/YOUR_FORK.git ( push ) > upstream https://github.com/OutlierDetectionJL/OutlierDetection.jl.git ( fetch ) > upstream https://github.com/OutlierDetectionJL/OutlierDetection.jl.git ( push ) Sync the main branch of your fork with the upstream repository: git fetch upstream git checkout main --track origin/main git merge upstream/main Create a new feature branch from the main branch to hold your changes: git checkout main git checkout -b <my-feature-branch> Always use a feature branch. It\\'s good practice to never work on the main branch! Name the feature branch after your contribution. Develop your contribution on your feature branch. Add changed files using git add and then git commit files to record your changes in Git: git add <modified_files> git commit When finished, push the changes to your GitHub account with: git push --set-upstream origin my-feature-branch Follow these instructions to create a pull request from your fork. If your work is still work in progress, you can open a draft pull request. We recommend to open a pull request early, so that other contributors become aware of your work and can give you feedback early on. To add more changes, simply repeat steps 7 - 8. Pull requests are updated automatically if you push new changes to the same branch. If any of the above seems like magic to you, please look up the Git documentation on the web. If you get stuck, feel free to chat with us . Continuous integration We use continuous integration services on GitHub to automatically check if new pull requests do not break anything on all the Julia versions we support. The main quality control measures right now are unit testing and test coverage . In the future we additionally want to check code style and formatting. Unit testing We use Julia's built-in Unit Testing . The tests can be found in the test folder. To check if your code passes all tests make sure that you have the OutlierDetection environment activated and run ] test from the Julia console. Test coverage We use the Coverage.jl package and codecov to measure and compare test coverage of our code. API design We follow the general design approach chosen by MLJ, which is described in the paper \"Designing Machine Learning Toolboxes: Concepts, Principles and Patterns\" . Additionally, we are always looking for feedback and improvement suggestions! Documentation We use Documenter.jl and mkdocs to build and deploy our online documention. The source files used to generate the online documentation can be found in docs/src/ . For example, the main configuration file for mkdocs is mkdocs.yml and the main page is index.md . To add new pages, you need to add a new .md file and include it in the mkdocs.yml file. To build the documentation locally, you need to navigate to docs/ and Build the markdown files with Documenter.jl: julia --project make.jl To build the website using the markdown files, run: mkdocs build # optionally run `mkdocs serve` to build and serve locally You can find the generated files in the OutlierDetection.jl/docs/site/ folder. To view the website, open OutlierDetection.jl/docs/site/index.html with your preferred web browser or use mkdocs serve to start a local documentation server. Coding style We use DocumentFormat.jl as a code formatter. Additionally, we use a maximum line length of 120 characters. Acknowledging contributions We follow the all-contributors specification and recognise various types of contributions. Take a look at our past and current contributors ! If you are a new contributor, please make sure we add you to our list of contributors. All contributions are recorded in .all-contributorsrc .","title":"Contributing"},{"location":"documentation/contributing/#how-to-contribute","text":"OutlierDetection.jl is a community-driven project and your help is extremely welcome. If you get stuck, please don't hesitate to chat with us or raise an issue . Take a look at Github's How to Contribute Guide to find out more about what it means to contribute. Note: To avoid duplicating work, it is highly advised that you search through the issue tracker and the PR list . If in doubt about duplicated work, or if you want to work on a non-trivial feature, it\u2019s recommended to first open an issue in the issue tracker to get some feedbacks from core developers.","title":"How to Contribute"},{"location":"documentation/contributing/#areas-of-contribution","text":"We value all kinds of contributions - not just code. The following table gives an overview of key contribution areas. Area Description Documentation Improve or add docstrings, glossary terms, the user guide, and the example notebooks Testing Report bugs, improve or add unit tests, conduct field testing on real-world data sets Code Improve or add functionality, fix bugs Mentoring Onboarding and mentoring of new contributors Outreach Organize talks, tutorials or workshops, write blog posts Maintenance Manage and review issues/pull requests API design Design interfaces for detectors and other functionality","title":"Areas of contribution"},{"location":"documentation/contributing/#reporting-bugs","text":"We use GitHub issues to track all bugs and feature requests; feel free to open an issue if you have found a bug or wish to see a feature implemented. It is recommended to check that your issue complies with the following rules before submitting: Verify that your issue is not being currently addressed by other issues or pull requests . Please ensure all code snippets and error messages are formatted in appropriate code blocks. See Creating and highlighting code blocks . Please be specific about what detectors and/or functions are involved and the shape of the data, as appropriate; please include a reproducible code snippet or link to a gist . If an exception is raised, please provide the traceback.","title":"Reporting bugs"},{"location":"documentation/contributing/#the-contribution-workflow","text":"The preferred workflow for contributing to OutlierDetection's repository is to fork the main repository on GitHub, clone, and develop on a new branch. Fork the project repository by clicking on the \\'Fork\\' button near the top right of the page. This creates a copy of the code under your GitHub user account. For more details on how to fork a repository see this guide . Clone your fork of the OutlierDetection.jl repo from your GitHub account to your local disk: git clone git@github.com:USERNAME/OutlierDetection.jl.git cd OutlierDetection.jl Configure and link the remote for your fork to the upstream repository: git remote -v git remote add upstream https://github.com/OutlierDetectionJL/OutlierDetection.git Verify the new upstream repository you\\'ve specified for your fork: git remote -v > origin https://github.com/USERNAME/YOUR_FORK.git ( fetch ) > origin https://github.com/YOUR_USERNAME/YOUR_FORK.git ( push ) > upstream https://github.com/OutlierDetectionJL/OutlierDetection.jl.git ( fetch ) > upstream https://github.com/OutlierDetectionJL/OutlierDetection.jl.git ( push ) Sync the main branch of your fork with the upstream repository: git fetch upstream git checkout main --track origin/main git merge upstream/main Create a new feature branch from the main branch to hold your changes: git checkout main git checkout -b <my-feature-branch> Always use a feature branch. It\\'s good practice to never work on the main branch! Name the feature branch after your contribution. Develop your contribution on your feature branch. Add changed files using git add and then git commit files to record your changes in Git: git add <modified_files> git commit When finished, push the changes to your GitHub account with: git push --set-upstream origin my-feature-branch Follow these instructions to create a pull request from your fork. If your work is still work in progress, you can open a draft pull request. We recommend to open a pull request early, so that other contributors become aware of your work and can give you feedback early on. To add more changes, simply repeat steps 7 - 8. Pull requests are updated automatically if you push new changes to the same branch. If any of the above seems like magic to you, please look up the Git documentation on the web. If you get stuck, feel free to chat with us .","title":"The contribution workflow"},{"location":"documentation/contributing/#continuous-integration","text":"We use continuous integration services on GitHub to automatically check if new pull requests do not break anything on all the Julia versions we support. The main quality control measures right now are unit testing and test coverage . In the future we additionally want to check code style and formatting.","title":"Continuous integration"},{"location":"documentation/contributing/#unit-testing","text":"We use Julia's built-in Unit Testing . The tests can be found in the test folder. To check if your code passes all tests make sure that you have the OutlierDetection environment activated and run ] test from the Julia console.","title":"Unit testing"},{"location":"documentation/contributing/#test-coverage","text":"We use the Coverage.jl package and codecov to measure and compare test coverage of our code.","title":"Test coverage"},{"location":"documentation/contributing/#api-design","text":"We follow the general design approach chosen by MLJ, which is described in the paper \"Designing Machine Learning Toolboxes: Concepts, Principles and Patterns\" . Additionally, we are always looking for feedback and improvement suggestions!","title":"API design"},{"location":"documentation/contributing/#documentation","text":"We use Documenter.jl and mkdocs to build and deploy our online documention. The source files used to generate the online documentation can be found in docs/src/ . For example, the main configuration file for mkdocs is mkdocs.yml and the main page is index.md . To add new pages, you need to add a new .md file and include it in the mkdocs.yml file. To build the documentation locally, you need to navigate to docs/ and Build the markdown files with Documenter.jl: julia --project make.jl To build the website using the markdown files, run: mkdocs build # optionally run `mkdocs serve` to build and serve locally You can find the generated files in the OutlierDetection.jl/docs/site/ folder. To view the website, open OutlierDetection.jl/docs/site/index.html with your preferred web browser or use mkdocs serve to start a local documentation server.","title":"Documentation"},{"location":"documentation/contributing/#coding-style","text":"We use DocumentFormat.jl as a code formatter. Additionally, we use a maximum line length of 120 characters.","title":"Coding style"},{"location":"documentation/contributing/#acknowledging-contributions","text":"We follow the all-contributors specification and recognise various types of contributions. Take a look at our past and current contributors ! If you are a new contributor, please make sure we add you to our list of contributors. All contributions are recorded in .all-contributorsrc .","title":"Acknowledging contributions"},{"location":"documentation/detector-creation/","text":"Detector Creation TODO","title":"Detector Creation"},{"location":"documentation/detector-creation/#detector-creation","text":"TODO","title":"Detector Creation"},{"location":"documentation/detector-evaluation/","text":"Detector Evaluation TODO","title":"Detector Evaluation"},{"location":"documentation/detector-evaluation/#detector-evaluation","text":"TODO","title":"Detector Evaluation"},{"location":"documentation/ensemble-learning/","text":"Ensemble Learning TODO","title":"Ensemble Learning"},{"location":"documentation/ensemble-learning/#ensemble-learning","text":"TODO","title":"Ensemble Learning"},{"location":"documentation/getting-started/","text":"Getting Started This example demonstrates using the OutlierDetection API to determine the outlierness of instances in the Thyroid Disease Dataset , which is part of the ODDS collection . We use OutlierDetectionData.jl to load the dataset. Import MLJ , OutlierDetection and OutlierDetectionData . using MLJ using OutlierDetection using OutlierDetectionData : ODDS Load the \"thyroid\" dataset from the ODDS collection. X , y = ODDS . load ( \"thyroid\" ) (3772\u00d76 DataFrame Row \u2502 x1 x2 x3 x4 x5 x6 \u2502 Float64 Float64 Float64 Float64 Float64 Float64 \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 \u2502 0.774194 0.00113208 0.137571 0.275701 0.295775 0.236066 2 \u2502 0.247312 0.000471698 0.279886 0.329439 0.535211 0.17377 3 \u2502 0.494624 0.00358491 0.22296 0.233645 0.525822 0.12459 4 \u2502 0.677419 0.00169811 0.156546 0.175234 0.333333 0.136066 5 \u2502 0.236559 0.000471698 0.241935 0.320093 0.333333 0.247541 6 \u2502 0.731183 0.000471698 0.147059 0.196262 0.239437 0.198361 7 \u2502 0.903226 0.000471698 0.213472 0.294393 0.399061 0.195082 8 \u2502 0.505376 0.00392453 0.185009 0.196262 0.276995 0.177049 \u22ee \u2502 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 3766 \u2502 0.763441 0.00943396 0.190702 0.231308 0.323944 0.185246 3767 \u2502 0.688172 0.000886792 0.0711575 0.35514 0.262911 0.331148 3768 \u2502 0.817204 0.000113208 0.190702 0.287383 0.413146 0.188525 3769 \u2502 0.430108 0.00245283 0.232448 0.287383 0.446009 0.17541 3770 \u2502 0.935484 0.0245283 0.160342 0.28271 0.375587 0.2 3771 \u2502 0.677419 0.0014717 0.190702 0.242991 0.323944 0.195082 3772 \u2502 0.483871 0.00356604 0.190702 0.212617 0.338028 0.163934 3757 rows omitted, CategoricalArrays.CategoricalValue{String, UInt32}[\"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\" \u2026 \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\"]) Create indices to split the data into 50% training and test data. train , test = partition ( eachindex ( y ), 0.5 , shuffle = true , rng = 0 ) ([2913, 2848, 707, 3243, 2580, 1308, 2321, 2373, 1876, 1063 \u2026 1830, 2001, 812, 2964, 200, 1295, 3008, 1264, 3250, 893], [2757, 1446, 3184, 3035, 3682, 1489, 1391, 3379, 1272, 1499 \u2026 3294, 1176, 1305, 276, 2305, 401, 3126, 922, 83, 3649]) Load a OutlierDetectionNeighbors.KNNDetector and initialize it with k=10 neighbors. KNN = @iload KNNDetector pkg = OutlierDetectionNeighbors verbosity = 0 knn = KNN ( k = 10 ) KNNDetector( k = 10, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum) Bind a raw, probabilistic and deterministic detector to data using a machine. knn_raw = machine ( knn , X ) knn_probabilistic = machine ( ProbabilisticDetector ( knn ), X ) knn_deterministic = machine ( DeterministicDetector ( knn ), X ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 0 times; caches data args: 1: Source @876 \u23ce `Table{AbstractVector{Continuous}}` Learn models from the training data. fit! ( knn_raw , rows = train ) fit! ( knn_probabilistic , rows = train ) fit! ( knn_deterministic , rows = train ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 1 time; caches data args: 1: Source @876 \u23ce `Table{AbstractVector{Continuous}}` Transform the test data into raw outlier scores. transform ( knn_raw , rows = test ) 1886-element Vector{Float64}: 0.04150080722414154 0.06332161576246768 0.15584728188740374 0.10211441619850055 0.049028607009550355 0.05535455202415266 0.040781731999420305 0.047055640453124284 0.028744836441760478 0.058699224498302595 \u22ee 0.06395147696918803 0.04980165081635798 0.09253572176985131 0.036833962818158164 0.031917866836413324 0.0741331730353965 0.11129509611654068 0.34959776501224477 0.04514282829421119 Predict outlier probabilities based on the test data. predict ( knn_probabilistic , rows = test ) 1886-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.96, outlier=>0.0403) UnivariateFinite{OrderedFactor{2}}(normal=>0.931, outlier=>0.069) UnivariateFinite{OrderedFactor{2}}(normal=>0.81, outlier=>0.19) UnivariateFinite{OrderedFactor{2}}(normal=>0.88, outlier=>0.12) UnivariateFinite{OrderedFactor{2}}(normal=>0.95, outlier=>0.0502) UnivariateFinite{OrderedFactor{2}}(normal=>0.941, outlier=>0.0585) UnivariateFinite{OrderedFactor{2}}(normal=>0.961, outlier=>0.0394) UnivariateFinite{OrderedFactor{2}}(normal=>0.952, outlier=>0.0476) UnivariateFinite{OrderedFactor{2}}(normal=>0.976, outlier=>0.0236) UnivariateFinite{OrderedFactor{2}}(normal=>0.937, outlier=>0.0629) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.93, outlier=>0.0698) UnivariateFinite{OrderedFactor{2}}(normal=>0.949, outlier=>0.0512) UnivariateFinite{OrderedFactor{2}}(normal=>0.893, outlier=>0.107) UnivariateFinite{OrderedFactor{2}}(normal=>0.966, outlier=>0.0342) UnivariateFinite{OrderedFactor{2}}(normal=>0.972, outlier=>0.0278) UnivariateFinite{OrderedFactor{2}}(normal=>0.917, outlier=>0.0832) UnivariateFinite{OrderedFactor{2}}(normal=>0.868, outlier=>0.132) UnivariateFinite{OrderedFactor{2}}(normal=>0.555, outlier=>0.445) UnivariateFinite{OrderedFactor{2}}(normal=>0.955, outlier=>0.0451) Predict outlier classes based on the test data. predict ( knn_deterministic , rows = test ) 1886-element CategoricalArrays.CategoricalArray{String,1,UInt32}: \"normal\" \"normal\" \"outlier\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \u22ee \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"outlier\" \"normal\" Learn more To learn more about the concepts in OutlierDetection.jl , check out the simple usage guide .","title":"Getting Started"},{"location":"documentation/getting-started/#getting-started","text":"This example demonstrates using the OutlierDetection API to determine the outlierness of instances in the Thyroid Disease Dataset , which is part of the ODDS collection . We use OutlierDetectionData.jl to load the dataset. Import MLJ , OutlierDetection and OutlierDetectionData . using MLJ using OutlierDetection using OutlierDetectionData : ODDS Load the \"thyroid\" dataset from the ODDS collection. X , y = ODDS . load ( \"thyroid\" ) (3772\u00d76 DataFrame Row \u2502 x1 x2 x3 x4 x5 x6 \u2502 Float64 Float64 Float64 Float64 Float64 Float64 \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 \u2502 0.774194 0.00113208 0.137571 0.275701 0.295775 0.236066 2 \u2502 0.247312 0.000471698 0.279886 0.329439 0.535211 0.17377 3 \u2502 0.494624 0.00358491 0.22296 0.233645 0.525822 0.12459 4 \u2502 0.677419 0.00169811 0.156546 0.175234 0.333333 0.136066 5 \u2502 0.236559 0.000471698 0.241935 0.320093 0.333333 0.247541 6 \u2502 0.731183 0.000471698 0.147059 0.196262 0.239437 0.198361 7 \u2502 0.903226 0.000471698 0.213472 0.294393 0.399061 0.195082 8 \u2502 0.505376 0.00392453 0.185009 0.196262 0.276995 0.177049 \u22ee \u2502 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 3766 \u2502 0.763441 0.00943396 0.190702 0.231308 0.323944 0.185246 3767 \u2502 0.688172 0.000886792 0.0711575 0.35514 0.262911 0.331148 3768 \u2502 0.817204 0.000113208 0.190702 0.287383 0.413146 0.188525 3769 \u2502 0.430108 0.00245283 0.232448 0.287383 0.446009 0.17541 3770 \u2502 0.935484 0.0245283 0.160342 0.28271 0.375587 0.2 3771 \u2502 0.677419 0.0014717 0.190702 0.242991 0.323944 0.195082 3772 \u2502 0.483871 0.00356604 0.190702 0.212617 0.338028 0.163934 3757 rows omitted, CategoricalArrays.CategoricalValue{String, UInt32}[\"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\" \u2026 \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\"]) Create indices to split the data into 50% training and test data. train , test = partition ( eachindex ( y ), 0.5 , shuffle = true , rng = 0 ) ([2913, 2848, 707, 3243, 2580, 1308, 2321, 2373, 1876, 1063 \u2026 1830, 2001, 812, 2964, 200, 1295, 3008, 1264, 3250, 893], [2757, 1446, 3184, 3035, 3682, 1489, 1391, 3379, 1272, 1499 \u2026 3294, 1176, 1305, 276, 2305, 401, 3126, 922, 83, 3649]) Load a OutlierDetectionNeighbors.KNNDetector and initialize it with k=10 neighbors. KNN = @iload KNNDetector pkg = OutlierDetectionNeighbors verbosity = 0 knn = KNN ( k = 10 ) KNNDetector( k = 10, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum) Bind a raw, probabilistic and deterministic detector to data using a machine. knn_raw = machine ( knn , X ) knn_probabilistic = machine ( ProbabilisticDetector ( knn ), X ) knn_deterministic = machine ( DeterministicDetector ( knn ), X ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 0 times; caches data args: 1: Source @876 \u23ce `Table{AbstractVector{Continuous}}` Learn models from the training data. fit! ( knn_raw , rows = train ) fit! ( knn_probabilistic , rows = train ) fit! ( knn_deterministic , rows = train ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 1 time; caches data args: 1: Source @876 \u23ce `Table{AbstractVector{Continuous}}` Transform the test data into raw outlier scores. transform ( knn_raw , rows = test ) 1886-element Vector{Float64}: 0.04150080722414154 0.06332161576246768 0.15584728188740374 0.10211441619850055 0.049028607009550355 0.05535455202415266 0.040781731999420305 0.047055640453124284 0.028744836441760478 0.058699224498302595 \u22ee 0.06395147696918803 0.04980165081635798 0.09253572176985131 0.036833962818158164 0.031917866836413324 0.0741331730353965 0.11129509611654068 0.34959776501224477 0.04514282829421119 Predict outlier probabilities based on the test data. predict ( knn_probabilistic , rows = test ) 1886-element MLJBase.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}: UnivariateFinite{OrderedFactor{2}}(normal=>0.96, outlier=>0.0403) UnivariateFinite{OrderedFactor{2}}(normal=>0.931, outlier=>0.069) UnivariateFinite{OrderedFactor{2}}(normal=>0.81, outlier=>0.19) UnivariateFinite{OrderedFactor{2}}(normal=>0.88, outlier=>0.12) UnivariateFinite{OrderedFactor{2}}(normal=>0.95, outlier=>0.0502) UnivariateFinite{OrderedFactor{2}}(normal=>0.941, outlier=>0.0585) UnivariateFinite{OrderedFactor{2}}(normal=>0.961, outlier=>0.0394) UnivariateFinite{OrderedFactor{2}}(normal=>0.952, outlier=>0.0476) UnivariateFinite{OrderedFactor{2}}(normal=>0.976, outlier=>0.0236) UnivariateFinite{OrderedFactor{2}}(normal=>0.937, outlier=>0.0629) \u22ee UnivariateFinite{OrderedFactor{2}}(normal=>0.93, outlier=>0.0698) UnivariateFinite{OrderedFactor{2}}(normal=>0.949, outlier=>0.0512) UnivariateFinite{OrderedFactor{2}}(normal=>0.893, outlier=>0.107) UnivariateFinite{OrderedFactor{2}}(normal=>0.966, outlier=>0.0342) UnivariateFinite{OrderedFactor{2}}(normal=>0.972, outlier=>0.0278) UnivariateFinite{OrderedFactor{2}}(normal=>0.917, outlier=>0.0832) UnivariateFinite{OrderedFactor{2}}(normal=>0.868, outlier=>0.132) UnivariateFinite{OrderedFactor{2}}(normal=>0.555, outlier=>0.445) UnivariateFinite{OrderedFactor{2}}(normal=>0.955, outlier=>0.0451) Predict outlier classes based on the test data. predict ( knn_deterministic , rows = test ) 1886-element CategoricalArrays.CategoricalArray{String,1,UInt32}: \"normal\" \"normal\" \"outlier\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \u22ee \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"outlier\" \"normal\"","title":"Getting Started"},{"location":"documentation/getting-started/#learn-more","text":"To learn more about the concepts in OutlierDetection.jl , check out the simple usage guide .","title":"Learn more"},{"location":"documentation/installation/","text":"Installation It is recommended to use Pkg.jl for installation. Please make sure that you are using a compatible version of Julia. A list of compatible versions can be found our CI pipeline . Follow the command below to install the latest official release or use ] add OutlierDetection in the Julia REPL. import Pkg ; Pkg . add ( \"OutlierDetection\" ) A specific version can be installed by appending a version after a @ symbol, e.g. OutlierDetection@v0.1 . Additionally, you can directly install specific branches or commits by appending a # symbol and the corresponding branch name or commit SHA, e.g. OutlierDetection#master . If you would like to modify the package locally, you can use Pkg.develop(OutlierDetection) or ] dev OutlierDetection in the Julia REPL. This fetches a full clone of the package to ~/.julia/dev/ (the path can be changed by setting the environment variable JULIA_PKG_DEVDIR ).","title":"Installation"},{"location":"documentation/installation/#installation","text":"It is recommended to use Pkg.jl for installation. Please make sure that you are using a compatible version of Julia. A list of compatible versions can be found our CI pipeline . Follow the command below to install the latest official release or use ] add OutlierDetection in the Julia REPL. import Pkg ; Pkg . add ( \"OutlierDetection\" ) A specific version can be installed by appending a version after a @ symbol, e.g. OutlierDetection@v0.1 . Additionally, you can directly install specific branches or commits by appending a # symbol and the corresponding branch name or commit SHA, e.g. OutlierDetection#master . If you would like to modify the package locally, you can use Pkg.develop(OutlierDetection) or ] dev OutlierDetection in the Julia REPL. This fetches a full clone of the package to ~/.julia/dev/ (the path can be changed by setting the environment variable JULIA_PKG_DEVDIR ).","title":"Installation"},{"location":"documentation/key-concepts/","text":"Key Concepts This guide should provide you the necessary knowledge to work with OutlierDetection.jl and understand the concepts behind the library design. Note Outlier detection is predominantly an unsupervised learning task , transforming each data point to an outlier score quantifying the level of \"outlierness\". This very general form of output retains all the information provided by a specific algorithm. The key design choice of OutlierDetection.jl is promoting the usage of outlier scores , not labels. The main data type, a Detector , has to implement two methods: fit and transform . Detector : A struct defining the hyperparameters for an outlier detection algorithm, just like an estimator in scikit-learn or a model in MLJ . A detector actually is an MLJModelInterface.Model (subtype). fit : Learn a DetectorModel for a specific detector from input data X and labels y (if supervised), for example the weights of a neural network. transform : Using a detector and a learned model, transform unseen data into outlier scores. Transforming the outlier scores to classes is seen as the last step of an outlier detection task. A Wrapper or Transformer turns scores into probabilities or labels, typically with two classes describing inliers \"normal\" and outliers \"outlier\" . A convention used in OutlierDetection.jl is that higher scores imply higher outlierness . Note A peculiarity of working with outlier scores is the distinction between train scores and test scores . Train scores result from fitting a detector ( fit ), and test scores result from predicting unseen data ( transform ). Classifying an instance as an inlier or outlier always requires a comparison to the train scores. Let's see how the data types look like in a typical outlier detection task. We use the following naming conventions for the data we are working with: the input data OutlierDetectionInterface.Data the raw scores OutlierDetectionInterface.Scores the labels OutlierDetectionInterface.Labels One last unmentioned structure is the Fit result, a struct that bundles the learned model and training scores. Let's now looks how the methods defined by OutlierDetection.jl transform the mentioned data structures. fit ( :: UnsupervisedDetector , :: Data ; verbosity :: Integer ) :: Fit fit ( :: SupervisedDetector , :: Data , :: Labels ; verbosity :: Integer ) :: Fit transform ( :: Detector , :: Fit , :: Data ) :: Scores A new outlier detection algorithm can be implemented in OutlierDetection.jl easily by implementing above fit and transform methods. Warning We expect the data to be formatted using the columns-as-observations convention for improved performance with Julia's column-major data. Integration with MLJ One of the exciting features of OutlierDetection.jl is it's interoperability with the rest of Julia's machine learning ecosystem. You might want to preprocess your data, cluster it, detect outliers, classify, and so forth. OutlierDetection.jl defines an interface for MLJ such the implemented OutlierDetection.jl detectors can be used directly with MLJ. A Detector is bound to data, either through machine(::UnsupervisedDetector, X) , or machine(::SupervisedDetector, X, y) . fit(::Detector, X, [y]; verbosity) becomes fit!(machine) , which calls fit under the hood transform(::Detector, ::Fit, X) becomes transform(machine) , which calls transform under the hood Additionally, OutlierDetection.jl defines a data front-end for MLJ, which ensures that fit and transform are always called with Julia arrays in column-major format, even though machine(::Detector, X, y) also accepts data from any Tables.jl -compatible data source. Take a look at our Simple Usage to learn more.","title":"Key Concepts"},{"location":"documentation/key-concepts/#key-concepts","text":"This guide should provide you the necessary knowledge to work with OutlierDetection.jl and understand the concepts behind the library design. Note Outlier detection is predominantly an unsupervised learning task , transforming each data point to an outlier score quantifying the level of \"outlierness\". This very general form of output retains all the information provided by a specific algorithm. The key design choice of OutlierDetection.jl is promoting the usage of outlier scores , not labels. The main data type, a Detector , has to implement two methods: fit and transform . Detector : A struct defining the hyperparameters for an outlier detection algorithm, just like an estimator in scikit-learn or a model in MLJ . A detector actually is an MLJModelInterface.Model (subtype). fit : Learn a DetectorModel for a specific detector from input data X and labels y (if supervised), for example the weights of a neural network. transform : Using a detector and a learned model, transform unseen data into outlier scores. Transforming the outlier scores to classes is seen as the last step of an outlier detection task. A Wrapper or Transformer turns scores into probabilities or labels, typically with two classes describing inliers \"normal\" and outliers \"outlier\" . A convention used in OutlierDetection.jl is that higher scores imply higher outlierness . Note A peculiarity of working with outlier scores is the distinction between train scores and test scores . Train scores result from fitting a detector ( fit ), and test scores result from predicting unseen data ( transform ). Classifying an instance as an inlier or outlier always requires a comparison to the train scores. Let's see how the data types look like in a typical outlier detection task. We use the following naming conventions for the data we are working with: the input data OutlierDetectionInterface.Data the raw scores OutlierDetectionInterface.Scores the labels OutlierDetectionInterface.Labels One last unmentioned structure is the Fit result, a struct that bundles the learned model and training scores. Let's now looks how the methods defined by OutlierDetection.jl transform the mentioned data structures. fit ( :: UnsupervisedDetector , :: Data ; verbosity :: Integer ) :: Fit fit ( :: SupervisedDetector , :: Data , :: Labels ; verbosity :: Integer ) :: Fit transform ( :: Detector , :: Fit , :: Data ) :: Scores A new outlier detection algorithm can be implemented in OutlierDetection.jl easily by implementing above fit and transform methods. Warning We expect the data to be formatted using the columns-as-observations convention for improved performance with Julia's column-major data.","title":"Key Concepts"},{"location":"documentation/key-concepts/#integration-with-mlj","text":"One of the exciting features of OutlierDetection.jl is it's interoperability with the rest of Julia's machine learning ecosystem. You might want to preprocess your data, cluster it, detect outliers, classify, and so forth. OutlierDetection.jl defines an interface for MLJ such the implemented OutlierDetection.jl detectors can be used directly with MLJ. A Detector is bound to data, either through machine(::UnsupervisedDetector, X) , or machine(::SupervisedDetector, X, y) . fit(::Detector, X, [y]; verbosity) becomes fit!(machine) , which calls fit under the hood transform(::Detector, ::Fit, X) becomes transform(machine) , which calls transform under the hood Additionally, OutlierDetection.jl defines a data front-end for MLJ, which ensures that fit and transform are always called with Julia arrays in column-major format, even though machine(::Detector, X, y) also accepts data from any Tables.jl -compatible data source. Take a look at our Simple Usage to learn more.","title":"Integration with MLJ"},{"location":"documentation/performance-tips/","text":"Performance Tips All the usual Julia performance tips apply . As always profiling your code is generally a useful way of finding bottlenecks. We provide a basic performance benchmarking toolkit. See benchmark/runbenchmarks.jl for usage instructions.","title":"Performance Tips"},{"location":"documentation/performance-tips/#performance-tips","text":"All the usual Julia performance tips apply . As always profiling your code is generally a useful way of finding bottlenecks. We provide a basic performance benchmarking toolkit. See benchmark/runbenchmarks.jl for usage instructions.","title":"Performance Tips"},{"location":"documentation/simple-usage/","text":"Simple Usage Let's import the necessary packages first. using MLJ using OutlierDetection using OutlierDetectionData : ODDS Loading data We can list the available datasets in the imported ODDS dataset collection with list ODDS . list () 27-element Vector{String}: \"annthyroid\" \"arrhythmia\" \"breastw\" \"cardio\" \"cover\" \"glass\" \"http\" \"ionosphere\" \"letter\" \"lympho\" \u22ee \"satimage-2\" \"shuttle\" \"smtp\" \"speech\" \"thyroid\" \"vertebral\" \"vowels\" \"wbc\" \"wine\" We can now load a dataset by specifying its name. X , y = ODDS . load ( \"annthyroid\" ) (7200\u00d76 DataFrame Row \u2502 x1 x2 x3 x4 x5 x6 \u2502 Float64 Float64 Float64 Float64 Float64 Float64 \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 \u2502 0.73 0.0006 0.015 0.12 0.082 0.146 2 \u2502 0.24 0.00025 0.03 0.143 0.133 0.108 3 \u2502 0.47 0.0019 0.024 0.102 0.131 0.078 4 \u2502 0.64 0.0009 0.017 0.077 0.09 0.085 5 \u2502 0.23 0.00025 0.026 0.139 0.09 0.153 6 \u2502 0.69 0.00025 0.016 0.086 0.07 0.123 7 \u2502 0.85 0.00025 0.023 0.128 0.104 0.121 8 \u2502 0.48 0.00208 0.02 0.086 0.078 0.11 \u22ee \u2502 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 7194 \u2502 0.7 0.0009 0.015 0.104 0.095 0.109 7195 \u2502 0.79 0.0049 0.0201 0.077 0.082 0.094 7196 \u2502 0.59 0.0025 0.0208 0.079 0.099 0.08 7197 \u2502 0.51 0.106 0.006 0.005 0.089 0.0055 7198 \u2502 0.51 0.00076 0.0201 0.09 0.067 0.134 7199 \u2502 0.35 0.0028 0.0201 0.09 0.089 0.101 7200 \u2502 0.73 0.00056 0.0201 0.081 0.09 0.09 7185 rows omitted, CategoricalArrays.CategoricalValue{String, UInt32}[\"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\" \u2026 \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"outlier\", \"normal\", \"normal\", \"normal\"]) Data formats Because OutlierDetection.jl is built upon MLJ, there are some things to know regarding the data used in outlier detection tasks. A detector can typically be instantiated with continuous data X satisfying the Tables.jl interface. Often we use DataFrames.jl to create such tables. An important distinction to know is the difference between machine types and scientific types . The machine type refers to the Julia type being used to represent the object (for instance, Float64). The scientific type is one of the types defined in ScientificTypes.jl reflecting how the object should be interpreted (for instance, Continuous or Multiclass ). We can examine the machine and scientific types of our loaded dataframe X with ScientificTypes.schema . schema ( X ) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 _.names \u2502 _.types \u2502 _.scitypes \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 x1 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x2 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x3 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x4 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x5 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x6 \u2502 Float64 \u2502 Continuous \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 _.nrows = 7200 Fortunately, our table contains only Continuous data as expected. Labels in outlier detection are always encoded as a categorical vectors with classes \"normal\" and \"outlier\" and scitype OrderedFactor{2} . Data with type OrderedFactor{2} is considered to have an intrinsic \"positive\" class, in our case \"outlier\" . Measures, such as true_positive assume the second class in the ordering is the \"positive\" class. Using the helper to_categorical , we can transform a Vector{String} to a categorical vector, which ensures there are only two classes and the positive class is \"outlier\" . We don't need to coerce y to a categorical array in our example because load already returns categorical vectors. to_categorical ([ \"normal\" , \"normal\" , \"outlier\" ]) 3-element CategoricalArrays.CategoricalArray{String,1,UInt32}: \"normal\" \"normal\" \"outlier\" Loading models Having the data ready, we can list all available detectors in MLJ. By convention, a detector is named $(Name)Detector in MLJ, e.g. KNNDetector and we can thus simply search for \"Detector\". models ( \"Detector\" ) 25-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype), T} where T<:Tuple}: (name = ABODDetector, package_name = OutlierDetectionNeighbors, ... ) (name = ABODDetector, package_name = OutlierDetectionPython, ... ) (name = AEDetector, package_name = OutlierDetectionNetworks, ... ) (name = CBLOFDetector, package_name = OutlierDetectionPython, ... ) (name = COFDetector, package_name = OutlierDetectionNeighbors, ... ) (name = COFDetector, package_name = OutlierDetectionPython, ... ) (name = COPODDetector, package_name = OutlierDetectionPython, ... ) (name = DNNDetector, package_name = OutlierDetectionNeighbors, ... ) (name = DSADDetector, package_name = OutlierDetectionNetworks, ... ) (name = ESADDetector, package_name = OutlierDetectionNetworks, ... ) \u22ee (name = LODADetector, package_name = OutlierDetectionPython, ... ) (name = LOFDetector, package_name = OutlierDetectionNeighbors, ... ) (name = LOFDetector, package_name = OutlierDetectionPython, ... ) (name = MCDDetector, package_name = OutlierDetectionPython, ... ) (name = OCSVMDetector, package_name = OutlierDetectionPython, ... ) (name = PCADetector, package_name = OutlierDetectionPython, ... ) (name = RODDetector, package_name = OutlierDetectionPython, ... ) (name = SODDetector, package_name = OutlierDetectionPython, ... ) (name = SOSDetector, package_name = OutlierDetectionPython, ... ) Loading a detector of your choice is simple with @load or @iload , see loading model code . There are multiple detectors named KNNDetector , thus we specify the package beforehand. KNN = @iload KNNDetector pkg = OutlierDetectionNeighbors verbosity = 0 OutlierDetectionNeighbors.KNNDetector To enable later evaluation, we wrap a raw detector (which only defines transform returning raw outlier scores) in a ProbabilisticDetector ; this enables us to predict outlier probabilities from the raw scores. knn = ProbabilisticDetector ( KNN ()) ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, detector = KNNDetector( k = 5, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum)) Note that the call above assumes that you want to use the default parameters to instantiate the OutlierDetectionNeighbors.KNNDetector and ProbabilisticDetector , e.g. k=5 so on. Model evaluation We can now evaluate how such a model performs. By default, a probabilistic detector is evaluated using area_under_curve , but there are a lot of other evaluation strategies available, see the list of measures . We use stratified five-fold cross validation to evaluate our model, but other resampling strategies are possible as well. cv = StratifiedCV ( nfolds = 5 , shuffle = true , rng = 0 ) evaluate ( knn , X , y ; resampling = cv ) PerformanceEvaluation object with these fields: measure, measurement, operation, per_fold, per_observation, fitted_params_per_fold, report_per_fold, train_test_pairs Extract: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 measure \u2502 measurement \u2502 operation \u2502 per_fold \u22ef \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 AreaUnderCurve() \u2502 0.747 \u2502 predict \u2502 [0.767, 0.725, 0.707, 0.753, 0. \u22ef \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 column omitted Model optimization As previously mentioned, we used the default parameters to create our model. However, we typically don't know an appropriate amount of neighbors ( k ) beforehand. Using MLJ's built-in model tuning we can identify the best k given some performance measure. Let's first define a range of possible parameter values for k . r = range ( knn , : ( detector . k ), values = [ 1 , 2 , 3 , 4 , 5 : 5 : 100 ... ]) NominalRange(detector.k = 1, 2, 3, ...) We can then use this range, or multiple ranges, to create a tuned model by additionally specifing a tuning-strategy , which defines how to efficiently evaluate ranges. In our case we use a simple grid search to evaluate all the given parameter options. t = TunedModel ( model = knn , resampling = cv , tuning = Grid (), range = r , acceleration = CPUThreads ()) ProbabilisticTunedModel( model = ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, detector = KNNDetector), tuning = Grid( goal = nothing, resolution = 10, shuffle = true, rng = Random._GLOBAL_RNG()), resampling = StratifiedCV( nfolds = 5, shuffle = true, rng = MersenneTwister(0, (0, 11022, 10020, 443))), measure = AreaUnderCurve(), weights = nothing, operation = nothing, range = NominalRange(detector.k = 1, 2, 3, ...), selection_heuristic = MLJTuning.NaiveSelection(nothing), train_best = true, repeats = 1, n = nothing, acceleration = ComputationalResources.CPUThreads{Int64}(1), acceleration_resampling = ComputationalResources.CPU1{Nothing}(nothing), check_measure = true, cache = true) We can again bind that model to data and fit it. Fitting a tuned model instigates a search for optimal model hyperparameters, within specified range s, and then uses all supplied data to train the best model. m = machine ( t , X , y ) |> fit! Machine{ProbabilisticTunedModel{Grid,\u2026},\u2026} trained 1 time; caches data args: 1: Source @835 \u23ce `Table{AbstractVector{Continuous}}` 2: Source @988 \u23ce `AbstractVector{OrderedFactor{2}}` Using the machines' report, we can idenity the best evaluation results. report ( m ) . best_history_entry (model = ProbabilisticUnsupervisedCompositeDetector{,\u2026}, measure = [AreaUnderCurve()], measurement = [0.7674529768473908], per_fold = [[0.7635922604735368, 0.7779655194172375, 0.7775027869116812, 0.7748175361597409, 0.743386781274758]],) Additionally, we can easily extract the best identified model. b = report ( m ) . best_model ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, detector = KNNDetector( k = 1, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum)) Let's evaluate the best model again to make sure it achieves the expected performance. evaluate ( b , X , y , resampling = cv ) PerformanceEvaluation object with these fields: measure, measurement, operation, per_fold, per_observation, fitted_params_per_fold, report_per_fold, train_test_pairs Extract: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 measure \u2502 measurement \u2502 operation \u2502 per_fold \u22ef \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 AreaUnderCurve() \u2502 0.767 \u2502 predict \u2502 [0.764, 0.778, 0.778, 0.775, 0. \u22ef \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 column omitted Model usage Now that we have found the best model, we can use it to determine outliers in the data. Converting scores to classes can be achieved with a DeterministicDetector . Let's create some fake train/test indices and suppose we want to identify outliers in the test data. train , test = partition ( eachindex ( y ), 0.5 , shuffle = true , stratify = y , rng = 0 ) ([2031, 4888, 6696, 4906, 527, 2594, 303, 1542, 4275, 6202 \u2026 4723, 3464, 1779, 3003, 5096, 3151, 5887, 2305, 3819, 922], [899, 6722, 253, 514, 5683, 4430, 4214, 6985, 2566, 1357 \u2026 214, 3589, 4588, 3590, 2444, 5272, 5401, 276, 4497, 83]) Let's determine the outlier_fraction in the training data, which we then use to determine a threshold to convert the outlier scores into classes. Using classify_quantile , we can create a classification function based on quantiles of the training data. In the following example we define an outlier's score to lie above the 1 - outlier_fraction training scores' quantile. threshold = classify_quantile ( 1 - outlier_fraction ( y [ train ])) final = machine ( DeterministicDetector ( b . detector , classify = threshold ), X ) fit! ( final , rows = train ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 1 time; caches data args: 1: Source @963 \u23ce `Table{AbstractVector{Continuous}}` Using predict allows us to determine the outliers in the test data. y\u0302 = predict ( final , rows = test ) 3600-element CategoricalArrays.CategoricalArray{String,1,UInt32}: \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \u22ee \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"outlier\" Model persistence Finally, we can store the model with MLJ.save . MLJ . save ( \"final.jlso\" , final ) Loading the model again, the machine is not bound to data anymore, but we can bind it to data if we supply X again. final = machine ( \"final.jlso\" ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 1 time; caches data args: We can still use the machine to predict, even though its not bound to data. y\u0302 == predict ( final , X [ test , : ]) true If you would like to know how you can combine detectors or how to develop your own detectors, continue with the Advanced Usage guide.","title":"Simple Usage"},{"location":"documentation/simple-usage/#simple-usage","text":"Let's import the necessary packages first. using MLJ using OutlierDetection using OutlierDetectionData : ODDS","title":"Simple Usage"},{"location":"documentation/simple-usage/#loading-data","text":"We can list the available datasets in the imported ODDS dataset collection with list ODDS . list () 27-element Vector{String}: \"annthyroid\" \"arrhythmia\" \"breastw\" \"cardio\" \"cover\" \"glass\" \"http\" \"ionosphere\" \"letter\" \"lympho\" \u22ee \"satimage-2\" \"shuttle\" \"smtp\" \"speech\" \"thyroid\" \"vertebral\" \"vowels\" \"wbc\" \"wine\" We can now load a dataset by specifying its name. X , y = ODDS . load ( \"annthyroid\" ) (7200\u00d76 DataFrame Row \u2502 x1 x2 x3 x4 x5 x6 \u2502 Float64 Float64 Float64 Float64 Float64 Float64 \u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 \u2502 0.73 0.0006 0.015 0.12 0.082 0.146 2 \u2502 0.24 0.00025 0.03 0.143 0.133 0.108 3 \u2502 0.47 0.0019 0.024 0.102 0.131 0.078 4 \u2502 0.64 0.0009 0.017 0.077 0.09 0.085 5 \u2502 0.23 0.00025 0.026 0.139 0.09 0.153 6 \u2502 0.69 0.00025 0.016 0.086 0.07 0.123 7 \u2502 0.85 0.00025 0.023 0.128 0.104 0.121 8 \u2502 0.48 0.00208 0.02 0.086 0.078 0.11 \u22ee \u2502 \u22ee \u22ee \u22ee \u22ee \u22ee \u22ee 7194 \u2502 0.7 0.0009 0.015 0.104 0.095 0.109 7195 \u2502 0.79 0.0049 0.0201 0.077 0.082 0.094 7196 \u2502 0.59 0.0025 0.0208 0.079 0.099 0.08 7197 \u2502 0.51 0.106 0.006 0.005 0.089 0.0055 7198 \u2502 0.51 0.00076 0.0201 0.09 0.067 0.134 7199 \u2502 0.35 0.0028 0.0201 0.09 0.089 0.101 7200 \u2502 0.73 0.00056 0.0201 0.081 0.09 0.09 7185 rows omitted, CategoricalArrays.CategoricalValue{String, UInt32}[\"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\" \u2026 \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"outlier\", \"normal\", \"normal\", \"normal\"])","title":"Loading data"},{"location":"documentation/simple-usage/#data-formats","text":"Because OutlierDetection.jl is built upon MLJ, there are some things to know regarding the data used in outlier detection tasks. A detector can typically be instantiated with continuous data X satisfying the Tables.jl interface. Often we use DataFrames.jl to create such tables. An important distinction to know is the difference between machine types and scientific types . The machine type refers to the Julia type being used to represent the object (for instance, Float64). The scientific type is one of the types defined in ScientificTypes.jl reflecting how the object should be interpreted (for instance, Continuous or Multiclass ). We can examine the machine and scientific types of our loaded dataframe X with ScientificTypes.schema . schema ( X ) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 _.names \u2502 _.types \u2502 _.scitypes \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 x1 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x2 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x3 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x4 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x5 \u2502 Float64 \u2502 Continuous \u2502 \u2502 x6 \u2502 Float64 \u2502 Continuous \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 _.nrows = 7200 Fortunately, our table contains only Continuous data as expected. Labels in outlier detection are always encoded as a categorical vectors with classes \"normal\" and \"outlier\" and scitype OrderedFactor{2} . Data with type OrderedFactor{2} is considered to have an intrinsic \"positive\" class, in our case \"outlier\" . Measures, such as true_positive assume the second class in the ordering is the \"positive\" class. Using the helper to_categorical , we can transform a Vector{String} to a categorical vector, which ensures there are only two classes and the positive class is \"outlier\" . We don't need to coerce y to a categorical array in our example because load already returns categorical vectors. to_categorical ([ \"normal\" , \"normal\" , \"outlier\" ]) 3-element CategoricalArrays.CategoricalArray{String,1,UInt32}: \"normal\" \"normal\" \"outlier\"","title":"Data formats"},{"location":"documentation/simple-usage/#loading-models","text":"Having the data ready, we can list all available detectors in MLJ. By convention, a detector is named $(Name)Detector in MLJ, e.g. KNNDetector and we can thus simply search for \"Detector\". models ( \"Detector\" ) 25-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype), T} where T<:Tuple}: (name = ABODDetector, package_name = OutlierDetectionNeighbors, ... ) (name = ABODDetector, package_name = OutlierDetectionPython, ... ) (name = AEDetector, package_name = OutlierDetectionNetworks, ... ) (name = CBLOFDetector, package_name = OutlierDetectionPython, ... ) (name = COFDetector, package_name = OutlierDetectionNeighbors, ... ) (name = COFDetector, package_name = OutlierDetectionPython, ... ) (name = COPODDetector, package_name = OutlierDetectionPython, ... ) (name = DNNDetector, package_name = OutlierDetectionNeighbors, ... ) (name = DSADDetector, package_name = OutlierDetectionNetworks, ... ) (name = ESADDetector, package_name = OutlierDetectionNetworks, ... ) \u22ee (name = LODADetector, package_name = OutlierDetectionPython, ... ) (name = LOFDetector, package_name = OutlierDetectionNeighbors, ... ) (name = LOFDetector, package_name = OutlierDetectionPython, ... ) (name = MCDDetector, package_name = OutlierDetectionPython, ... ) (name = OCSVMDetector, package_name = OutlierDetectionPython, ... ) (name = PCADetector, package_name = OutlierDetectionPython, ... ) (name = RODDetector, package_name = OutlierDetectionPython, ... ) (name = SODDetector, package_name = OutlierDetectionPython, ... ) (name = SOSDetector, package_name = OutlierDetectionPython, ... ) Loading a detector of your choice is simple with @load or @iload , see loading model code . There are multiple detectors named KNNDetector , thus we specify the package beforehand. KNN = @iload KNNDetector pkg = OutlierDetectionNeighbors verbosity = 0 OutlierDetectionNeighbors.KNNDetector To enable later evaluation, we wrap a raw detector (which only defines transform returning raw outlier scores) in a ProbabilisticDetector ; this enables us to predict outlier probabilities from the raw scores. knn = ProbabilisticDetector ( KNN ()) ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, detector = KNNDetector( k = 5, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum)) Note that the call above assumes that you want to use the default parameters to instantiate the OutlierDetectionNeighbors.KNNDetector and ProbabilisticDetector , e.g. k=5 so on.","title":"Loading models"},{"location":"documentation/simple-usage/#model-evaluation","text":"We can now evaluate how such a model performs. By default, a probabilistic detector is evaluated using area_under_curve , but there are a lot of other evaluation strategies available, see the list of measures . We use stratified five-fold cross validation to evaluate our model, but other resampling strategies are possible as well. cv = StratifiedCV ( nfolds = 5 , shuffle = true , rng = 0 ) evaluate ( knn , X , y ; resampling = cv ) PerformanceEvaluation object with these fields: measure, measurement, operation, per_fold, per_observation, fitted_params_per_fold, report_per_fold, train_test_pairs Extract: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 measure \u2502 measurement \u2502 operation \u2502 per_fold \u22ef \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 AreaUnderCurve() \u2502 0.747 \u2502 predict \u2502 [0.767, 0.725, 0.707, 0.753, 0. \u22ef \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 column omitted","title":"Model evaluation"},{"location":"documentation/simple-usage/#model-optimization","text":"As previously mentioned, we used the default parameters to create our model. However, we typically don't know an appropriate amount of neighbors ( k ) beforehand. Using MLJ's built-in model tuning we can identify the best k given some performance measure. Let's first define a range of possible parameter values for k . r = range ( knn , : ( detector . k ), values = [ 1 , 2 , 3 , 4 , 5 : 5 : 100 ... ]) NominalRange(detector.k = 1, 2, 3, ...) We can then use this range, or multiple ranges, to create a tuned model by additionally specifing a tuning-strategy , which defines how to efficiently evaluate ranges. In our case we use a simple grid search to evaluate all the given parameter options. t = TunedModel ( model = knn , resampling = cv , tuning = Grid (), range = r , acceleration = CPUThreads ()) ProbabilisticTunedModel( model = ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, detector = KNNDetector), tuning = Grid( goal = nothing, resolution = 10, shuffle = true, rng = Random._GLOBAL_RNG()), resampling = StratifiedCV( nfolds = 5, shuffle = true, rng = MersenneTwister(0, (0, 11022, 10020, 443))), measure = AreaUnderCurve(), weights = nothing, operation = nothing, range = NominalRange(detector.k = 1, 2, 3, ...), selection_heuristic = MLJTuning.NaiveSelection(nothing), train_best = true, repeats = 1, n = nothing, acceleration = ComputationalResources.CPUThreads{Int64}(1), acceleration_resampling = ComputationalResources.CPU1{Nothing}(nothing), check_measure = true, cache = true) We can again bind that model to data and fit it. Fitting a tuned model instigates a search for optimal model hyperparameters, within specified range s, and then uses all supplied data to train the best model. m = machine ( t , X , y ) |> fit! Machine{ProbabilisticTunedModel{Grid,\u2026},\u2026} trained 1 time; caches data args: 1: Source @835 \u23ce `Table{AbstractVector{Continuous}}` 2: Source @988 \u23ce `AbstractVector{OrderedFactor{2}}` Using the machines' report, we can idenity the best evaluation results. report ( m ) . best_history_entry (model = ProbabilisticUnsupervisedCompositeDetector{,\u2026}, measure = [AreaUnderCurve()], measurement = [0.7674529768473908], per_fold = [[0.7635922604735368, 0.7779655194172375, 0.7775027869116812, 0.7748175361597409, 0.743386781274758]],) Additionally, we can easily extract the best identified model. b = report ( m ) . best_model ProbabilisticUnsupervisedCompositeDetector( normalize = OutlierDetection.scale_minmax, combine = OutlierDetection.combine_mean, detector = KNNDetector( k = 1, metric = Distances.Euclidean(0.0), algorithm = :kdtree, leafsize = 10, reorder = true, parallel = false, reduction = :maximum)) Let's evaluate the best model again to make sure it achieves the expected performance. evaluate ( b , X , y , resampling = cv ) PerformanceEvaluation object with these fields: measure, measurement, operation, per_fold, per_observation, fitted_params_per_fold, report_per_fold, train_test_pairs Extract: \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 measure \u2502 measurement \u2502 operation \u2502 per_fold \u22ef \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502 AreaUnderCurve() \u2502 0.767 \u2502 predict \u2502 [0.764, 0.778, 0.778, 0.775, 0. \u22ef \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 1 column omitted","title":"Model optimization"},{"location":"documentation/simple-usage/#model-usage","text":"Now that we have found the best model, we can use it to determine outliers in the data. Converting scores to classes can be achieved with a DeterministicDetector . Let's create some fake train/test indices and suppose we want to identify outliers in the test data. train , test = partition ( eachindex ( y ), 0.5 , shuffle = true , stratify = y , rng = 0 ) ([2031, 4888, 6696, 4906, 527, 2594, 303, 1542, 4275, 6202 \u2026 4723, 3464, 1779, 3003, 5096, 3151, 5887, 2305, 3819, 922], [899, 6722, 253, 514, 5683, 4430, 4214, 6985, 2566, 1357 \u2026 214, 3589, 4588, 3590, 2444, 5272, 5401, 276, 4497, 83]) Let's determine the outlier_fraction in the training data, which we then use to determine a threshold to convert the outlier scores into classes. Using classify_quantile , we can create a classification function based on quantiles of the training data. In the following example we define an outlier's score to lie above the 1 - outlier_fraction training scores' quantile. threshold = classify_quantile ( 1 - outlier_fraction ( y [ train ])) final = machine ( DeterministicDetector ( b . detector , classify = threshold ), X ) fit! ( final , rows = train ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 1 time; caches data args: 1: Source @963 \u23ce `Table{AbstractVector{Continuous}}` Using predict allows us to determine the outliers in the test data. y\u0302 = predict ( final , rows = test ) 3600-element CategoricalArrays.CategoricalArray{String,1,UInt32}: \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \u22ee \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"normal\" \"outlier\"","title":"Model usage"},{"location":"documentation/simple-usage/#model-persistence","text":"Finally, we can store the model with MLJ.save . MLJ . save ( \"final.jlso\" , final ) Loading the model again, the machine is not bound to data anymore, but we can bind it to data if we supply X again. final = machine ( \"final.jlso\" ) Machine{DeterministicUnsupervisedCompositeDetector{,\u2026},\u2026} trained 1 time; caches data args: We can still use the machine to predict, even though its not bound to data. y\u0302 == predict ( final , X [ test , : ]) true If you would like to know how you can combine detectors or how to develop your own detectors, continue with the Advanced Usage guide.","title":"Model persistence"}]}