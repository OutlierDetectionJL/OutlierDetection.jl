{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"API/datasets/","title":"Datasets","text":""},{"location":"API/datasets/#datasets","title":"Datasets","text":"<p><code>OutlierDetectionData</code> provides access to collections of outlier detection datasets. The following collections are currently supported:</p> <ul> <li>ODDS, Outlier Detection DataSets, Shebuti Rayana, 2016</li> <li>ELKI, On the Evaluation of Unsupervised Outlier Detection, Campos et al., 2016</li> </ul> <p>The following methods are defined for all collections.</p> <p></p> <p></p>"},{"location":"API/datasets/#list","title":"<code>list</code>","text":"<p># <code>OutlierDetectionData.list</code> \u2014 Function.</p> <pre><code>list([prefix])\n</code></pre> <p>List the available datasets in a dataset collection optionally given a prefix.</p> <p>Parameters</p> <pre><code>prefix::Union{Regex, AbstractString}\n</code></pre> <p>Regex or string used to filter the datasets.    </p> <p></p> <p></p>"},{"location":"API/datasets/#load","title":"<code>load</code>","text":"<p># <code>OutlierDetectionData.load</code> \u2014 Function.</p> <pre><code>load(dataset)\n</code></pre> <p>Load a given dataset from a dataset collection.</p> <p>Parameters</p> <pre><code>name::AbstractString\n</code></pre> <p>Name of the dataset to load.</p>"},{"location":"API/detectors/","title":"Detectors","text":""},{"location":"API/detectors/#detectors","title":"Detectors","text":"<p>A <code>Detector</code> is just a collection of hyperparameters. Each detector implements a <code>fit</code> and <code>transform</code> method, where fit refers to learning a model from training data and transform refers to using a learned model to calculate outlier scores of new data. Detectors typically do not classify samples into inliers and outliers; that's a <code>DeterministicDetector</code> wrapper is used to convert the raw scores into binary labels.</p> <p></p> <p></p>"},{"location":"API/detectors/#neighbor-based","title":"Neighbor-based","text":""},{"location":"API/detectors/#aboddetector","title":"<code>ABODDetector</code>","text":"<p># <code>OutlierDetectionNeighbors.ABODDetector</code> \u2014 Type.</p> <pre><code>ABODDetector(k = 5,\n             metric = Euclidean(),\n             algorithm = :kdtree,\n             static = :auto,\n             leafsize = 10,\n             reorder = true,\n             parallel = false,\n             enhanced = false)\n</code></pre> <p>Determine outliers based on the angles to its nearest neighbors. This implements the <code>FastABOD</code> variant described in the paper, that is, it uses the variance of angles to its nearest neighbors, not to the whole dataset, see [1]. </p> <p>Notice: The scores are inverted, to conform to our notion that higher scores describe higher outlierness.</p> <p>Parameters</p> <pre><code>k::Integer\n</code></pre> <p>Number of neighbors (must be greater than 0).</p> <pre><code>metric::Metric\n</code></pre> <p>This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric.</p> <pre><code>algorithm::Symbol\n</code></pre> <p>One of <code>(:kdtree, :balltree)</code>. In a <code>kdtree</code>, points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric.</p> <pre><code>static::Union{Bool, Symbol}\n</code></pre> <p>One of <code>(true, false, :auto)</code>. Whether the input data for fitting and transform should be statically or dynamically allocated. If <code>true</code>, the data is statically allocated. If <code>false</code>, the data is dynamically allocated. If <code>:auto</code>, the data is dynamically allocated if the product of all dimensions except the last is greater than 100.</p> <pre><code>leafsize::Int\n</code></pre> <p>Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points.</p> <pre><code>reorder::Bool\n</code></pre> <p>While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true.</p> <pre><code>parallel::Bool\n</code></pre> <p>Parallelize <code>score</code> and <code>predict</code> using all threads available. The number of threads can be set with the <code>JULIA_NUM_THREADS</code> environment variable. Note: <code>fit</code> is not parallel.</p> <pre><code>enhanced::Bool\n</code></pre> <p>When <code>enhanced=true</code>, it uses the enhanced ABOD (EABOD) adaptation proposed by [2].</p> <p>Examples</p> <pre><code>using OutlierDetection: ABODDetector, fit, transform\ndetector = ABODDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Kriegel, Hans-Peter; S hubert, Matthias; Zimek, Arthur (2008): Angle-based outlier detection in high-dimensional data.</p> <p>[2] Li, Xiaojie; Lv, Jian Cheng; Cheng, Dongdong (2015): Angle-Based Outlier Detection Algorithm with More Stable Relationships.</p> <p></p> <p></p>"},{"location":"API/detectors/#cofdetector","title":"<code>COFDetector</code>","text":"<p># <code>OutlierDetectionNeighbors.COFDetector</code> \u2014 Type.</p> <pre><code>COFDetector(k = 5,\n            metric = Euclidean(),\n            algorithm = :kdtree,\n            leafsize = 10,\n            reorder = true,\n            parallel = false)\n</code></pre> <p>Local outlier density based on chaining distance between graphs of neighbors, as described in [1].</p> <p>Parameters</p> <pre><code>k::Integer\n</code></pre> <p>Number of neighbors (must be greater than 0).</p> <pre><code>metric::Metric\n</code></pre> <p>This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric.</p> <pre><code>algorithm::Symbol\n</code></pre> <p>One of <code>(:kdtree, :balltree)</code>. In a <code>kdtree</code>, points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric.</p> <pre><code>static::Union{Bool, Symbol}\n</code></pre> <p>One of <code>(true, false, :auto)</code>. Whether the input data for fitting and transform should be statically or dynamically allocated. If <code>true</code>, the data is statically allocated. If <code>false</code>, the data is dynamically allocated. If <code>:auto</code>, the data is dynamically allocated if the product of all dimensions except the last is greater than 100.</p> <pre><code>leafsize::Int\n</code></pre> <p>Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points.</p> <pre><code>reorder::Bool\n</code></pre> <p>While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true.</p> <pre><code>parallel::Bool\n</code></pre> <p>Parallelize <code>score</code> and <code>predict</code> using all threads available. The number of threads can be set with the <code>JULIA_NUM_THREADS</code> environment variable. Note: <code>fit</code> is not parallel.</p> <p>Examples</p> <pre><code>using OutlierDetection: COFDetector, fit, transform\ndetector = COFDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Tang, Jian; Chen, Zhixiang; Fu, Ada Wai-Chee; Cheung, David Wai-Lok (2002): Enhancing Effectiveness of Outlier Detections for Low Density Patterns.</p> <p></p> <p></p>"},{"location":"API/detectors/#dnndetector","title":"<code>DNNDetector</code>","text":"<p># <code>OutlierDetectionNeighbors.DNNDetector</code> \u2014 Type.</p> <pre><code>DNNDetector(d = 0,\n            metric = Euclidean(),\n            algorithm = :kdtree,\n            leafsize = 10,\n            reorder = true,\n            parallel = false)\n</code></pre> <p>Anomaly score based on the number of neighbors in a hypersphere of radius <code>d</code>. Knorr et al. [1] directly converted the resulting outlier scores to labels, thus this implementation does not fully reflect the approach from the paper.</p> <p>Parameters</p> <pre><code>d::Real\n</code></pre> <p>The hypersphere radius used to calculate the global density of an instance.</p> <pre><code>metric::Metric\n</code></pre> <p>This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric.</p> <pre><code>algorithm::Symbol\n</code></pre> <p>One of <code>(:kdtree, :balltree)</code>. In a <code>kdtree</code>, points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric.</p> <pre><code>static::Union{Bool, Symbol}\n</code></pre> <p>One of <code>(true, false, :auto)</code>. Whether the input data for fitting and transform should be statically or dynamically allocated. If <code>true</code>, the data is statically allocated. If <code>false</code>, the data is dynamically allocated. If <code>:auto</code>, the data is dynamically allocated if the product of all dimensions except the last is greater than 100.</p> <pre><code>leafsize::Int\n</code></pre> <p>Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points.</p> <pre><code>reorder::Bool\n</code></pre> <p>While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true.</p> <pre><code>parallel::Bool\n</code></pre> <p>Parallelize <code>score</code> and <code>predict</code> using all threads available. The number of threads can be set with the <code>JULIA_NUM_THREADS</code> environment variable. Note: <code>fit</code> is not parallel.</p> <p>Examples</p> <pre><code>using OutlierDetection: DNNDetector, fit, transform\ndetector = DNNDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Knorr, Edwin M.; Ng, Raymond T. (1998): Algorithms for Mining Distance-Based Outliers in Large Datasets.</p> <p></p> <p></p>"},{"location":"API/detectors/#knndetector","title":"<code>KNNDetector</code>","text":"<p># <code>OutlierDetectionNeighbors.KNNDetector</code> \u2014 Type.</p> <pre><code>KNNDetector(k=5,\n            metric=Euclidean,\n            algorithm=:kdtree,\n            leafsize=10,\n            reorder=true,\n            reduction=:maximum)\n</code></pre> <p>Calculate the anomaly score of an instance based on the distance to its k-nearest neighbors.</p> <p>Parameters</p> <pre><code>k::Integer\n</code></pre> <p>Number of neighbors (must be greater than 0).</p> <pre><code>metric::Metric\n</code></pre> <p>This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric.</p> <pre><code>algorithm::Symbol\n</code></pre> <p>One of <code>(:kdtree, :balltree)</code>. In a <code>kdtree</code>, points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric.</p> <pre><code>static::Union{Bool, Symbol}\n</code></pre> <p>One of <code>(true, false, :auto)</code>. Whether the input data for fitting and transform should be statically or dynamically allocated. If <code>true</code>, the data is statically allocated. If <code>false</code>, the data is dynamically allocated. If <code>:auto</code>, the data is dynamically allocated if the product of all dimensions except the last is greater than 100.</p> <pre><code>leafsize::Int\n</code></pre> <p>Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points.</p> <pre><code>reorder::Bool\n</code></pre> <p>While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true.</p> <pre><code>parallel::Bool\n</code></pre> <p>Parallelize <code>score</code> and <code>predict</code> using all threads available. The number of threads can be set with the <code>JULIA_NUM_THREADS</code> environment variable. Note: <code>fit</code> is not parallel.</p> <pre><code>reduction::Symbol\n</code></pre> <p>One of <code>(:maximum, :median, :mean)</code>. (<code>reduction=:maximum</code>) was proposed by [1]. Angiulli et al. [2] proposed sum to reduce the distances, but mean has been implemented for numerical stability.</p> <p>Examples</p> <pre><code>using OutlierDetection: KNNDetector, fit, transform\ndetector = KNNDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Ramaswamy, Sridhar; Rastogi, Rajeev; Shim, Kyuseok (2000): Efficient Algorithms for Mining Outliers from Large Data Sets.</p> <p>[2] Angiulli, Fabrizio; Pizzuti, Clara (2002): Fast Outlier Detection in High Dimensional Spaces.</p> <p></p> <p></p>"},{"location":"API/detectors/#lofdetector","title":"<code>LOFDetector</code>","text":"<p># <code>OutlierDetectionNeighbors.LOFDetector</code> \u2014 Type.</p> <pre><code>LOFDetector(k = 5,\n            metric = Euclidean(),\n            algorithm = :kdtree,\n            leafsize = 10,\n            reorder = true,\n            parallel = false)\n</code></pre> <p>Calculate an anomaly score based on the density of an instance in comparison to its neighbors. This algorithm introduced the notion of local outliers and was developed by Breunig et al., see [1].</p> <p>Parameters</p> <pre><code>k::Integer\n</code></pre> <p>Number of neighbors (must be greater than 0).</p> <pre><code>metric::Metric\n</code></pre> <p>This is one of the Metric types defined in the Distances.jl package. It is possible to define your own metrics by creating new types that are subtypes of Metric.</p> <pre><code>algorithm::Symbol\n</code></pre> <p>One of <code>(:kdtree, :balltree)</code>. In a <code>kdtree</code>, points are recursively split into groups using hyper-planes. Therefore a KDTree only works with axis aligned metrics which are: Euclidean, Chebyshev, Minkowski and Cityblock. A brutetree linearly searches all points in a brute force fashion and works with any Metric. A balltree recursively splits points into groups bounded by hyper-spheres and works with any Metric.</p> <pre><code>static::Union{Bool, Symbol}\n</code></pre> <p>One of <code>(true, false, :auto)</code>. Whether the input data for fitting and transform should be statically or dynamically allocated. If <code>true</code>, the data is statically allocated. If <code>false</code>, the data is dynamically allocated. If <code>:auto</code>, the data is dynamically allocated if the product of all dimensions except the last is greater than 100.</p> <pre><code>leafsize::Int\n</code></pre> <p>Determines at what number of points to stop splitting the tree further. There is a trade-off between traversing the tree and having to evaluate the metric function for increasing number of points.</p> <pre><code>reorder::Bool\n</code></pre> <p>While building the tree this will put points close in distance close in memory since this helps with cache locality. In this case, a copy of the original data will be made so that the original data is left unmodified. This can have a significant impact on performance and is by default set to true.</p> <pre><code>parallel::Bool\n</code></pre> <p>Parallelize <code>score</code> and <code>predict</code> using all threads available. The number of threads can be set with the <code>JULIA_NUM_THREADS</code> environment variable. Note: <code>fit</code> is not parallel.</p> <p>Examples</p> <pre><code>using OutlierDetection: LOFDetector, fit, transform\ndetector = LOFDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Breunig, Markus M.; Kriegel, Hans-Peter; Ng, Raymond T.; Sander, J\u00f6rg (2000): LOF: Identifying Density-Based Local Outliers.</p> <p></p> <p></p>"},{"location":"API/detectors/#network-based","title":"Network-based","text":"<p>Warning</p> <p>The neural-network detectors are experimental and subject to change.</p> <p></p> <p></p>"},{"location":"API/detectors/#aedetector","title":"<code>AEDetector</code>","text":"<p># <code>OutlierDetectionNetworks.AEDetector</code> \u2014 Type.</p> <pre><code>AEDetector(encoder= Chain(),\n           decoder = Chain(),\n           batchsize= 32,\n           epochs = 1,\n           shuffle = false,\n           partial = true,\n           opt = Adam(),\n           loss = mse)\n</code></pre> <p>Calculate the anomaly score of an instance based on the reconstruction loss of an autoencoder, see [1] for an explanation of auto encoders.</p> <p>Parameters</p> <pre><code>encoder::Chain\n</code></pre> <p>Transforms the input data into a latent state with a fixed shape.</p> <pre><code>decoder::Chain\n</code></pre> <p>Transforms the latent state back into the shape of the input data.</p> <pre><code>batchsize::Integer\n</code></pre> <p>The number of samples to work through before updating the internal model parameters.</p> <pre><code>epochs::Integer\n</code></pre> <p>The number of passes of the entire training dataset the machine learning algorithm has completed. </p> <pre><code>shuffle::Bool\n</code></pre> <p>If <code>shuffle=true</code>, shuffles the observations each time iterations are re-started, else no shuffling is performed.</p> <pre><code>partial::Bool\n</code></pre> <p>If <code>partial=false</code>, drops the last mini-batch if it is smaller than the batchsize.</p> <pre><code>opt::Any\n</code></pre> <p>Any Flux-compatibale optimizer, typically a <code>struct</code>  that holds all the optimiser parameters along with a definition of <code>apply!</code> that defines how to apply the update rule associated with the optimizer.</p> <pre><code>loss::Function\n</code></pre> <p>The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples.</p> <p>Examples</p> <pre><code>using OutlierDetection: AEDetector, fit, transform\ndetector = AEDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Aggarwal, Charu C. (2017): Outlier Analysis.</p> <p></p> <p></p>"},{"location":"API/detectors/#dsaddetector","title":"<code>DSADDetector</code>","text":"<p># <code>OutlierDetectionNetworks.DSADDetector</code> \u2014 Type.</p> <pre><code>DSADDetector(encoder = Chain(),\n                decoder = Chain(),\n                batchsize = 32,\n                epochs = 1,\n                shuffle = true,\n                partial = false,\n                opt = Adam(),\n                loss = mse,\n                eta = 1,\n                eps = 1e-6,\n                callback = _ -&gt; () -&gt; ())\n</code></pre> <p>Deep Semi-Supervised Anomaly detection technique based on the distance to a hypersphere center as described in [1].</p> <p>Parameters</p> <pre><code>encoder::Chain\n</code></pre> <p>Transforms the input data into a latent state with a fixed shape.</p> <pre><code>decoder::Chain\n</code></pre> <p>Transforms the latent state back into the shape of the input data.</p> <pre><code>batchsize::Integer\n</code></pre> <p>The number of samples to work through before updating the internal model parameters.</p> <pre><code>epochs::Integer\n</code></pre> <p>The number of passes of the entire training dataset the machine learning algorithm has completed. </p> <pre><code>shuffle::Bool\n</code></pre> <p>If <code>shuffle=true</code>, shuffles the observations each time iterations are re-started, else no shuffling is performed.</p> <pre><code>partial::Bool\n</code></pre> <p>If <code>partial=false</code>, drops the last mini-batch if it is smaller than the batchsize.</p> <pre><code>opt::Any\n</code></pre> <p>Any Flux-compatibale optimizer, typically a <code>struct</code>  that holds all the optimiser parameters along with a definition of <code>apply!</code> that defines how to apply the update rule associated with the optimizer.</p> <pre><code>loss::Function\n</code></pre> <p>The loss function used to calculate the reconstruction error, see https://fluxml.ai/Flux.jl/stable/models/losses/ for examples.</p> <pre><code>eta::Real\n</code></pre> <p>Weighting parameter for the labeled data; i.e. higher values of eta assign higher weight to labeled data in the svdd loss function. For a sensitivity analysis of this parameter, see [1].</p> <pre><code>eps::Real\n</code></pre> <p>Because the inverse distance used in the svdd loss can lead to division by zero, the parameters <code>eps</code> is added for numerical stability.</p> <pre><code>callback::Function\n</code></pre> <p>Experimental parameter that might change. A function to be called after the model parameters have been updated that can call Flux's callback helpers, see https://fluxml.ai/Flux.jl/stable/utilities/#Callback-Helpers-1.</p> <p>Notice: The parameters <code>batchsize</code>, <code>epochs</code>, <code>shuffle</code>, <code>partial</code>, <code>opt</code> and <code>callback</code> can also be tuples of size 2, specifying the corresponding values for (1) pretraining and (2) training; otherwise the same values are used for pretraining and training.</p> <p>Examples</p> <pre><code>using OutlierDetection: DSADDetector, fit, score\ndetector = DSADDetector()\nX = rand(10, 100)\ny = rand([-1,1], 100)\nmodel = fit(detector, X, y; verbosity=0)\ntrain_scores, test_scores = score(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Ruff, Lukas; Vandermeulen, Robert A.; G\u00f6rnitz, Nico; Binder, Alexander; M\u00fcller, Emmanuel; M\u00fcller, Klaus-Robert; Kloft, Marius (2019): Deep Semi-Supervised Anomaly Detection.</p> <p></p> <p></p>"},{"location":"API/detectors/#esaddetector","title":"<code>ESADDetector</code>","text":"<p># <code>OutlierDetectionNetworks.ESADDetector</code> \u2014 Type.</p> <pre><code>ESADDetector(encoder = Chain(),\n            decoder = Chain(),\n            batchsize = 32,\n            epochs = 1,\n            shuffle = false,\n            partial = true,\n            opt = Adam(),\n            \u03bb1 = 1,\n            \u03bb2 = 1,\n            noise = identity)\n</code></pre> <p>End-to-End semi-supervised anomaly detection algorithm similar to DeepSAD, but without the pretraining phase. The algorithm was published by Huang et al., see [1].</p> <p>Parameters</p> <pre><code>encoder::Chain\n</code></pre> <p>Transforms the input data into a latent state with a fixed shape.</p> <pre><code>decoder::Chain\n</code></pre> <p>Transforms the latent state back into the shape of the input data.</p> <pre><code>batchsize::Integer\n</code></pre> <p>The number of samples to work through before updating the internal model parameters.</p> <pre><code>epochs::Integer\n</code></pre> <p>The number of passes of the entire training dataset the machine learning algorithm has completed. </p> <pre><code>shuffle::Bool\n</code></pre> <p>If <code>shuffle=true</code>, shuffles the observations each time iterations are re-started, else no shuffling is performed.</p> <pre><code>partial::Bool\n</code></pre> <p>If <code>partial=false</code>, drops the last mini-batch if it is smaller than the batchsize.</p> <pre><code>opt::Any\n</code></pre> <p>Any Flux-compatibale optimizer, typically a <code>struct</code>  that holds all the optimiser parameters along with a definition of <code>apply!</code> that defines how to apply the update rule associated with the optimizer.</p> <pre><code>\u03bb1::Real\n</code></pre> <p>Weighting parameter of the norm loss, which minimizes the empirical variance and thus minimizes entropy.</p> <pre><code>\u03bb2::Real\n</code></pre> <p>Weighting parameter of the assistent loss function to define the consistency between the two encoders.</p> <pre><code>noise::Function (AbstractArray{T} -&gt; AbstractArray{T})\n</code></pre> <p>A function to be applied to a batch of input data to add noise, see [1] for an explanation.</p> <p>Examples</p> <pre><code>using OutlierDetection: ESADDetector, fit, score\ndetector = ESADDetector()\nX = rand(10, 100)\ny = rand([-1,1], 100)\nmodel = fit(detector, X, y; verbosity=0)\ntrain_scores, test_scores = score(detector, model, X)\n</code></pre> <p>References</p> <p>[1] Huang, Chaoqin; Ye, Fei; Zhang, Ya; Wang, Yan-Feng; Tian, Qi (2020): ESAD: End-to-end Deep Semi-supervised Anomaly Detection.</p> <p></p> <p></p>"},{"location":"API/detectors/#python-based","title":"Python-based","text":"<p>Using PyCall, we can easily integrate existing python outlier detection algorithms. Currently, almost every PyOD algorithm is integrated and can thus be easily used directly from Julia.</p> <p></p>"},{"location":"API/detectors/#aboddetector_1","title":"<code>ABODDetector</code>","text":"<p># <code>OutlierDetectionPython.ABODDetector</code> \u2014 Type.</p> <pre><code>ABODDetector(n_neighbors = 5,\n                method = \"fast\")\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.abod</p> <p></p> <p></p>"},{"location":"API/detectors/#cblofdetector","title":"<code>CBLOFDetector</code>","text":"<p># <code>OutlierDetectionPython.CBLOFDetector</code> \u2014 Type.</p> <pre><code>CBLOFDetector(n_clusters = 8,\n                 alpha = 0.9,\n                 beta = 5,\n                 use_weights = false,\n                 random_state = nothing,\n                 n_jobs = 1)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cblof</p> <p></p> <p></p>"},{"location":"API/detectors/#cddetector","title":"<code>CDDetector</code>","text":"<p># <code>OutlierDetectionPython.CDDetector</code> \u2014 Type.</p> <pre><code>CDDetector(whitening = true,\n              rule_of_thumb = false)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cd</p> <p></p>"},{"location":"API/detectors/#cofdetector_1","title":"<code>COFDetector</code>","text":"<p># <code>OutlierDetectionPython.COFDetector</code> \u2014 Type.</p> <pre><code>COFDetector(n_neighbors = 5,\n               method=\"fast\")\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.cof</p> <p></p> <p></p>"},{"location":"API/detectors/#copoddetector","title":"<code>COPODDetector</code>","text":"<p># <code>OutlierDetectionPython.COPODDetector</code> \u2014 Type.</p> <pre><code>COPODDetector(n_jobs = 1)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.copod</p> <p></p> <p></p>"},{"location":"API/detectors/#ecoddetector","title":"<code>ECODDetector</code>","text":"<p># <code>OutlierDetectionPython.ECODDetector</code> \u2014 Type.</p> <pre><code>ECODDetector(n_jobs = 1)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.ecod</p> <p></p> <p></p>"},{"location":"API/detectors/#gmmdetector","title":"<code>GMMDetector</code>","text":"<p># <code>OutlierDetectionPython.GMMDetector</code> \u2014 Type.</p> <pre><code>GMMDetector(n_components=1,\n               covariance_type=\"full\",\n               tol=0.001,\n               reg_covar=1e-06,\n               max_iter=100,\n               n_init=1,\n               init_params=\"kmeans\",\n               weights_init=None,\n               means_init=None,\n               precisions_init=None,\n               random_state=None,\n               warm_start=False)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.gmm</p> <p></p> <p></p>"},{"location":"API/detectors/#hbosdetector","title":"<code>HBOSDetector</code>","text":"<p># <code>OutlierDetectionPython.HBOSDetector</code> \u2014 Type.</p> <pre><code>HBOSDetector(n_bins = 10,\n                alpha = 0.1,\n                tol = 0.5)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.hbos</p> <p></p> <p></p>"},{"location":"API/detectors/#iforestdetector","title":"<code>IForestDetector</code>","text":"<p># <code>OutlierDetectionPython.IForestDetector</code> \u2014 Type.</p> <pre><code>IForestDetector(n_estimators = 100,\n                   max_samples = \"auto\",\n                   max_features = 1.0\n                   bootstrap = false,\n                   random_state = nothing,\n                   verbose = 0,\n                   n_jobs = 1)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.iforest</p> <p></p> <p></p>"},{"location":"API/detectors/#innedetector","title":"<code>INNEDetector</code>","text":"<p># <code>OutlierDetectionPython.INNEDetector</code> \u2014 Type.</p> <pre><code>INNEDetector(n_estimators=200,\n                max_samples=\"auto\",\n                random_state=None)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.inne</p> <p></p> <p></p>"},{"location":"API/detectors/#kdedetector","title":"<code>KDEDetector</code>","text":"<p># <code>OutlierDetectionPython.KDEDetector</code> \u2014 Type.</p> <pre><code>KDEDetector(bandwidth=1.0,\n               algorithm=\"auto\",\n               leaf_size=30,\n               metric=\"minkowski\",\n               metric_params=None)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.kde</p> <p></p>"},{"location":"API/detectors/#knndetector_1","title":"<code>KNNDetector</code>","text":"<p># <code>OutlierDetectionPython.KNNDetector</code> \u2014 Type.</p> <pre><code>KNNDetector(n_neighbors = 5,\n               method = \"largest\",\n               radius = 1.0,\n               algorithm = \"auto\",\n               leaf_size = 30,\n               metric = \"minkowski\",\n               p = 2,\n               metric_params = nothing,\n               n_jobs = 1)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.knn</p> <p></p> <p></p>"},{"location":"API/detectors/#lmdddetector","title":"<code>LMDDDetector</code>","text":"<p># <code>OutlierDetectionPython.LMDDDetector</code> \u2014 Type.</p> <pre><code>LMDDDetector(n_iter = 50,\n                dis_measure = \"aad\",\n                random_state = nothing)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.lmdd</p> <p></p> <p></p>"},{"location":"API/detectors/#lodadetector","title":"<code>LODADetector</code>","text":"<p># <code>OutlierDetectionPython.LODADetector</code> \u2014 Type.</p> <pre><code>LODADetector(n_bins = 10,\n                n_random_cuts = 100)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.loda</p> <p></p>"},{"location":"API/detectors/#lofdetector_1","title":"<code>LOFDetector</code>","text":"<p># <code>OutlierDetectionPython.LOFDetector</code> \u2014 Type.</p> <pre><code>LOFDetector(n_neighbors = 5,\n               algorithm = \"auto\",\n               leaf_size = 30,\n               metric = \"minkowski\",\n               p = 2,\n               metric_params = nothing,\n               n_jobs = 1,\n               novelty = true)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.lof</p> <p></p> <p></p>"},{"location":"API/detectors/#locidetector","title":"<code>LOCIDetector</code>","text":"<p># <code>OutlierDetectionPython.LOCIDetector</code> \u2014 Type.</p> <pre><code>LOCIDetector(alpha = 0.5,\n                k = 3)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.loci</p> <p></p> <p></p>"},{"location":"API/detectors/#mcddetector","title":"<code>MCDDetector</code>","text":"<p># <code>OutlierDetectionPython.MCDDetector</code> \u2014 Type.</p> <pre><code>MCDDetector(store_precision = true,\n               assume_centered = false,\n               support_fraction = nothing,\n               random_state = nothing)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.mcd</p> <p></p> <p></p>"},{"location":"API/detectors/#ocsvmdetector","title":"<code>OCSVMDetector</code>","text":"<p># <code>OutlierDetectionPython.OCSVMDetector</code> \u2014 Type.</p> <pre><code>OCSVMDetector(kernel = \"rbf\",\n                 degree = 3,\n                 gamma = \"auto\",\n                 coef0 = 0.0,\n                 tol = 0.001,\n                 nu = 0.5,\n                 shrinking = true,\n                 cache_size = 200,\n                 verbose = false,\n                 max_iter = -1)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.ocsvm</p> <p></p> <p></p>"},{"location":"API/detectors/#pcadetector","title":"<code>PCADetector</code>","text":"<p># <code>OutlierDetectionPython.PCADetector</code> \u2014 Type.</p> <pre><code>PCADetector(n_components = nothing,\n               n_selected_components = nothing,\n               copy = true,\n               whiten = false,\n               svd_solver = \"auto\",\n               tol = 0.0\n               iterated_power = \"auto\",\n               standardization = true,\n               weighted = true,\n               random_state = nothing)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.pca</p> <p></p> <p></p>"},{"location":"API/detectors/#roddetector","title":"<code>RODDetector</code>","text":"<p># <code>OutlierDetectionPython.RODDetector</code> \u2014 Type.</p> <pre><code>RODDetector(parallel_execution = false)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.rod</p> <p></p> <p></p>"},{"location":"API/detectors/#soddetector","title":"<code>SODDetector</code>","text":"<p># <code>OutlierDetectionPython.SODDetector</code> \u2014 Type.</p> <pre><code>SODDetector(n_neighbors = 5,\n               ref_set = 10,\n               alpha = 0.8)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.sod</p> <p></p> <p></p>"},{"location":"API/detectors/#sosdetector","title":"<code>SOSDetector</code>","text":"<p># <code>OutlierDetectionPython.SOSDetector</code> \u2014 Type.</p> <pre><code>SOSDetector(perplexity = 4.5,\n               metric = \"minkowski\",\n               eps = 1e-5)\n</code></pre> <p>https://pyod.readthedocs.io/en/latest/pyod.models.html#module-pyod.models.sos</p>"},{"location":"API/interface/","title":"Interface","text":""},{"location":"API/interface/#interface","title":"Interface","text":"<p>Here we define the abstract supertypes that all outlier detectors share as well as useful datatypes use throughout <code>OutlierDetectionJL</code> and the <code>fit</code> and <code>transform</code> methods, that have to be implemented for each detector.</p> <p></p> <p></p>"},{"location":"API/interface/#detectors","title":"Detectors","text":""},{"location":"API/interface/#detector","title":"<code>Detector</code>","text":"<p># <code>OutlierDetectionInterface.Detector</code> \u2014 Type.</p> <pre><code>Detector\n</code></pre> <p>The union type of all detectors, including supervised, semi-supervised and unsupervised detectors. Note: A semi-supervised detector can be seen as a supervised detector with <code>missing</code> labels denoting unlabeled data.</p> <p></p> <p></p>"},{"location":"API/interface/#superviseddetector","title":"<code>SupervisedDetector</code>","text":"<p># <code>OutlierDetectionInterface.SupervisedDetector</code> \u2014 Type.</p> <pre><code>SupervisedDetector\n</code></pre> <p>This abstract type forms the basis for all implemented supervised outlier detection algorithms.</p> <p></p> <p></p>"},{"location":"API/interface/#unsuperviseddetector","title":"<code>UnsupervisedDetector</code>","text":"<p># <code>OutlierDetectionInterface.UnsupervisedDetector</code> \u2014 Type.</p> <pre><code>UnsupervisedDetector\n</code></pre> <p>This abstract type forms the basis for all implemented unsupervised outlier detection algorithms.</p> <p></p> <p></p>"},{"location":"API/interface/#data-types","title":"Data types","text":""},{"location":"API/interface/#detectormodel","title":"<code>DetectorModel</code>","text":"<p># <code>OutlierDetectionInterface.DetectorModel</code> \u2014 Type.</p> <pre><code>DetectorModel\n</code></pre> <p>A <code>DetectorModel</code> represents the learned behaviour for specific <code>Detector</code>. This might include parameters in parametric models or other repesentations of the learned data in nonparametric models. In essence, it includes everything required to transform an instance to an outlier score.</p> <p></p> <p></p>"},{"location":"API/interface/#scores","title":"<code>Scores</code>","text":"<p># <code>OutlierDetectionInterface.Scores</code> \u2014 Type.</p> <pre><code>Scores::AbstractVector{&lt;:Real}\n</code></pre> <p>Scores are continuous values, where the range depends on the specific detector yielding the scores. Note: All detectors return increasing scores and higher scores are associated with higher outlierness.</p> <p></p> <p></p>"},{"location":"API/interface/#data","title":"<code>Data</code>","text":"<p># <code>OutlierDetectionInterface.Data</code> \u2014 Type.</p> <pre><code>Data::AbstractArray{&lt;:Real}\n</code></pre> <p>The raw input data for every detector is defined as<code>AbstractArray{&lt;:Real}</code> and should be a one observation per last dimension in an n-dimensional array.</p> <p></p> <p></p>"},{"location":"API/interface/#label","title":"<code>Label</code>","text":"<p># <code>OutlierDetectionInterface.Labels</code> \u2014 Type.</p> <pre><code>Labels::AbstractVector{&lt;:Union{Missing,CategoricalValue{&lt;:T,&lt;:Integer}}} where {T}\n</code></pre> <p>Labels are used for supervision and evaluation and are defined as an (categorical) vectors of strings. The convention for labels is that <code>\"outlier\"</code> indicates outliers, <code>\"normal\"</code> indicates inliers and <code>missing</code> indicates unlabeled data.</p> <p></p> <p></p>"},{"location":"API/interface/#fit","title":"<code>Fit</code>","text":"<p># <code>OutlierDetectionInterface.Fit</code> \u2014 Type.</p> <pre><code>Fit::Tuple{T, Scores} where {T}\n</code></pre> <p>A fit results in a learned model of type <code>T &lt;: Any</code> and the observed training scores of type <code>Scores</code>.</p> <p></p> <p></p>"},{"location":"API/interface/#fitresult","title":"<code>FitResult</code>","text":"<p># <code>OutlierDetectionInterface.FitResult</code> \u2014 Type.</p> <pre><code>FitResult\n</code></pre> <p>A structured fit result used as a fit return type MLJ bundling a model and the observed training scores of type <code>Scores</code>.</p> <p></p> <p></p>"},{"location":"API/interface/#functions","title":"Functions","text":""},{"location":"API/interface/#fit_1","title":"<code>fit</code>","text":"<p># <code>OutlierDetectionInterface.fit</code> \u2014 Function.</p> <pre><code>fit(detector,\n    X,\n    y;\n    verbosity)\n</code></pre> <p>Fit an unsupervised, supervised or semi-supervised outlier detector. That is, learn a <code>DetectorModel</code> from input data <code>X</code> and, in the supervised and semi-supervised setting, labels <code>y</code>. In a supervised setting, the label <code>\"outlier\"</code> represents outliers and <code>\"normal\"</code> inliers. In a semi-supervised setting, <code>missing</code> additionally represents unlabeled data. Note: Unsupervised detectors can be fitted without specifying <code>y</code>.</p> <p>Parameters</p> <pre><code>detector::Detector\n</code></pre> <p>Any <code>UnsupervisedDetector</code> or <code>SupervisedDetector</code> implementation.</p> <pre><code>X::AbstractArray{&lt;:Real}\n</code></pre> <p>An array of real values with one observation per last axis.</p> <p>Returns</p> <pre><code>fit::Fit\n</code></pre> <p>The learned model of the given detector, which contains all the necessary information for later prediction and the achieved outlier scores of the given input data <code>X</code>.</p> <p>Examples</p> <pre><code>using OutlierDetection: KNNDetector, fit, transform\ndetector = KNNDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p></p> <p></p>"},{"location":"API/interface/#transform","title":"<code>transform</code>","text":"<p># <code>OutlierDetectionInterface.transform</code> \u2014 Function.</p> <pre><code>transform(detector,\n          model,\n          X)\n</code></pre> <p>Transform input data <code>X</code> to outlier scores using an <code>UnsupervisedDetector</code> or <code>SupervisedDetector</code> and a corresponding <code>DetectorModel</code>.</p> <p>Parameters</p> <pre><code>detector::Detector\n</code></pre> <p>Any <code>UnsupervisedDetector</code> or <code>SupervisedDetector</code> implementation.</p> <pre><code>model::DetectorModel\n</code></pre> <p>The model learned from using <code>fit</code> with a <code>Detector</code></p> <pre><code>X::AbstractArray{&lt;:Real}\n</code></pre> <p>An array of real values with one observation per last axis.</p> <p>Returns</p> <pre><code>result::Scores\n</code></pre> <p>Tuple of the achieved outlier scores of the given train and test data.</p> <p>Examples</p> <pre><code>using OutlierDetection: KNNDetector, fit, transform\ndetector = KNNDetector()\nX = rand(10, 100)\nmodel, result = fit(detector, X; verbosity=0)\ntest_scores = transform(detector, model, X)\n</code></pre> <p></p> <p></p>"},{"location":"API/interface/#macros","title":"Macros","text":""},{"location":"API/interface/#detector_1","title":"<code>@detector</code>","text":"<p># <code>OutlierDetectionInterface.@detector</code> \u2014 Macro.</p> <pre><code>@detector(expr)\n</code></pre> <p>An alternative to declaring the detector struct, clean! method and keyword constructor, direcly referring to MLJModelInterface.@mlj_model.</p> <p>Parameters</p> <pre><code>expr::Expr\n</code></pre> <p>An expression of a mutable struct defining a detector's hyperparameters.</p> <p></p> <p></p>"},{"location":"API/interface/#default_frontend","title":"<code>@default_frontend</code>","text":"<p># <code>OutlierDetectionInterface.@default_frontend</code> \u2014 Macro.</p> <pre><code>@default_frontend(detector)\n</code></pre> <p>Define a data front end for a given detector, which transforms the input data to <code>OutlierDetectionInterface.Data</code>.</p> <p>Parameters</p> <pre><code>detector::T where T&lt;:Detector\n</code></pre> <p>The detector datatype for which the data frontend should be defined.</p> <p></p> <p></p>"},{"location":"API/interface/#default_metadata","title":"<code>@default_metadata</code>","text":"<p># <code>OutlierDetectionInterface.@default_metadata</code> \u2014 Macro.</p> <pre><code>@default_metadata(detector,\n                  uuid)\n</code></pre> <p>Define the default metadata for a given detector, which is useful when a detector is exported into MLJModels, such that it can be directly loaded with MLJ. By default, we assume that a detector is exported on a package's top-level and we set the <code>load_path</code> accordingly.</p> <p>Additionally, we assume the following metadata defaults:</p> <ul> <li><code>package_name</code> is equal to the <code>@__MODULE__</code>, where <code>@default_metadata</code> is used</li> <li>The detector is implemented in julia, <code>is_pure_julia=true</code></li> <li>The detector is no wrapper, <code>is_wrapper=false</code></li> <li>The package lives in the <code>OutlierDetectionJL</code> github organization</li> </ul> <p>Parameters</p> <pre><code>detector::T where T&lt;:Detector\n</code></pre> <p>The detector datatype for which the data frontend should be defined.</p> <pre><code>uuid::String\n</code></pre> <p>The UUID of the detector's package.</p>"},{"location":"API/neural-networks/","title":"Neural Networks","text":""},{"location":"API/neural-networks/#neural-networks","title":"Neural Networks","text":"<p><code>OutlierDetectionNetworks</code> contains helpers to generate simple neural-network architectures. Note that the neural-network API is highly experimental and subject to change.</p> <p></p> <p></p>"},{"location":"API/neural-networks/#multilayer-perceptron","title":"Multilayer Perceptron","text":"<p>Helpers to construct MLP networks.</p> <p></p> <p></p>"},{"location":"API/neural-networks/#mlpencoder","title":"<code>MLPEncoder</code>","text":"<p># <code>OutlierDetectionNetworks.Templates.MLPEncoder</code> \u2014 Function.</p> <pre><code>MLPEncoder(in, latent, hidden; bias)\n</code></pre> <p>A MLP encoder with variable number of hidden layers.</p> <p></p> <p></p>"},{"location":"API/neural-networks/#mlpdecoder","title":"<code>MLPDecoder</code>","text":"<p># <code>OutlierDetectionNetworks.Templates.MLPDecoder</code> \u2014 Function.</p> <pre><code>MLPDecoder(in, latent, hidden; bias)\n</code></pre> <p>A MLP decoder with variable number of hidden layers.</p> <p></p> <p></p>"},{"location":"API/neural-networks/#mlpautoencoder","title":"<code>MLPAutoEncoder</code>","text":"<p># <code>OutlierDetectionNetworks.Templates.MLPAutoEncoder</code> \u2014 Function.</p> <pre><code>MLPAutoEncoder(in, latent, hidden; bias)\n</code></pre> <p>A MLP auto-encoder with variable number of hidden layers.</p>"},{"location":"API/score-helpers/","title":"Score Helpers","text":""},{"location":"API/score-helpers/#score-helpers","title":"Score Helpers","text":"<p><code>OutlierDetection.jl</code> provides many useful helper functions to work with outlier scores. The goal of these helpers is to normalize, combine and classify raw outlier scores. The main design philosophy behind all of these functions is that they transform a tuple of train/test scores into some different train/test tuple representation, e.g. train/test classes.</p> <p></p> <p></p>"},{"location":"API/score-helpers/#transformers","title":"Transformers","text":"<p>In order to normalize scores or classify them, both the training and testing scores are necessary. We thus return a tuple of training and test scores in all <code>transform</code> calls. Transformers can make use of one or more such train/test tuples to convert them into normalized scores, probabilities or classes.</p> <p></p> <p></p>"},{"location":"API/score-helpers/#scoretransformer","title":"<code>ScoreTransformer</code>","text":"<p># <code>OutlierDetection.ScoreTransformer</code> \u2014 Type.</p> <pre><code>ScoreTransformer(combine = combine,           \n                 normalize = normalize)\n</code></pre> <p>Transform the results of a single or multiple outlier detection models to combined and normalized scores.</p> <p>Parameters</p> <p>normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See <code>scale_minmax</code> for a specific implementation.</p> <pre><code>combine::Function\n</code></pre> <p>A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See <code>combine_mean</code> for a specific implementation.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#probabilistictransformer","title":"<code>ProbabilisticTransformer</code>","text":"<p># <code>OutlierDetection.ProbabilisticTransformer</code> \u2014 Type.</p> <pre><code>ProbabilisticTransformer(combine = combine,           \n                         normalize = normalize)\n</code></pre> <p>Transform the results of a single or multiple outlier detection models to combined univariate finite distributions.</p> <p>Parameters</p> <p>normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See <code>scale_minmax</code> for a specific implementation.</p> <pre><code>combine::Function\n</code></pre> <p>A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See <code>combine_mean</code> for a specific implementation.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#deterministictransformer","title":"<code>DeterministicTransformer</code>","text":"<p># <code>OutlierDetection.DeterministicTransformer</code> \u2014 Type.</p> <pre><code>DeterministicTransformer(combine = combine,           \n                         normalize = normalize,\n                         classify = classify_quantile(DEFAULT_THRESHOLD))\n</code></pre> <p>Transform the results of a single or multiple outlier detection models to combined categorical values.</p> <p>Parameters</p> <p>normalize::Function A function to reduce a matrix, where each row represents an instance and each column a score of specific detector, to a vector of scores for each instance. See <code>scale_minmax</code> for a specific implementation.</p> <pre><code>combine::Function\n</code></pre> <p>A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See <code>combine_mean</code> for a specific implementation.</p> <p>source</p> <p>Surrogate models can be used to transform learning networks into MLJ-models.</p> <p></p> <p></p>"},{"location":"API/score-helpers/#surrogate","title":"<code>@surrogate</code>","text":"<p># <code>OutlierDetection.@surrogate</code> \u2014 Macro.</p> <pre><code>@surrogate(fn, name)\n</code></pre> <p>Create a surrogate model from a learning network, implicitly defining a composite struct using <code>name</code> and a <code>prefit</code> function using <code>fn</code>.</p> <p>Parameters</p> <pre><code>fn::Function\n</code></pre> <p>A function to reduce a matrix, where each row represents an instance and each column represents the score of specific detector, to a vector of scores for each instance. See <code>combine_mean</code> for a specific implementation.     name::Symbol The name of the resulting composite model (the surrogate model).    </p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#wrappers","title":"Wrappers","text":"<p>Wrappers take one or more detectors and transform the (combined) raw scores to probabilities (<code>ProbabilisticDetector</code>) or classes (<code>DeterministicDetector</code>). Using wrappers, you can easily evaluate outlier detection models with MLJ.</p> <p></p> <p></p>"},{"location":"API/score-helpers/#compositedetector","title":"<code>CompositeDetector</code>","text":"<p># <code>OutlierDetection.CompositeDetector</code> \u2014 Function.</p> <pre><code>CompositeDetector(unnamed_detectors...;\n                  normalize,\n                  combine,\n                  named_detectors...)\n</code></pre> <p>Transform one or more raw detectors into a single composite detector (that returns raw outlier scores).</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#probabilisticdetector","title":"<code>ProbabilisticDetector</code>","text":"<p># <code>OutlierDetection.ProbabilisticDetector</code> \u2014 Function.</p> <pre><code>ProbabilisticDetector(unnamed_detectors...;\n                      normalize,\n                      combine,\n                      named_detectors...)\n</code></pre> <p>Transform one or more raw detectors into a single probabilistic detector (that returns outlier probabilities).</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#deterministicdetector","title":"<code>DeterministicDetector</code>","text":"<p># <code>OutlierDetection.DeterministicDetector</code> \u2014 Function.</p> <pre><code>DeterministicDetector(unnamed_detectors...;\n                      normalize,\n                      combine,\n                      named_detectors...)\n</code></pre> <p>Transform one or more raw detectors into a single deterministic detector (that returns inlier and outlier classes).</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#normalization","title":"Normalization","text":"<p>These functions may be used as an input for the <code>normalize</code> keyword argument present in wrappers and transformers, they transform a tuple of train/test scores into a tuple of normalized train/test scores.</p> <p></p> <p></p>"},{"location":"API/score-helpers/#scale_minmax","title":"<code>scale_minmax</code>","text":"<p># <code>OutlierDetection.scale_minmax</code> \u2014 Function.</p> <pre><code>scale_minmax(scores)\n</code></pre> <p>Transform an array of scores into a range between [0,1] using min-max scaling.</p> <p>Parameters</p> <pre><code>  scores::Tuple{Scores, Scores}\n</code></pre> <p>A tuple consisting of two vectors representing training and test scores.</p> <p>Returns</p> <pre><code>normalized_scores::Tuple{Scores, Scores}\n</code></pre> <p>The normalized train and test scores.</p> <p>Examples</p> <pre><code>scores_train, scores_test = ([1, 2, 3], [4, 3, 2, 1, 0])\nscale_minmax(scores_train, scores_test) # ([0.0, 0.5, 1.0], [1.0, 1.0, 0.5, 0.0, 0.0])\n</code></pre> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#scale_unify","title":"<code>scale_unify</code>","text":"<p># <code>OutlierDetection.scale_unify</code> \u2014 Function.</p> <pre><code>scale_unify(scores)\n</code></pre> <p>Transform an array of scores into a range between [0,1] using unifying scores as described in [1].</p> <p>Parameters</p> <pre><code>scores::Tuple{Scores, Scores}\n</code></pre> <p>A tuple consisting of two vectors representing training and test scores.</p> <p>Returns</p> <pre><code>unified_scores::Tuple{Scores, Scores}\n</code></pre> <p>The unified train and test scores.</p> <p>Examples</p> <pre><code>scores_train, scores_test = ([1, 2, 3], [4, 3, 2, 1, 0])\nunify(scores_train, scores_test) # ([0.0, 0.0, 0.68..], [0.95.., 0.68.., 0.0, 0.0, 0.0])\n</code></pre> <p>References</p> <p>Kriegel, Hans-Peter; Kroger, Peer; Schubert, Erich; Zimek, Arthur (2011): Interpreting and Unifying Outlier Scores.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#combination","title":"Combination","text":"<p>These functions may be used as an input for the <code>combine</code> keyword argument present in wrappers and transformers. The input for the combine functions are one or more train/test score tuples or alternatively a matrix where the first columns represents train scores and the second column test scores.</p> <p></p> <p></p>"},{"location":"API/score-helpers/#combine_mean","title":"<code>combine_mean</code>","text":"<p># <code>OutlierDetection.combine_mean</code> \u2014 Function.</p> <pre><code>combine_mean(scores_mat)\n</code></pre> <p>Combination method to merge outlier scores from multiple detectors using the mean value of scores.</p> <p>Parameters</p> <pre><code>scores_mat::AbstractMatrix{T}\n</code></pre> <p>A matrix, with each row representing the scores for a specific instance and each column representing a detector.</p> <p>Returns</p> <pre><code>combined_scores::AbstractVector{T}\nThe combined scores, i.e. column-wise mean.\n</code></pre> <p>Examples</p> <pre><code>scores = [1 2; 3 4; 5 6]\ncombine_mean(scores) # [1.5, 3.5, 5.5]\n</code></pre> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#combine_median","title":"<code>combine_median</code>","text":"<p># <code>OutlierDetection.combine_median</code> \u2014 Function.</p> <pre><code>combine_median(scores_mat)\n</code></pre> <p>Combination method to merge outlier scores from multiple detectors using the median value of scores.</p> <p>Parameters</p> <pre><code>scores_mat::AbstractMatrix{T}\n</code></pre> <p>A matrix, with each row representing the scores for a specific instance and each column representing a detector.</p> <p>Returns</p> <pre><code>combined_scores::AbstractVector{T}\n</code></pre> <p>The combined scores, i.e. column-wise median.</p> <p>Examples</p> <pre><code>scores = [1 2; 3 4; 5 6]\ncombine_median(scores) # [1.5, 3.5, 5.5]\n</code></pre> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#combine_max","title":"<code>combine_max</code>","text":"<p># <code>OutlierDetection.combine_max</code> \u2014 Function.</p> <pre><code>combine_max(scores_mat)\n</code></pre> <p>Combination method to merge outlier scores from multiple detectors using the maximum value of scores.</p> <p>Parameters</p> <pre><code>scores_mat::AbstractMatrix{T}\n</code></pre> <p>A matrix, with each row representing the scores for a specific instance and each column representing a detector.</p> <p>Returns</p> <pre><code>combined_scores::AbstractVector{T}\n</code></pre> <p>The combined scores, i.e. column-wise maximum.</p> <p>Examples</p> <pre><code>scores = [1 2; 3 4; 5 6]\ncombine_max(scores) # [2, 4, 6]\n</code></pre> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#classification","title":"Classification","text":"<p>These functions may be used as an input for the <code>classify</code> keyword argument present in wrappers and transformers, they transform a tuple of train/test scores into a tuple of train/test classes.</p> <p></p> <p></p>"},{"location":"API/score-helpers/#classify_quantile","title":"<code>classify_quantile</code>","text":"<p># <code>OutlierDetection.classify_quantile</code> \u2014 Function.</p> <pre><code>classify_quantile(threshold)\n</code></pre> <p>Create a percentile-based classification function that converts <code>scores_train::Scores</code> and <code>scores_test::Scores</code> to an array of classes with <code>\"normal\"</code> indicating normal data and <code>\"outlier\"</code> indicating outliers. The conversion is based on percentiles of the training data, i.e. all datapoints above the <code>threshold</code> percentile are considered outliers.</p> <p>Parameters</p> <pre><code>threshold::Real\n</code></pre> <p>The score threshold (number between 0 and 1) used to classify the samples into inliers and outliers.</p> <pre><code>scores::Tuple{Scores, Scores}\n</code></pre> <p>A tuple consisting of two vectors representing training and test scores.</p> <p>Returns</p> <pre><code>classes::Tuple{Vector{String}, Vector{String}}\n</code></pre> <p>The vector of classes consisting of <code>\"outlier\"</code> and <code>\"normal\"</code> elements.</p> <p>Examples</p> <pre><code>classify = classify_quantile(0.9)\nscores_train, scores_test = ([1, 2, 3], [4, 3, 2])\nclassify(scores_train, scores_train) # [\"inlier\", \"inlier\", \"outlier\"]\nclassify(scores_train, scores_test) # [\"outlier\", \"outlier\", \"inlier\"]\n</code></pre> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#output-helpers","title":"Output helpers","text":""},{"location":"API/score-helpers/#to_univariate_finite","title":"<code>to_univariate_finite</code>","text":"<p># <code>OutlierDetection.to_univariate_finite</code> \u2014 Function.</p> <pre><code>to_univariate_finite(scores::Scores)\n</code></pre> <p>Convert normalized scores to a vector of univariate finite distributions. </p> <p>Parameters</p> <pre><code>scores::[`Scores`](@ref)\n</code></pre> <p>Raw vector of scores.</p> <p>Returns</p> <pre><code>scores::UnivariateFiniteVector{OrderedFactor{2}}\n</code></pre> <p>Univariate finite vector of scores.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#to_categorical","title":"<code>to_categorical</code>","text":"<p># <code>OutlierDetection.to_categorical</code> \u2014 Function.</p> <pre><code>to_categorical(classes::AbstractVector{String})\n</code></pre> <p>Convert a vector of classes (with possible missing values) to a categorical vector.</p> <p>Parameters</p> <pre><code>classes::[`Labels`](@ref)\n</code></pre> <p>A vector of classes.</p> <p>Returns</p> <pre><code>classes::CategoricalVector{Union{Missing,String}, UInt32}\n</code></pre> <p>A categorical vector of classes.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#from_univariate_finite","title":"<code>from_univariate_finite</code>","text":"<p># <code>OutlierDetection.from_univariate_finite</code> \u2014 Function.</p> <pre><code>from_univariate_finite(scores)\n</code></pre> <p>Extract the raw scores from a vector of univariate finite distributions.</p> <p>Parameters</p> <pre><code>scores::MLJ.UnivariateFiniteVector\n</code></pre> <p>A vector of univariate finite distributions.</p> <p>Returns</p> <pre><code>scores::[`Scores`](@ref)\n</code></pre> <p>A vector of raw scores.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#from_categorical","title":"<code>from_categorical</code>","text":"<p># <code>OutlierDetection.from_categorical</code> \u2014 Function.</p> <pre><code>from_categorical(classes)\n</code></pre> <p>Extract the raw classes from categorical arrays.</p> <p>Parameters</p> <pre><code>classes::MLJ.CategoricalVector\n</code></pre> <p>A vector of categorical values.</p> <p>Returns</p> <pre><code>classes::[`Labels`](@ref)\n</code></pre> <p>A vector of raw classes.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#label-helpers","title":"Label helpers","text":""},{"location":"API/score-helpers/#normal_fraction","title":"<code>normal_fraction</code>","text":"<p># <code>OutlierDetection.normal_fraction</code> \u2014 Function.</p> <pre><code>normal_fraction(y)\n</code></pre> <p>Determine the fraction of normals in a given vector.</p> <p>Parameters</p> <pre><code>y::Labels\n</code></pre> <p>An array containing \"normal\" and \"outlier\" classes.</p> <p>Returns</p> <pre><code>outlier_fraction::Float64\n</code></pre> <p>The fraction of normals.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#outlier_fraction","title":"<code>outlier_fraction</code>","text":"<p># <code>OutlierDetection.outlier_fraction</code> \u2014 Function.</p> <pre><code>outlier_fraction(y)\n</code></pre> <p>Determine the fraction of outliers in a given vector.</p> <p>Parameters</p> <pre><code>y::Labels\n</code></pre> <p>An array containing \"normal\" and \"outlier\" classes.</p> <p>Returns</p> <pre><code>outlier_fraction::Float64\n</code></pre> <p>The fraction of outliers.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#normal_count","title":"<code>normal_count</code>","text":"<p># <code>OutlierDetection.normal_count</code> \u2014 Function.</p> <pre><code>normal_count(y)\n</code></pre> <p>Determine the count of normals in a given vector.</p> <p>Parameters</p> <pre><code>y::Labels\n</code></pre> <p>An array containing \"normal\" and \"outlier\" classes.</p> <p>Returns</p> <pre><code>normal_count::Int64\n</code></pre> <p>The count of normals.</p> <p>source</p> <p></p> <p></p>"},{"location":"API/score-helpers/#outlier_count","title":"<code>outlier_count</code>","text":"<p># <code>OutlierDetection.outlier_count</code> \u2014 Function.</p> <pre><code>outlier_count(y)\n</code></pre> <p>Determine the count of outliers in a given vector.</p> <p>Parameters</p> <pre><code>y::Labels\n</code></pre> <p>An array containing \"normal\" and \"outlier\" classes.</p> <p>Returns</p> <pre><code>outlier_count::Int64\n</code></pre> <p>The count of outliers.</p> <p>source</p>"},{"location":"documentation/advanced-usage/","title":"Advanced Usage","text":""},{"location":"documentation/advanced-usage/#advanced-usage","title":"Advanced Usage","text":"<p>The simple usage guide covered how you can use and optimize an existing outlier detection model, however, sometimes it is necessary to combine the results of multiple models or create entirely new models.</p> <p></p> <p></p>"},{"location":"documentation/advanced-usage/#working-with-scores","title":"Working with scores","text":"<p>An outlier detection model, whether supervised or unsupervised, typically assigns an outlier score to each datapoint. We further differentiate between outlier scores achieved during training or testing. Because both train and test scores are essential for further score processing, e.g. converting the scores to classes, we provide a <code>transform</code> that returns a tuple of train and test scores.</p> <pre><code>using MLJ, OutlierDetection\nusing OutlierDetectionData: ODDS\n\nX, y = ODDS.load(\"annthyroid\")\ntrain, test = partition(eachindex(y), 0.5, shuffle=true, stratify=y, rng=0)\nKNN = @iload KNNDetector pkg=OutlierDetectionNeighbors verbosity=0\nknn = KNN()\n</code></pre> <pre><code>KNNDetector(\n  k = 5, \n  metric = Distances.Euclidean(0.0), \n  algorithm = :kdtree, \n  static = :auto, \n  leafsize = 10, \n  reorder = true, \n  parallel = false, \n  reduction = :maximum)\n</code></pre> <p>Let's bind the detector to data and perform a <code>transform</code>.</p> <pre><code>mach = machine(knn, X, y)\nfit!(mach, rows=train)\nscores = transform(mach, rows=test)\nscores_train, scores_test = scores\n</code></pre> <pre><code>([0.015809329524050033, 0.01227884359375915, 0.0459156835950419, 0.020099952736262826, 0.013580868897091973, 0.021063000735887565, 0.014748030376968972, 0.012825447360618655, 0.03674629232997528, 0.0058999999999999955  \u2026  0.01025134137564445, 0.01916101249934356, 0.01497412434835507, 0.015076140089558737, 0.01764709607839205, 0.06715745751590066, 0.01403980412968785, 0.010630785483678995, 0.02923597783553682, 0.02754246902512554], [0.007383319036855991, 0.012256920494153502, 0.017696609844826204, 0.024054440338532098, 0.015375304875026054, 0.023503616742961086, 0.01673977598416418, 0.010000000000000009, 0.028750652166516153, 0.008564864272129474  \u2026  0.012658597868642494, 0.010416544532617329, 0.017795867497820923, 0.04766550115125195, 0.012879689437249651, 0.021236292049225534, 0.013329906226226798, 0.03016661068134767, 0.006801698317332226, 0.10986355173577815])\n</code></pre> <p>We split the into 50% train and 50% test data, thus <code>scores_train</code> and <code>scores_test</code> should return an equal amount of scores.</p> <pre><code>scores_train\n</code></pre> <pre><code>3600-element Vector{Float64}:\n 0.015809329524050033\n 0.01227884359375915\n 0.0459156835950419\n 0.020099952736262826\n 0.013580868897091973\n 0.021063000735887565\n 0.014748030376968972\n 0.012825447360618655\n 0.03674629232997528\n 0.0058999999999999955\n \u22ee\n 0.01916101249934356\n 0.01497412434835507\n 0.015076140089558737\n 0.01764709607839205\n 0.06715745751590066\n 0.01403980412968785\n 0.010630785483678995\n 0.02923597783553682\n 0.02754246902512554\n</code></pre> <pre><code>scores_test\n</code></pre> <pre><code>3600-element Vector{Float64}:\n 0.007383319036855991\n 0.012256920494153502\n 0.017696609844826204\n 0.024054440338532098\n 0.015375304875026054\n 0.023503616742961086\n 0.01673977598416418\n 0.010000000000000009\n 0.028750652166516153\n 0.008564864272129474\n \u22ee\n 0.010416544532617329\n 0.017795867497820923\n 0.04766550115125195\n 0.012879689437249651\n 0.021236292049225534\n 0.013329906226226798\n 0.03016661068134767\n 0.006801698317332226\n 0.10986355173577815\n</code></pre> <p>OutlierDetection.jl provides many helper functions to work with scores, see score helpers. The fundamental datatype to work with scores is a tuple of train/test scores and all helper functions work with this datatype. An example for such a helper function is <code>scale_minmax</code>, which scales the scores to lie between 0 and 1 using min-max scaling.</p> <pre><code>last(scores |&gt; scale_minmax)\n</code></pre> <pre><code>3600-element Vector{Float64}:\n 0.009915879968108363\n 0.02187720506179054\n 0.03522788490341164\n 0.05083196703693757\n 0.029530684664811027\n 0.04948007559615709\n 0.032879518717070275\n 0.01633802423674759\n 0.062357923124135045\n 0.0128157573577204\n \u22ee\n 0.01736035333244564\n 0.0354714938783983\n 0.10878081177982465\n 0.02340567263385019\n 0.0439153596479345\n 0.02451064385949808\n 0.0658331231919836\n 0.008488402861413877\n 0.2614340621027081\n</code></pre> <p>Another exemplary helper function is <code>classify_quantile</code>, which is used to transform scores to classes. We only display the test scores using the <code>last</code> element of the tuple.</p> <pre><code>last(scores |&gt; classify_quantile(0.9))\n</code></pre> <pre><code>3600-element Vector{String}:\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \u22ee\n \"normal\"\n \"normal\"\n \"outlier\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"outlier\"\n</code></pre> <p>Sometimes it's also necessary to combine scores from multiple detectors, which can, for example, be achieved with <code>combine_mean</code>.</p> <pre><code>combine_mean(scores, scores) == scores\n</code></pre> <pre><code>true\n</code></pre> <p>We can see that <code>combine_mean</code> can work with multiple train/test tuples and combines them into one final tuple. In this case the resulting tuple consists of the means of the individual train and test score vectors.</p> <p></p> <p></p>"},{"location":"documentation/advanced-usage/#combining-models","title":"Combining models","text":"<p>We typically want to deal with probabilistic or deterministic predictions instead of raw scores. Using a <code>ProbabilisticDetector</code> or <code>DeterministicDetector</code>, we can simply wrap a detector to enable such predictions. Both wrappers, however, are designed such that they can work with multiple models and combine them into one probabilistic or deterministic result. When using multiple models, we have to provide them as keyword arguments as follows.</p> <pre><code>knn = ProbabilisticDetector(knn1=KNN(k=5), knn2=KNN(k=10),\n                            normalize=scale_minmax,\n                            combine=combine_mean)\n</code></pre> <pre><code>ProbabilisticUnsupervisedCompositeDetector(\n  normalize = OutlierDetection.scale_minmax, \n  combine = OutlierDetection.combine_mean, \n  knn1 = KNNDetector(\n        k = 5, \n        metric = Distances.Euclidean(0.0), \n        algorithm = :kdtree, \n        static = :auto, \n        leafsize = 10, \n        reorder = true, \n        parallel = false, \n        reduction = :maximum), \n  knn2 = KNNDetector(\n        k = 10, \n        metric = Distances.Euclidean(0.0), \n        algorithm = :kdtree, \n        static = :auto, \n        leafsize = 10, \n        reorder = true, \n        parallel = false, \n        reduction = :maximum))\n</code></pre> <p>As you can see, we additionally provided explicit arguments to <code>normalize</code> and <code>combine</code>, which take function arguments and are used for score normalization and combination. Those are the default, thus we could have also just left them unspecified and achieved the same result. The scores are always normalized before they are combined. Notice that any function that maps a train/test score tuple to a score tuple with values in the range <code>[0,1]</code> works for <code>normalization</code>. For example, if the scores are already in the range <code>[0,1]</code> we could just pass the <code>identity</code> function. Let's see the predictions of the defined detector.</p> <pre><code>mach = machine(knn, X, y)\nfit!(mach, rows=train)\npredict(mach, rows=test)\n</code></pre> <pre><code>3600-element CategoricalDistributions.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}:\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.991, outlier=&gt;0.00914)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.978, outlier=&gt;0.0224)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.963, outlier=&gt;0.0365)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.953, outlier=&gt;0.0465)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.975, outlier=&gt;0.0247)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.951, outlier=&gt;0.0485)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.966, outlier=&gt;0.0344)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.989, outlier=&gt;0.0114)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.942, outlier=&gt;0.0578)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.989, outlier=&gt;0.0115)\n \u22ee\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.985, outlier=&gt;0.0151)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.97, outlier=&gt;0.03)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.894, outlier=&gt;0.106)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.98, outlier=&gt;0.0201)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.956, outlier=&gt;0.0444)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.974, outlier=&gt;0.0262)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.939, outlier=&gt;0.0606)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.991, outlier=&gt;0.00866)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.748, outlier=&gt;0.252)\n</code></pre> <p>Pretty simple, huh?</p> <p></p> <p></p>"},{"location":"documentation/advanced-usage/#learning-networks","title":"Learning networks","text":"<p>Sometimes we need more flexibility to define outlier models. Unfortunately MLJ's linear pipelines are not yet usable for outlier detection models, thus we need to define our learning networks manually. Let's, for example, create a machine that standardizes the input features before applying the detector.</p> <pre><code>Xs, ys = source(X), source(y)\nXstd = transform(machine(Standardizer(), Xs), Xs)\ny\u0302 = predict(machine(knn, Xstd), Xstd)\n</code></pre> <pre><code>Node @327 \u2192 ProbabilisticUnsupervisedCompositeDetector(\u2026)\n  args:\n    1:  Node @609 \u2192 Standardizer(\u2026)\n  formula:\n    predict(\n      machine(ProbabilisticUnsupervisedCompositeDetector(normalize = scale_minmax, \u2026), \u2026), \n      transform(\n        machine(Standardizer(features = Symbol[], \u2026), \u2026), \n        Source @184))\n</code></pre> <p>We can <code>fit!</code> and predict with the resulting model as usual.</p> <pre><code>fit!(y\u0302, rows=train)\ny\u0302(rows=test)\n</code></pre> <pre><code>3600-element CategoricalDistributions.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}:\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.988, outlier=&gt;0.0116)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.977, outlier=&gt;0.0229)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.964, outlier=&gt;0.0359)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.958, outlier=&gt;0.0417)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.971, outlier=&gt;0.029)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.945, outlier=&gt;0.0551)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.964, outlier=&gt;0.0362)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.997, outlier=&gt;0.00341)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.937, outlier=&gt;0.0629)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.975, outlier=&gt;0.0247)\n \u22ee\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.986, outlier=&gt;0.0142)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.955, outlier=&gt;0.0451)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.888, outlier=&gt;0.112)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.961, outlier=&gt;0.0386)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.962, outlier=&gt;0.0376)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.97, outlier=&gt;0.0301)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.953, outlier=&gt;0.0471)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.987, outlier=&gt;0.0129)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.786, outlier=&gt;0.214)\n</code></pre> <p>Furthermore, if the goal is to create a standalone model from a network, we provide a helper macro called <code>@surrogate</code>, which directly let's you implement a <code>prefit</code> function and implicitly generates the required model struct. The standalone model can be bound to data again like any other model. Have a look at the original learning networks documentation if you would like to understand how prefit and composite models work.</p> <pre><code>@surrogate(StandardizedKNN) do Xs\n    Xstd = transform(machine(Standardizer(), Xs), Xs)\n    y\u0302 = predict(machine(knn, Xstd), Xstd)\n    return (;predict=y\u0302)\nend\n\nknn_std = machine(StandardizedKNN(), X)\nfit!(knn_std, rows=train)\npredict(knn_std, rows=test)\n</code></pre> <pre><code>3600-element CategoricalDistributions.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}:\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.988, outlier=&gt;0.0116)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.977, outlier=&gt;0.0229)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.964, outlier=&gt;0.0359)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.958, outlier=&gt;0.0417)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.971, outlier=&gt;0.029)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.945, outlier=&gt;0.0551)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.964, outlier=&gt;0.0362)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.997, outlier=&gt;0.00341)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.937, outlier=&gt;0.0629)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.975, outlier=&gt;0.0247)\n \u22ee\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.986, outlier=&gt;0.0142)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.955, outlier=&gt;0.0451)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.888, outlier=&gt;0.112)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.961, outlier=&gt;0.0386)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.962, outlier=&gt;0.0376)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.97, outlier=&gt;0.0301)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.953, outlier=&gt;0.0471)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.987, outlier=&gt;0.0129)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.786, outlier=&gt;0.214)\n</code></pre> <p>There might be occasions, where our <code>ProbabilisticDetector</code> or <code>DeterministicDetector</code> wrappers are not flexible enough. In such cases we can directly use <code>transform</code> in your learning networks and use a <code>ProbabilisticTransformer</code> or <code>DeterministicTransformer</code>, which takes one or more train/test tuples as inputs returning probabilistic or deterministic predictions.</p> <p></p> <p></p>"},{"location":"documentation/advanced-usage/#implementing-models","title":"Implementing models","text":"<p>Learning networks let us flexibly create complex combinations of existing models, however, sometimes it's necessary to develop new outlier detection models for specific tasks. OutlierDetection.jl builds on top of MLJ and provides a simple interface defining how an outlier detection algorithm can be implemented. Let's first import the interface and the packages relevant to our new algorithm.</p> <pre><code>import OutlierDetectionInterface\nconst OD = OutlierDetectionInterface\n\nusing Statistics:mean\nusing LinearAlgebra:norm\n</code></pre> <p>Our proposed algorithm calculates a central point from the training data and defines an outlier as a point that's far away from that center. The only hyperparameter is <code>p</code> specifying which p-norm to use to calculate the distance. Using <code>@detector</code>, which replicates <code>@mlj_model</code>, we can define our detector struct with macro-generated keyword arguments and default values.</p> <pre><code>OD.@detector mutable struct SimpleDetector &lt;: OD.UnsupervisedDetector\n    p::Float64 = 2\nend\n</code></pre> <p>Our <code>DetectorModel</code>, then, defines the learned parameters of our model. In this case the only learned parameter is the center.</p> <pre><code>struct SimpleModel &lt;: OD.DetectorModel\n    center::AbstractArray{&lt;:Real}\nend\n</code></pre> <p>Let's further define a helper function to calculate the distance from the center.</p> <pre><code>function distances_from(center, vectors::AbstractMatrix, p)\n    deviations = vectors .- center\n    return [norm(deviations[:, i], p) for i in axes(deviations, 2)]\nend\n</code></pre> <pre><code>distances_from (generic function with 1 method)\n</code></pre> <p>Finally, we can implement the two methods necessary to implement a detector, namely <code>fit</code> and <code>transform</code>. Please refer to the Key Concepts to learn more about the involved methods and types.</p> <pre><code>function OD.fit(detector::SimpleDetector, X::OD.Data; verbosity)::OD.Fit\n    center = mean(X, dims=2)\n    training_scores = distances_from(center, X, detector.p)\n    return SimpleModel(center), training_scores\nend\n\nfunction OD.transform(detector::SimpleDetector, model::SimpleModel, X::OD.Data)::OD.Scores\n    distances_from(model.center, X, detector.p)\nend\n</code></pre> <p>Using a data-frontend, we can make sure that MLJ internally transforms input data to <code>Data</code>, which refers to column-major Julia arrays with the last dimension representing an example. Registering that frontend can be achieved with <code>@default_frontend</code>.</p> <pre><code>OD.@default_frontend SimpleDetector\n</code></pre> <p>Again, we can simply wrap our detector in a <code>ProbabilisticDetector</code> to enable probabilistic predictions.</p> <pre><code>sd = machine(ProbabilisticDetector(SimpleDetector()), X, y)\nfit!(sd, rows=train)\npredict(sd, rows=test)\n</code></pre> <pre><code>3600-element CategoricalDistributions.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}:\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.903, outlier=&gt;0.0972)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.874, outlier=&gt;0.126)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.917, outlier=&gt;0.0826)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.564, outlier=&gt;0.436)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.67, outlier=&gt;0.33)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.531, outlier=&gt;0.469)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.832, outlier=&gt;0.168)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.729, outlier=&gt;0.271)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.677, outlier=&gt;0.323)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.688, outlier=&gt;0.312)\n \u22ee\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.874, outlier=&gt;0.126)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.742, outlier=&gt;0.258)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.816, outlier=&gt;0.184)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.713, outlier=&gt;0.287)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.564, outlier=&gt;0.436)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.932, outlier=&gt;0.0679)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.631, outlier=&gt;0.369)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.526, outlier=&gt;0.474)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.408, outlier=&gt;0.592)\n</code></pre> <p>Remember: Your feedback and contributions are extremely welcome, join us on Github or #outlierdetection on Slack and get involved.</p>"},{"location":"documentation/architecture/","title":"Architecture","text":""},{"location":"documentation/architecture/#architecture","title":"Architecture","text":"<p>TODO</p>"},{"location":"documentation/benchmark-datasets/","title":"Benchmark datasets","text":""},{"location":"documentation/benchmark-datasets/#benchmark-datasets","title":"Benchmark Datasets","text":"<p>TODO</p>"},{"location":"documentation/contributing/","title":"Contributing","text":""},{"location":"documentation/contributing/#how-to-contribute","title":"How to Contribute","text":"<p>OutlierDetection.jl is a community-driven project and your help is extremely welcome. If you get stuck, please don't hesitate to chat with us or raise an issue. Take a look at Github's How to Contribute Guide to find out more about what it means to contribute.</p> <p>Note: To avoid duplicating work, it is highly advised that you search through the issue tracker and the PR list. If in doubt about duplicated work, or if you want to work on a non-trivial feature, it\u2019s recommended to first open an issue in the issue tracker to get some feedbacks from core developers.</p> <p></p> <p></p>"},{"location":"documentation/contributing/#areas-of-contribution","title":"Areas of contribution","text":"<p>We value all kinds of contributions - not just code. The following table gives an overview of key contribution areas.</p> Area Description Documentation Improve or add docstrings, glossary terms, the user guide, and the example notebooks Testing Report bugs, improve or add unit tests, conduct field testing on real-world data sets Code Improve or add functionality, fix bugs Mentoring Onboarding and mentoring of new contributors Outreach Organize talks, tutorials or workshops, write blog posts Maintenance Manage and review issues/pull requests API design Design interfaces for detectors and other functionality <p></p> <p></p>"},{"location":"documentation/contributing/#reporting-bugs","title":"Reporting bugs","text":"<p>We use GitHub issues to track all bugs and feature requests; feel free to open an issue if you have found a bug or wish to see a feature implemented.</p> <p>It is recommended to check that your issue complies with the following rules before submitting:</p> <ul> <li>Verify that your issue is not being currently addressed by other issues or pull requests.</li> <li>Please ensure all code snippets and error messages are formatted in appropriate code blocks. See Creating and highlighting code blocks.</li> <li>Please be specific about what detectors and/or functions are involved and the shape of the data, as appropriate; please include a reproducible code snippet or link to a gist. If an exception is raised, please provide the traceback.</li> </ul> <p></p> <p></p>"},{"location":"documentation/contributing/#the-contribution-workflow","title":"The contribution workflow","text":"<p>The preferred workflow for contributing to OutlierDetection's repository is to fork the main repository on GitHub, clone, and develop on a new branch.</p> <ol> <li>Fork the project repository by clicking on the \\'Fork\\' button near the top right of the page. This creates a copy of the code under your GitHub user account. For more details on how to fork a repository see this guide.</li> <li>Clone your fork of the OutlierDetection.jl repo from your GitHub account to your local disk:</li> </ol> <pre><code>git clone git@github.com:USERNAME/OutlierDetection.jl.git\ncd OutlierDetection.jl\n</code></pre> <ol> <li>Configure and link the remote for your fork to the upstream repository:</li> </ol> <pre><code>git remote -v\ngit remote add upstream https://github.com/OutlierDetectionJL/OutlierDetection.git\n</code></pre> <ol> <li>Verify the new upstream repository you\\'ve specified for your fork:</li> </ol> <pre><code>git remote -v\n&gt; origin    https://github.com/USERNAME/YOUR_FORK.git (fetch)\n&gt; origin    https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)\n&gt; upstream  https://github.com/OutlierDetectionJL/OutlierDetection.jl.git (fetch)\n&gt; upstream  https://github.com/OutlierDetectionJL/OutlierDetection.jl.git (push)\n</code></pre> <ol> <li>Sync the <code>main</code> branch of your fork with the upstream repository:</li> </ol> <pre><code>git fetch upstream\ngit checkout main --track origin/main\ngit merge upstream/main\n</code></pre> <ol> <li>Create a new <code>feature</code> branch from the <code>main</code> branch to hold your changes:</li> </ol> <pre><code>git checkout main\ngit checkout -b &lt;my-feature-branch&gt;\n</code></pre> <p>Always use a <code>feature</code> branch. It\\'s good practice to never work on the <code>main</code> branch! Name the <code>feature</code> branch after your contribution.</p> <ol> <li>Develop your contribution on your feature branch. Add changed files using <code>git add</code> and then <code>git commit</code> files to record your changes in Git:</li> </ol> <pre><code>git add &lt;modified_files&gt;\ngit commit\n</code></pre> <ol> <li>When finished, push the changes to your GitHub account with:</li> </ol> <pre><code>git push --set-upstream origin my-feature-branch\n</code></pre> <ol> <li>Follow these instructions to create a pull request from your fork. If your work is still work in progress, you can open a draft pull request. We recommend to open a pull request early, so that other contributors become aware of your work and can give you feedback early on.</li> <li>To add more changes, simply repeat steps 7 - 8. Pull requests are</li> </ol> <p>updated automatically if you push new changes to the same branch.</p> <p>If any of the above seems like magic to you, please look up the Git documentation on the web. If you get stuck, feel free to chat with us.</p> <p></p> <p></p>"},{"location":"documentation/contributing/#continuous-integration","title":"Continuous integration","text":"<p>We use continuous integration services on GitHub to automatically check if new pull requests do not break anything on all the Julia versions we support. The main quality control measures right now are unit testing and test coverage. In the future we additionally want to check code style and formatting.</p> <p></p> <p></p>"},{"location":"documentation/contributing/#unit-testing","title":"Unit testing","text":"<p>We use Julia's built-in Unit Testing. The tests can be found in the test folder. To check if your code passes all tests make sure that you have the <code>OutlierDetection</code> environment activated and run <code>] test</code> from the Julia console.</p> <p></p> <p></p>"},{"location":"documentation/contributing/#test-coverage","title":"Test coverage","text":"<p>We use the Coverage.jl package and codecov to measure and compare test coverage of our code.</p> <p></p> <p></p>"},{"location":"documentation/contributing/#api-design","title":"API design","text":"<p>We follow the general design approach chosen by MLJ, which is described in the paper \"Designing Machine Learning Toolboxes: Concepts, Principles and Patterns\". Additionally, we are always looking for feedback and improvement suggestions!</p> <p></p> <p></p>"},{"location":"documentation/contributing/#documentation","title":"Documentation","text":"<p>We use Documenter.jl and mkdocs to build and deploy our online documentation.</p> <p>The source files used to generate the online documentation can be found in docs/src/. For example, the main configuration file for mkdocs is mkdocs.yml and the main page is index.md. To add new pages, you need to add a new <code>.md</code> file and include it in the <code>mkdocs.yml</code> file.</p> <p>To build the documentation locally, you need to navigate to docs/ and</p> <ol> <li>Build the markdown files with Documenter.jl:</li> </ol> <pre><code>julia --project make.jl\n</code></pre> <ol> <li>To build the website using the markdown files, run:</li> </ol> <pre><code>mkdocs build # optionally run `mkdocs serve` to build and serve locally\n</code></pre> <p>You can find the generated files in the <code>OutlierDetection.jl/docs/site/</code> folder. To view the website, open <code>OutlierDetection.jl/docs/site/index.html</code> with your preferred web browser or use <code>mkdocs serve</code> to start a local documentation server.</p> <p></p> <p></p>"},{"location":"documentation/contributing/#coding-style","title":"Coding style","text":"<p>We use DocumentFormat.jl as a code formatter. Additionally, we use a maximum line length of 120 characters.</p> <p></p> <p></p>"},{"location":"documentation/contributing/#acknowledging-contributions","title":"Acknowledging contributions","text":"<p>We follow the all-contributors specification and recognise various types of contributions. Take a look at our past and current contributors! If you are a new contributor, please make sure we add you to our list of contributors. All contributions are recorded in .all-contributorsrc.</p>"},{"location":"documentation/detector-creation/","title":"Detector creation","text":""},{"location":"documentation/detector-creation/#detector-creation","title":"Detector Creation","text":"<p>TODO</p>"},{"location":"documentation/detector-evaluation/","title":"Detector evaluation","text":""},{"location":"documentation/detector-evaluation/#detector-evaluation","title":"Detector Evaluation","text":"<p>TODO</p>"},{"location":"documentation/ensemble-learning/","title":"Ensemble learning","text":""},{"location":"documentation/ensemble-learning/#ensemble-learning","title":"Ensemble Learning","text":"<p>TODO</p>"},{"location":"documentation/getting-started/","title":"Getting Started","text":""},{"location":"documentation/getting-started/#getting-started","title":"Getting Started","text":"<p>This example demonstrates using the <code>OutlierDetection</code> API to determine the outlierness of instances in the Thyroid Disease Dataset, which is part of the ODDS collection. We use <code>OutlierDetectionData.jl</code> to load the dataset. </p> <p>Import <code>MLJ</code>, <code>OutlierDetection</code> and <code>OutlierDetectionData</code>.</p> <pre><code>using MLJ\nusing OutlierDetection\nusing OutlierDetectionData: ODDS\n</code></pre> <p>Load the <code>\"thyroid\"</code> dataset from the <code>ODDS</code> collection.</p> <pre><code>X, y = ODDS.load(\"thyroid\")\n</code></pre> <pre><code>(3772\u00d76 DataFrame\n  Row \u2502 x1        x2           x3         x4        x5        x6\n      \u2502 Float64   Float64      Float64    Float64   Float64   Float64\n\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    1 \u2502 0.774194  0.00113208   0.137571   0.275701  0.295775  0.236066\n    2 \u2502 0.247312  0.000471698  0.279886   0.329439  0.535211  0.17377\n    3 \u2502 0.494624  0.00358491   0.22296    0.233645  0.525822  0.12459\n    4 \u2502 0.677419  0.00169811   0.156546   0.175234  0.333333  0.136066\n    5 \u2502 0.236559  0.000471698  0.241935   0.320093  0.333333  0.247541\n    6 \u2502 0.731183  0.000471698  0.147059   0.196262  0.239437  0.198361\n    7 \u2502 0.903226  0.000471698  0.213472   0.294393  0.399061  0.195082\n    8 \u2502 0.505376  0.00392453   0.185009   0.196262  0.276995  0.177049\n  \u22ee   \u2502    \u22ee           \u22ee           \u22ee         \u22ee         \u22ee         \u22ee\n 3766 \u2502 0.763441  0.00943396   0.190702   0.231308  0.323944  0.185246\n 3767 \u2502 0.688172  0.000886792  0.0711575  0.35514   0.262911  0.331148\n 3768 \u2502 0.817204  0.000113208  0.190702   0.287383  0.413146  0.188525\n 3769 \u2502 0.430108  0.00245283   0.232448   0.287383  0.446009  0.17541\n 3770 \u2502 0.935484  0.0245283    0.160342   0.28271   0.375587  0.2\n 3771 \u2502 0.677419  0.0014717    0.190702   0.242991  0.323944  0.195082\n 3772 \u2502 0.483871  0.00356604   0.190702   0.212617  0.338028  0.163934\n                                                      3757 rows omitted, CategoricalArrays.CategoricalValue{String, UInt32}[\"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\"  \u2026  \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\"])\n</code></pre> <p>Create indices to split the data into 50% training and test data.</p> <pre><code>train, test = partition(eachindex(y), 0.5, shuffle=true, rng=0)\n</code></pre> <pre><code>([2913, 2848, 707, 3243, 2580, 1308, 2321, 2373, 1876, 1063  \u2026  1830, 2001, 812, 2964, 200, 1295, 3008, 1264, 3250, 893], [2757, 1446, 3184, 3035, 3682, 1489, 1391, 3379, 1272, 1499  \u2026  3294, 1176, 1305, 276, 2305, 401, 3126, 922, 83, 3649])\n</code></pre> <p>Load a <code>OutlierDetectionNeighbors.KNNDetector</code> and initialize it with <code>k=10</code> neighbors. </p> <pre><code>KNN = @iload KNNDetector pkg=OutlierDetectionNeighbors verbosity=0\nknn = KNN(k=10)\n</code></pre> <pre><code>KNNDetector(\n  k = 10, \n  metric = Distances.Euclidean(0.0), \n  algorithm = :kdtree, \n  static = :auto, \n  leafsize = 10, \n  reorder = true, \n  parallel = false, \n  reduction = :maximum)\n</code></pre> <p>Bind a raw, probabilistic and deterministic detector to data using a machine.</p> <pre><code>knn_raw = machine(knn, X)\nknn_probabilistic = machine(ProbabilisticDetector(knn), X)\nknn_deterministic = machine(DeterministicDetector(knn), X)\n</code></pre> <pre><code>untrained Machine; does not cache data\n  model: DeterministicUnsupervisedCompositeDetector(normalize = scale_minmax, \u2026)\n  args: \n    1:  Source @922 \u23ce Table{AbstractVector{Continuous}}\n</code></pre> <p>Learn models from the training data.</p> <pre><code>fit!(knn_raw, rows=train)\nfit!(knn_probabilistic, rows=train)\nfit!(knn_deterministic, rows=train)\n</code></pre> <pre><code>trained Machine; does not cache data\n  model: DeterministicUnsupervisedCompositeDetector(normalize = scale_minmax, \u2026)\n  args: \n    1:  Source @922 \u23ce Table{AbstractVector{Continuous}}\n</code></pre> <p>Transform the data into raw outlier scores.</p> <pre><code>transform(knn_raw, rows=test)\n</code></pre> <pre><code>([0.01269328678242623, 0.11156667711676535, 0.05088217126019664, 0.0841671446633964, 0.032502201393999515, 0.03766161901423662, 0.1734321580021272, 0.06473704089745065, 0.06125773587607718, 0.0490542190240858  \u2026  0.05576388438216412, 0.06427497252168496, 0.12223562779567965, 0.05180742182984218, 0.05661766603307932, 0.03708848055736689, 0.06657327635767228, 0.05110185241493615, 0.04823106409311639, 0.0635408342739163], [0.04150080722414154, 0.06332161576246768, 0.15584728188740374, 0.10211441619850055, 0.049028607009550355, 0.05535455202415265, 0.040781731999420305, 0.047055640453124284, 0.028744836441760478, 0.058699224498302595  \u2026  0.03332858315541014, 0.06395147696918803, 0.04980165081635798, 0.09253572176985131, 0.036833962818158164, 0.031917866836413324, 0.0741331730353965, 0.11129509611654069, 0.34959776501224477, 0.04514282829421119])\n</code></pre> <p>Predict outlier probabilities based on the test data.</p> <pre><code>predict(knn_probabilistic, rows=test)\n</code></pre> <pre><code>1886-element CategoricalDistributions.UnivariateFiniteVector{OrderedFactor{2}, String, UInt8, Float64}:\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.96, outlier=&gt;0.0403)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.931, outlier=&gt;0.069)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.81, outlier=&gt;0.19)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.88, outlier=&gt;0.12)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.95, outlier=&gt;0.0502)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.941, outlier=&gt;0.0585)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.961, outlier=&gt;0.0394)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.952, outlier=&gt;0.0476)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.976, outlier=&gt;0.0236)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.937, outlier=&gt;0.0629)\n \u22ee\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.93, outlier=&gt;0.0698)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.949, outlier=&gt;0.0512)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.893, outlier=&gt;0.107)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.966, outlier=&gt;0.0342)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.972, outlier=&gt;0.0278)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.917, outlier=&gt;0.0832)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.868, outlier=&gt;0.132)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.555, outlier=&gt;0.445)\n UnivariateFinite{OrderedFactor{2}}(normal=&gt;0.955, outlier=&gt;0.0451)\n</code></pre> <p>Predict outlier classes based on the test data.</p> <pre><code>predict(knn_deterministic, rows=test)\n</code></pre> <pre><code>1886-element CategoricalArrays.CategoricalArray{String,1,UInt32}:\n \"normal\"\n \"normal\"\n \"outlier\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \u22ee\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"outlier\"\n \"normal\"\n</code></pre> <p></p> <p></p>"},{"location":"documentation/getting-started/#learn-more","title":"Learn more","text":"<p>To learn more about the concepts in <code>OutlierDetection.jl</code>, check out the simple usage guide.</p>"},{"location":"documentation/installation/","title":"Installation","text":""},{"location":"documentation/installation/#installation","title":"Installation","text":"<p>It is recommended to use Pkg.jl for installation. Please make sure that you are using a compatible version of Julia. A list of compatible versions can be found our CI pipeline.</p> <p>Follow the command below to install the latest official release or use <code>] add OutlierDetection</code> in the Julia REPL.</p> <pre><code>import Pkg;\nPkg.add(\"OutlierDetection\")\n</code></pre> <p>A specific version can be installed by appending a version after a <code>@</code> symbol, e.g. <code>OutlierDetection@v0.1</code>. Additionally, you can directly install specific branches or commits by appending a <code>#</code> symbol and the corresponding branch name or commit SHA, e.g. <code>OutlierDetection#master</code>.</p> <p>If you would like to modify the package locally, you can use <code>Pkg.develop(OutlierDetection)</code> or <code>] dev OutlierDetection</code> in the Julia REPL. This fetches a full clone of the package to <code>~/.julia/dev/</code> (the path can be changed by setting the environment variable <code>JULIA_PKG_DEVDIR</code>).</p>"},{"location":"documentation/key-concepts/","title":"Key Concepts","text":""},{"location":"documentation/key-concepts/#key-concepts","title":"Key Concepts","text":"<p>This guide should provide you the necessary knowledge to work with <code>OutlierDetection.jl</code> and understand the concepts behind the library design.</p> <p>Note</p> <p>Outlier detection is predominantly an unsupervised learning task, transforming each data point to an outlier score quantifying the level of \"outlierness\". This very general form of output retains all the information provided by a specific algorithm.</p> <p>The key design choice of OutlierDetection.jl is promoting the usage of outlier scores, not labels. The main data type, a <code>Detector</code>, has to implement two methods: <code>fit</code> and <code>transform</code>.</p> <ul> <li><code>Detector</code>: A <code>struct</code> defining the hyperparameters for an outlier detection algorithm, just like an estimator in scikit-learn or a model in MLJ. A detector actually is an <code>MLJModelInterface.Model</code> (subtype).</li> <li><code>fit</code>: Learn a <code>DetectorModel</code> for a specific detector from input data <code>X</code> and labels <code>y</code> (if supervised), for example the weights of a neural network.</li> <li><code>transform</code>: Using a detector and a learned model, transform unseen data into outlier scores.</li> </ul> <p>Transforming the outlier scores to classes is seen as the last step of an outlier detection task. A Wrapper or Transformer turns scores into probabilities or labels, typically with two classes describing inliers <code>\"normal\"</code> and outliers <code>\"outlier\"</code>. </p> <p>A convention used in OutlierDetection.jl is that higher scores imply higher outlierness.</p> <p>Note</p> <p>A peculiarity of working with outlier scores is the distinction between train scores and test scores. Train scores result from fitting a detector (<code>fit</code>), and test scores result from predicting unseen data (<code>transform</code>). Classifying an instance as an inlier or outlier always requires a comparison to the train scores.</p> <p>Let's see how the data types look like in a typical outlier detection task. We use the following naming conventions for the data we are working with: </p> <ul> <li>the input data <code>OutlierDetectionInterface.Data</code></li> <li>the raw scores <code>OutlierDetectionInterface.Scores</code></li> <li>the labels <code>OutlierDetectionInterface.Labels</code></li> </ul> <p>One last unmentioned structure is the <code>Fit</code> result, a <code>struct</code> that bundles the learned model and training scores. Let's now looks how the methods defined by OutlierDetection.jl transform the mentioned data structures.</p> <pre><code>fit(::UnsupervisedDetector, ::Data; verbosity::Integer)::Fit\nfit(::SupervisedDetector, ::Data, ::Labels; verbosity::Integer)::Fit\ntransform(::Detector, ::Fit, ::Data)::Scores\n</code></pre> <p>A new outlier detection algorithm can be implemented in OutlierDetection.jl easily by implementing above <code>fit</code> and <code>transform</code> methods.</p> <p>Warning</p> <p>We expect the data to be formatted using the columns-as-observations convention for improved performance with Julia's column-major data.</p> <p></p> <p></p>"},{"location":"documentation/key-concepts/#integration-with-mlj","title":"Integration with MLJ","text":"<p>One of the exciting features of OutlierDetection.jl is it's interoperability with the rest of Julia's machine learning ecosystem. You might want to preprocess your data, cluster it, detect outliers, classify, and so forth.</p> <p>OutlierDetection.jl defines an interface for MLJ such the implemented <code>OutlierDetection.jl</code> detectors can be used directly with MLJ.</p> <ul> <li>A <code>Detector</code> is bound to data, either through <code>machine(::UnsupervisedDetector, X)</code>, or <code>machine(::SupervisedDetector, X, y)</code>.</li> <li><code>fit(::Detector, X, [y]; verbosity)</code> becomes <code>fit!(machine)</code>, which calls <code>fit</code> under the hood</li> <li><code>transform(::Detector, ::Fit, X)</code> becomes <code>transform(machine)</code>, which calls <code>transform</code> under the hood</li> </ul> <p>Additionally, OutlierDetection.jl defines a data front-end for MLJ, which ensures that <code>fit</code> and <code>transform</code> are always called with Julia arrays in column-major format, even though <code>machine(::Detector, X, y)</code> also accepts data from any Tables.jl-compatible data source.</p> <p>Take a look at our Simple Usage to learn more.</p>"},{"location":"documentation/performance-tips/","title":"Performance Tips","text":""},{"location":"documentation/performance-tips/#performance-tips","title":"Performance Tips","text":"<p>All the usual Julia performance tips apply. As always profiling your code is generally a useful way of finding bottlenecks.</p> <p>We provide a basic performance benchmarking toolkit. See benchmark/runbenchmarks.jl for usage instructions.</p>"},{"location":"documentation/simple-usage/","title":"Simple Usage","text":""},{"location":"documentation/simple-usage/#simple-usage","title":"Simple Usage","text":"<p>Let's import the necessary packages first.</p> <pre><code>using MLJ\nusing OutlierDetection\nusing OutlierDetectionData: ODDS\nusing StatisticalMeasures: area_under_curve\n</code></pre> <p></p> <p></p>"},{"location":"documentation/simple-usage/#loading-data","title":"Loading data","text":"<p>We can list the available datasets in the imported <code>ODDS</code> dataset collection with <code>list</code></p> <pre><code>ODDS.list()\n</code></pre> <pre><code>27-element Vector{String}:\n \"annthyroid\"\n \"arrhythmia\"\n \"breastw\"\n \"cardio\"\n \"cover\"\n \"glass\"\n \"http\"\n \"ionosphere\"\n \"letter\"\n \"lympho\"\n \u22ee\n \"satimage-2\"\n \"shuttle\"\n \"smtp\"\n \"speech\"\n \"thyroid\"\n \"vertebral\"\n \"vowels\"\n \"wbc\"\n \"wine\"\n</code></pre> <p>We can now <code>load</code> a dataset by specifying its name.</p> <pre><code>X, y = ODDS.load(\"annthyroid\")\n</code></pre> <pre><code>(7200\u00d76 DataFrame\n  Row \u2502 x1       x2       x3       x4       x5       x6\n      \u2502 Float64  Float64  Float64  Float64  Float64  Float64\n\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n    1 \u2502    0.73  0.0006    0.015   0.12       0.082  0.146\n    2 \u2502    0.24  0.00025   0.03    0.143      0.133  0.108\n    3 \u2502    0.47  0.0019    0.024   0.102      0.131  0.078\n    4 \u2502    0.64  0.0009    0.017   0.077      0.09   0.085\n    5 \u2502    0.23  0.00025   0.026   0.139      0.09   0.153\n    6 \u2502    0.69  0.00025   0.016   0.086      0.07   0.123\n    7 \u2502    0.85  0.00025   0.023   0.128      0.104  0.121\n    8 \u2502    0.48  0.00208   0.02    0.086      0.078  0.11\n  \u22ee   \u2502    \u22ee        \u22ee        \u22ee        \u22ee        \u22ee        \u22ee\n 7194 \u2502    0.7   0.0009    0.015   0.104      0.095  0.109\n 7195 \u2502    0.79  0.0049    0.0201  0.077      0.082  0.094\n 7196 \u2502    0.59  0.0025    0.0208  0.079      0.099  0.08\n 7197 \u2502    0.51  0.106     0.006   0.005      0.089  0.0055\n 7198 \u2502    0.51  0.00076   0.0201  0.09       0.067  0.134\n 7199 \u2502    0.35  0.0028    0.0201  0.09       0.089  0.101\n 7200 \u2502    0.73  0.00056   0.0201  0.081      0.09   0.09\n                                            7185 rows omitted, CategoricalArrays.CategoricalValue{String, UInt32}[\"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\"  \u2026  \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"normal\", \"outlier\", \"normal\", \"normal\", \"normal\"])\n</code></pre> <p></p> <p></p>"},{"location":"documentation/simple-usage/#data-formats","title":"Data formats","text":"<p>Because <code>OutlierDetection.jl</code> is built upon MLJ, there are some things to know regarding the data used in outlier detection tasks. A detector can typically be instantiated with continuous data <code>X</code> satisfying the <code>Tables.jl</code> interface. Often we use <code>DataFrames.jl</code> to create such tables. An important distinction to know is the difference between machine types and scientific types.</p> <ul> <li>The machine type refers to the Julia type being used to represent the object (for instance, Float64).</li> <li>The scientific type is one of the types defined in <code>ScientificTypes.jl</code> reflecting how the object should be interpreted (for instance, <code>Continuous</code> or <code>Multiclass</code>).</li> </ul> <p>We can examine the machine and scientific types of our loaded dataframe <code>X</code> with <code>ScientificTypes.schema</code>.</p> <pre><code>schema(X)\n</code></pre> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 names \u2502 scitypes   \u2502 types   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 x1    \u2502 Continuous \u2502 Float64 \u2502\n\u2502 x2    \u2502 Continuous \u2502 Float64 \u2502\n\u2502 x3    \u2502 Continuous \u2502 Float64 \u2502\n\u2502 x4    \u2502 Continuous \u2502 Float64 \u2502\n\u2502 x5    \u2502 Continuous \u2502 Float64 \u2502\n\u2502 x6    \u2502 Continuous \u2502 Float64 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Fortunately, our table contains only <code>Continuous</code> data as expected. Labels in outlier detection are always encoded as a categorical vectors with classes <code>\"normal\"</code> and <code>\"outlier\"</code> and scitype <code>OrderedFactor{2}</code>. Data with type <code>OrderedFactor{2}</code> is considered to have an intrinsic \"positive\" class, in our case <code>\"outlier\"</code>. Measures, such as <code>true_positive</code> assume the second class in the ordering is the \"positive\" class. Using the helper <code>to_categorical</code>, we can transform a <code>Vector{String}</code> to a categorical vector, which ensures there are only two classes and the positive class is <code>\"outlier\"</code>. We don't need to coerce <code>y</code> to a categorical array in our example because <code>load</code> already returns categorical vectors.</p> <pre><code>to_categorical([\"normal\", \"normal\", \"outlier\"])\n</code></pre> <pre><code>3-element CategoricalArrays.CategoricalArray{String,1,UInt32}:\n \"normal\"\n \"normal\"\n \"outlier\"\n</code></pre> <p></p> <p></p>"},{"location":"documentation/simple-usage/#loading-models","title":"Loading models","text":"<p>Having the data ready, we can list all available detectors in MLJ. By convention, a detector is named <code>$(Name)Detector</code> in MLJ, e.g. <code>KNNDetector</code> and we can thus simply search for \"Detector\".</p> <pre><code>models(\"Detector\")\n</code></pre> <pre><code>28-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:\n (name = ABODDetector, package_name = OutlierDetectionNeighbors, ... )\n (name = ABODDetector, package_name = OutlierDetectionPython, ... )\n (name = CBLOFDetector, package_name = OutlierDetectionPython, ... )\n (name = CDDetector, package_name = OutlierDetectionPython, ... )\n (name = COFDetector, package_name = OutlierDetectionNeighbors, ... )\n (name = COFDetector, package_name = OutlierDetectionPython, ... )\n (name = COPODDetector, package_name = OutlierDetectionPython, ... )\n (name = DNNDetector, package_name = OutlierDetectionNeighbors, ... )\n (name = ECODDetector, package_name = OutlierDetectionPython, ... )\n (name = GMMDetector, package_name = OutlierDetectionPython, ... )\n \u22ee\n (name = LOFDetector, package_name = OutlierDetectionNeighbors, ... )\n (name = LOFDetector, package_name = OutlierDetectionPython, ... )\n (name = MCDDetector, package_name = OutlierDetectionPython, ... )\n (name = OCSVMDetector, package_name = OutlierDetectionPython, ... )\n (name = OneClassSVM, package_name = LIBSVM, ... )\n (name = PCADetector, package_name = OutlierDetectionPython, ... )\n (name = RODDetector, package_name = OutlierDetectionPython, ... )\n (name = SODDetector, package_name = OutlierDetectionPython, ... )\n (name = SOSDetector, package_name = OutlierDetectionPython, ... )\n</code></pre> <p>Loading a detector of your choice is simple with <code>@load</code> or <code>@iload</code>, see loading model code. There are multiple detectors named <code>KNNDetector</code>, thus we specify the package beforehand.</p> <pre><code>KNN = @iload KNNDetector pkg=OutlierDetectionNeighbors verbosity=0\n</code></pre> <pre><code>OutlierDetectionNeighbors.KNNDetector\n</code></pre> <p>To enable later evaluation, we wrap a raw detector (which only defines <code>transform</code> returning raw outlier scores) in a <code>ProbabilisticDetector</code>; this enables us to <code>predict</code> outlier probabilities from the raw scores.</p> <pre><code>knn = ProbabilisticDetector(KNN())\n</code></pre> <pre><code>ProbabilisticUnsupervisedCompositeDetector(\n  normalize = OutlierDetection.scale_minmax, \n  combine = OutlierDetection.combine_mean, \n  detector = KNNDetector(\n        k = 5, \n        metric = Distances.Euclidean(0.0), \n        algorithm = :kdtree, \n        static = :auto, \n        leafsize = 10, \n        reorder = true, \n        parallel = false, \n        reduction = :maximum))\n</code></pre> <p>Note that the call above assumes that you want to use the default parameters to instantiate the <code>OutlierDetectionNeighbors.KNNDetector</code> and <code>ProbabilisticDetector</code>, e.g. <code>k=5</code> so on.</p> <p></p> <p></p>"},{"location":"documentation/simple-usage/#model-evaluation","title":"Model evaluation","text":"<p>We can now evaluate how such a model performs. By default, a probabilistic detector is evaluated using <code>area_under_curve</code>, but there are a lot of other evaluation strategies available, see the list of measures. We use stratified five-fold cross validation to evaluate our model, but other resampling strategies are possible as well.</p> <pre><code>cv = StratifiedCV(nfolds=5, shuffle=true, rng=0)\nevaluate(knn, X, y; resampling=cv, measure=area_under_curve)\n</code></pre> <pre><code>PerformanceEvaluation object with these fields:\n  model, measure, operation, measurement, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_rows, resampling, repeats\nExtract:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2502 measure          \u2502 operation \u2502 measurement \u2502 1.96*SE \u2502 per_fold              \u22ef\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2502 AreaUnderCurve() \u2502 predict   \u2502 0.747       \u2502 0.0293  \u2502 [0.767, 0.725, 0.707, \u22ef\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                                                1 column omitted\n</code></pre> <p></p> <p></p>"},{"location":"documentation/simple-usage/#model-optimization","title":"Model optimization","text":"<p>As previously mentioned, we used the default parameters to create our model. However, we typically don't know an appropriate amount of neighbors (<code>k</code>) beforehand. Using MLJ's built-in model tuning we can identify the best <code>k</code> given some performance measure.</p> <p>Let's first define a range of possible parameter values for <code>k</code>.</p> <pre><code>r = range(knn, :(detector.k), values=[1,2,3,4,5:5:100...])\n</code></pre> <pre><code>NominalRange(detector.k = 1, 2, 3, ...)\n</code></pre> <p>We can then use this range, or multiple ranges, to create a tuned model by additionally specifying a tuning-strategy, which defines how to efficiently evaluate ranges. In our case we use a simple grid search to evaluate all the given parameter options.</p> <pre><code>t = TunedModel(model=knn, resampling=cv, tuning=Grid(), range=r, acceleration=CPUThreads(), measure=area_under_curve)\n</code></pre> <pre><code>ProbabilisticTunedModel(\n  model = ProbabilisticUnsupervisedCompositeDetector(\n        normalize = OutlierDetection.scale_minmax, \n        combine = OutlierDetection.combine_mean, \n        detector = KNNDetector(k = 5, \u2026)), \n  tuning = Grid(\n        goal = nothing, \n        resolution = 10, \n        shuffle = true, \n        rng = Random._GLOBAL_RNG()), \n  resampling = StratifiedCV(\n        nfolds = 5, \n        shuffle = true, \n        rng = Random.MersenneTwister(0, (0, 11022, 10020, 443))), \n  measure = AreaUnderCurve(), \n  weights = nothing, \n  class_weights = nothing, \n  operation = nothing, \n  range = NominalRange(detector.k = 1, 2, 3, ...), \n  selection_heuristic = MLJTuning.NaiveSelection(nothing), \n  train_best = true, \n  repeats = 1, \n  n = nothing, \n  acceleration = ComputationalResources.CPUThreads{Int64}(1), \n  acceleration_resampling = ComputationalResources.CPU1{Nothing}(nothing), \n  check_measure = true, \n  cache = true)\n</code></pre> <p>We can again bind that model to data and fit it. Fitting a tuned model instigates a search for optimal model hyperparameters, within specified <code>range</code>s, and then uses all supplied data to train the best model.</p> <pre><code>m = machine(t, X, y) |&gt; fit!\n</code></pre> <pre><code>trained Machine; does not cache data\n  model: ProbabilisticTunedModel(model = ProbabilisticUnsupervisedCompositeDetector(normalize = scale_minmax, \u2026), \u2026)\n  args: \n    1:  Source @003 \u23ce Table{AbstractVector{Continuous}}\n    2:  Source @313 \u23ce AbstractVector{OrderedFactor{2}}\n</code></pre> <p>Using the machines' report, we can identify the best evaluation results.</p> <pre><code>report(m).best_history_entry\n</code></pre> <pre><code>(model = ProbabilisticUnsupervisedCompositeDetector(normalize = scale_minmax, \u2026),\n measure = [AreaUnderCurve()],\n measurement = [0.7674522757375343],\n per_fold = [[0.7635922604735362, 0.7779620138679535, 0.7775027869116816, 0.7748175361597406, 0.743386781274759]],)\n</code></pre> <p>Additionally, we can easily extract the best identified model.</p> <pre><code>b = report(m).best_model\n</code></pre> <pre><code>ProbabilisticUnsupervisedCompositeDetector(\n  normalize = OutlierDetection.scale_minmax, \n  combine = OutlierDetection.combine_mean, \n  detector = KNNDetector(\n        k = 1, \n        metric = Distances.Euclidean(0.0), \n        algorithm = :kdtree, \n        static = :auto, \n        leafsize = 10, \n        reorder = true, \n        parallel = false, \n        reduction = :maximum))\n</code></pre> <p>Let's evaluate the best model again to make sure it achieves the expected performance.</p> <pre><code>evaluate(b, X, y, resampling=cv, measure=area_under_curve)\n</code></pre> <pre><code>PerformanceEvaluation object with these fields:\n  model, measure, operation, measurement, per_fold,\n  per_observation, fitted_params_per_fold,\n  report_per_fold, train_test_rows, resampling, repeats\nExtract:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2502 measure          \u2502 operation \u2502 measurement \u2502 1.96*SE \u2502 per_fold              \u22ef\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2502 AreaUnderCurve() \u2502 predict   \u2502 0.767       \u2502 0.0144  \u2502 [0.764, 0.778, 0.778, \u22ef\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n                                                                1 column omitted\n</code></pre> <p></p> <p></p>"},{"location":"documentation/simple-usage/#model-usage","title":"Model usage","text":"<p>Now that we have found the best model, we can use it to determine outliers in the data. Converting scores to classes can be achieved with a <code>DeterministicDetector</code>. Let's create some fake train/test indices and suppose we want to identify outliers in the test data.</p> <pre><code>train, test = partition(eachindex(y), 0.5, shuffle=true, stratify=y, rng=0)\n</code></pre> <pre><code>([2031, 4888, 6696, 4906, 527, 2594, 303, 1542, 4275, 6202  \u2026  4723, 3464, 1779, 3003, 5096, 3151, 5887, 2305, 3819, 922], [899, 6722, 253, 514, 5683, 4430, 4214, 6985, 2566, 1357  \u2026  214, 3589, 4588, 3590, 2444, 5272, 5401, 276, 4497, 83])\n</code></pre> <p>Let's determine the <code>outlier_fraction</code> in the training data, which we then use to determine a threshold to convert the outlier scores into classes. Using <code>classify_quantile</code>, we can create a classification function based on quantiles of the training data. In the following example we define an outlier's score to lie above the 1 - outlier_fraction training scores' quantile.</p> <pre><code>threshold = classify_quantile(1 - outlier_fraction(y[train]))\nfinal = machine(DeterministicDetector(b.detector, classify=threshold), X)\nfit!(final, rows=train)\n</code></pre> <pre><code>trained Machine; does not cache data\n  model: DeterministicUnsupervisedCompositeDetector(normalize = scale_minmax, \u2026)\n  args: \n    1:  Source @293 \u23ce Table{AbstractVector{Continuous}}\n</code></pre> <p>Using <code>predict</code> allows us to determine the outliers in the test data.</p> <pre><code>y\u0302 = predict(final, rows=test)\n</code></pre> <pre><code>3600-element CategoricalArrays.CategoricalArray{String,1,UInt32}:\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \u22ee\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"normal\"\n \"outlier\"\n</code></pre> <p></p> <p></p>"},{"location":"documentation/simple-usage/#model-persistence","title":"Model persistence","text":"<p>Finally, we can store the model with <code>MLJ.save</code>.</p> <pre><code>MLJ.save(\"final.jlso\", final)\n</code></pre> <p>Loading the model again, the machine is not bound to data anymore, but we can bind it to data if we supply <code>X</code> again.</p> <pre><code>final = machine(\"final.jlso\")\n</code></pre> <pre><code>trained Machine; does not cache data\n  model: DeterministicUnsupervisedCompositeDetector(normalize = scale_minmax, \u2026)\n  args: \n</code></pre> <p>We can still use the machine to predict, even though its not bound to data.</p> <pre><code>y\u0302 == predict(final, X[test, :])\n</code></pre> <pre><code>true\n</code></pre> <p>If you would like to know how you can combine detectors or how to develop your own detectors, continue with the Advanced Usage guide.</p>"}]}